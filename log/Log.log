INFO:root:
----------parameters----------
seed: 0
model_path: ./models
output_path: ./outputs
log_path: ./log
layers: [2, 20, 20, 20, 20, 1]
learning_rate: 0.001
epochs: 100
save_epoch_freq: 1
INFO:root:
----------model----------
INFO:root:PINN(
  (activation): Tanh()
  (loss_function): MSELoss()
  (linears): ModuleList(
    (0): Linear(in_features=2, out_features=20, bias=True)
    (1-3): 3 x Linear(in_features=20, out_features=20, bias=True)
    (4): Linear(in_features=20, out_features=1, bias=True)
  )
)
INFO:root:Number of parameters: 1341
INFO:root:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)
INFO:root:
----------parameters----------
seed: 0
model_path: ./models
output_path: ./outputs
log_path: ./log
layers: [2, 20, 20, 20, 20, 1]
learning_rate: 0.001
epochs: 100
save_epoch_freq: 1
INFO:root:
----------model----------
INFO:root:PINN(
  (activation): Tanh()
  (loss_function): MSELoss()
  (linears): ModuleList(
    (0): Linear(in_features=2, out_features=20, bias=True)
    (1-3): 3 x Linear(in_features=20, out_features=20, bias=True)
    (4): Linear(in_features=20, out_features=1, bias=True)
  )
)
INFO:root:Number of parameters: 1341
INFO:root:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)
INFO:root:
----------parameters----------
seed: 0
model_path: ./models
output_path: ./outputs
log_path: ./log
layers: [2, 20, 20, 20, 20, 1]
learning_rate: 0.001
epochs: 100
save_epoch_freq: 1
INFO:root:
----------model----------
INFO:root:PINN(
  (activation): Tanh()
  (loss_function): MSELoss()
  (linears): ModuleList(
    (0): Linear(in_features=2, out_features=20, bias=True)
    (1-3): 3 x Linear(in_features=20, out_features=20, bias=True)
    (4): Linear(in_features=20, out_features=1, bias=True)
  )
)
INFO:root:Number of parameters: 1341
INFO:root:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)
INFO:root:
----------parameters----------
seed: 0
model_path: ./models
output_path: ./outputs
log_path: ./log
layers: [2, 20, 20, 20, 20, 1]
learning_rate: 0.001
epochs: 100
save_epoch_freq: 1
INFO:root:
----------model----------
INFO:root:PINN(
  (activation): Tanh()
  (loss_function): MSELoss()
  (linears): ModuleList(
    (0): Linear(in_features=2, out_features=20, bias=True)
    (1-3): 3 x Linear(in_features=20, out_features=20, bias=True)
    (4): Linear(in_features=20, out_features=1, bias=True)
  )
)
INFO:root:Number of parameters: 1341
INFO:root:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)
INFO:root:
----------parameters----------
seed: 0
model_path: ./models
output_path: ./outputs
log_path: ./log
layers: [2, 20, 20, 20, 20, 1]
learning_rate: 0.001
epochs: 100
save_epoch_freq: 1
INFO:root:
----------model----------
INFO:root:PINN(
  (activation): Tanh()
  (loss_function): MSELoss()
  (linears): ModuleList(
    (0): Linear(in_features=2, out_features=20, bias=True)
    (1-3): 3 x Linear(in_features=20, out_features=20, bias=True)
    (4): Linear(in_features=20, out_features=1, bias=True)
  )
)
INFO:root:Number of parameters: 1341
INFO:root:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)
INFO:root:
----------parameters----------
seed: 0
model_path: ./models
output_path: ./outputs
log_path: ./log
layers: [2, 20, 20, 20, 20, 1]
learning_rate: 0.001
epochs: 100
save_epoch_freq: 1
INFO:root:
----------parameters----------
seed: 0
model_path: ./models
output_path: ./outputs
log_path: ./log
layers: [2, 20, 20, 20, 20, 1]
learning_rate: 0.001
epochs: 10000
save_epoch_freq: 1
INFO:root:
----------model----------
INFO:root:PINN(
  (activation): ReLU()
  (loss_function): MSELoss()
  (linears): ModuleList(
    (0): Linear(in_features=2, out_features=20, bias=True)
    (1-3): 3 x Linear(in_features=20, out_features=20, bias=True)
    (4): Linear(in_features=20, out_features=1, bias=True)
  )
)
INFO:root:Number of parameters: 1341
INFO:root:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)
INFO:root:
----------parameters----------
seed: 0
model_path: ./models
output_path: ./outputs
log_path: ./log
layers: [2, 20, 20, 20, 20, 1]
learning_rate: 0.001
epochs: 1000
save_epoch_freq: 1
INFO:root:
----------model----------
INFO:root:PINN(
  (activation): ReLU()
  (loss_function): MSELoss()
  (linears): ModuleList(
    (0): Linear(in_features=2, out_features=20, bias=True)
    (1-3): 3 x Linear(in_features=20, out_features=20, bias=True)
    (4): Linear(in_features=20, out_features=1, bias=True)
  )
)
INFO:root:Number of parameters: 1341
INFO:root:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)
INFO:root:
----------parameters----------
seed: 0
model_path: ./models
output_path: ./outputs
log_path: ./log
layers: [2, 20, 20, 20, 20, 1]
learning_rate: 0.001
epochs: 1000
save_epoch_freq: 1
INFO:root:
----------model----------
INFO:root:PINN(
  (activation): ReLU()
  (loss_function): MSELoss()
  (linears): ModuleList(
    (0): Linear(in_features=2, out_features=20, bias=True)
    (1-3): 3 x Linear(in_features=20, out_features=20, bias=True)
    (4): Linear(in_features=20, out_features=1, bias=True)
  )
)
INFO:root:Number of parameters: 1341
INFO:root:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)
INFO:root:
----------parameters----------
seed: 0
model_path: ./models
output_path: ./outputs
log_path: ./log
layers: [2, 20, 20, 20, 20, 1]
learning_rate: 0.001
epochs: 1000
save_epoch_freq: 1
INFO:root:
----------model----------
INFO:root:PINN(
  (activation): ReLU()
  (loss_function): MSELoss()
  (linears): ModuleList(
    (0): Linear(in_features=2, out_features=20, bias=True)
    (1-3): 3 x Linear(in_features=20, out_features=20, bias=True)
    (4): Linear(in_features=20, out_features=1, bias=True)
  )
)
INFO:root:Number of parameters: 1341
INFO:root:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)
INFO:root:
----------parameters----------
seed: 0
model_path: ./models
output_path: ./outputs
log_path: ./log
layers: [2, 20, 20, 20, 20, 1]
learning_rate: 0.001
epochs: 1000
save_epoch_freq: 1
INFO:root:
----------model----------
INFO:root:PINN(
  (activation): ReLU()
  (loss_function): MSELoss()
  (linears): ModuleList(
    (0): Linear(in_features=2, out_features=20, bias=True)
    (1-3): 3 x Linear(in_features=20, out_features=20, bias=True)
    (4): Linear(in_features=20, out_features=1, bias=True)
  )
)
INFO:root:Number of parameters: 1341
INFO:root:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)
INFO:root:
----------parameters----------
seed: 0
model_path: ./models
output_path: ./outputs
log_path: ./log
layers: [2, 20, 20, 20, 20, 1]
learning_rate: 0.001
epochs: 1000
save_epoch_freq: 1
INFO:root:
----------model----------
INFO:root:PINN(
  (activation): ReLU()
  (loss_function): MSELoss()
  (linears): ModuleList(
    (0): Linear(in_features=2, out_features=20, bias=True)
    (1-3): 3 x Linear(in_features=20, out_features=20, bias=True)
    (4): Linear(in_features=20, out_features=1, bias=True)
  )
)
INFO:root:Number of parameters: 1341
INFO:root:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)
INFO:root:
----------parameters----------
seed: 0
model_path: ./models
output_path: ./outputs
log_path: ./log
layers: [2, 20, 20, 20, 20, 1]
learning_rate: 0.001
epochs: 1000
save_epoch_freq: 1
INFO:root:
----------model----------
INFO:root:PINN(
  (activation): ReLU()
  (loss_function): MSELoss()
  (linears): ModuleList(
    (0): Linear(in_features=2, out_features=20, bias=True)
    (1-3): 3 x Linear(in_features=20, out_features=20, bias=True)
    (4): Linear(in_features=20, out_features=1, bias=True)
  )
)
INFO:root:Number of parameters: 1341
INFO:root:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)
INFO:root:
----------parameters----------
seed: 0
model_path: ./models
output_path: ./outputs
log_path: ./log
layers: [2, 20, 20, 20, 20, 1]
learning_rate: 0.001
epochs: 1000
save_epoch_freq: 1
INFO:root:
----------model----------
INFO:root:PINN(
  (activation): ReLU()
  (loss_function): MSELoss()
  (linears): ModuleList(
    (0): Linear(in_features=2, out_features=20, bias=True)
    (1-3): 3 x Linear(in_features=20, out_features=20, bias=True)
    (4): Linear(in_features=20, out_features=1, bias=True)
  )
)
INFO:root:Number of parameters: 1341
INFO:root:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)
INFO:root:
----------parameters----------
seed: 0
model_path: ./models
output_path: ./outputs
log_path: ./log
layers: [2, 20, 20, 20, 20, 1]
learning_rate: 0.001
epochs: 1000
save_epoch_freq: 1
INFO:root:
----------model----------
INFO:root:PINN(
  (activation): ReLU()
  (loss_function): MSELoss()
  (linears): ModuleList(
    (0): Linear(in_features=2, out_features=20, bias=True)
    (1-3): 3 x Linear(in_features=20, out_features=20, bias=True)
    (4): Linear(in_features=20, out_features=1, bias=True)
  )
)
INFO:root:Number of parameters: 1341
INFO:root:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)
INFO:root:
----------parameters----------
seed: 0
model_path: ./models
output_path: ./outputs
log_path: ./log
layers: [2, 20, 20, 20, 20, 1]
learning_rate: 0.001
epochs: 1000
save_epoch_freq: 1
INFO:root:
----------model----------
INFO:root:PINN(
  (activation): ReLU()
  (loss_function): MSELoss()
  (linears): ModuleList(
    (0): Linear(in_features=2, out_features=20, bias=True)
    (1-3): 3 x Linear(in_features=20, out_features=20, bias=True)
    (4): Linear(in_features=20, out_features=1, bias=True)
  )
)
INFO:root:Number of parameters: 1341
INFO:root:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)
INFO:root:
----------parameters----------
seed: 0
model_path: ./models
output_path: ./outputs
log_path: ./log
layers: [2, 20, 20, 20, 20, 1]
learning_rate: 0.001
epochs: 1000
save_epoch_freq: 1
INFO:root:
----------model----------
INFO:root:PINN(
  (activation): ReLU()
  (loss_function): MSELoss()
  (linears): ModuleList(
    (0): Linear(in_features=2, out_features=20, bias=True)
    (1-3): 3 x Linear(in_features=20, out_features=20, bias=True)
    (4): Linear(in_features=20, out_features=1, bias=True)
  )
)
INFO:root:Number of parameters: 1341
INFO:root:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)
INFO:root:
----------parameters----------
seed: 0
model_path: ./models
output_path: ./outputs
log_path: ./log
layers: [2, 20, 20, 20, 20, 1]
learning_rate: 0.001
epochs: 1000
save_epoch_freq: 1
INFO:root:
----------model----------
INFO:root:PINN(
  (activation): ReLU()
  (loss_function): MSELoss()
  (linears): ModuleList(
    (0): Linear(in_features=2, out_features=20, bias=True)
    (1-3): 3 x Linear(in_features=20, out_features=20, bias=True)
    (4): Linear(in_features=20, out_features=1, bias=True)
  )
)
INFO:root:Number of parameters: 1341
INFO:root:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)
INFO:root:
----------parameters----------
seed: 0
model_path: ./models
output_path: ./outputs
log_path: ./log
layers: [2, 20, 20, 20, 20, 1]
learning_rate: 0.001
epochs: 1000
save_epoch_freq: 1
INFO:root:
----------model----------
INFO:root:PINN(
  (activation): ReLU()
  (loss_function): MSELoss()
  (linears): ModuleList(
    (0): Linear(in_features=2, out_features=20, bias=True)
    (1-3): 3 x Linear(in_features=20, out_features=20, bias=True)
    (4): Linear(in_features=20, out_features=1, bias=True)
  )
)
INFO:root:Number of parameters: 1341
INFO:root:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)
INFO:root:
----------parameters----------
seed: 0
model_path: ./models
output_path: ./outputs
log_path: ./log
layers: [2, 20, 20, 20, 20, 1]
learning_rate: 0.001
epochs: 1000
save_epoch_freq: 1
INFO:root:
----------model----------
INFO:root:PINN(
  (activation): ReLU()
  (loss_function): MSELoss()
  (linears): ModuleList(
    (0): Linear(in_features=2, out_features=20, bias=True)
    (1-3): 3 x Linear(in_features=20, out_features=20, bias=True)
    (4): Linear(in_features=20, out_features=1, bias=True)
  )
)
INFO:root:Number of parameters: 1341
INFO:root:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)
INFO:root:
----------parameters----------
seed: 0
model_path: ./models
output_path: ./outputs
log_path: ./log
layers: [2, 20, 20, 20, 20, 1]
learning_rate: 0.001
epochs: 1000
save_epoch_freq: 1
INFO:root:
----------model----------
INFO:root:PINN(
  (activation): ReLU()
  (loss_function): MSELoss()
  (linears): ModuleList(
    (0): Linear(in_features=2, out_features=20, bias=True)
    (1-3): 3 x Linear(in_features=20, out_features=20, bias=True)
    (4): Linear(in_features=20, out_features=1, bias=True)
  )
)
INFO:root:Number of parameters: 1341
INFO:root:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)
INFO:root:
----------parameters----------
seed: 0
model_path: ./models
output_path: ./outputs
log_path: ./log
layers: [2, 20, 20, 20, 20, 1]
learning_rate: 0.001
epochs: 1000
save_epoch_freq: 1
INFO:root:
----------model----------
INFO:root:PINN(
  (activation): ReLU()
  (loss_function): MSELoss()
  (linears): ModuleList(
    (0): Linear(in_features=2, out_features=20, bias=True)
    (1-3): 3 x Linear(in_features=20, out_features=20, bias=True)
    (4): Linear(in_features=20, out_features=1, bias=True)
  )
)
INFO:root:Number of parameters: 1341
INFO:root:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)
INFO:root:
----------parameters----------
seed: 0
model_path: ./models
output_path: ./outputs
log_path: ./log
layers: [2, 20, 20, 20, 20, 1]
learning_rate: 0.001
epochs: 1000
save_epoch_freq: 1
INFO:root:
----------model----------
INFO:root:PINN(
  (activation): ReLU()
  (loss_function): MSELoss()
  (linears): ModuleList(
    (0): Linear(in_features=2, out_features=20, bias=True)
    (1-3): 3 x Linear(in_features=20, out_features=20, bias=True)
    (4): Linear(in_features=20, out_features=1, bias=True)
  )
)
INFO:root:Number of parameters: 1341
INFO:root:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)
INFO:root:
----------parameters----------
seed: 0
model_path: ./models
output_path: ./outputs
log_path: ./log
layers: [2, 20, 20, 20, 20, 1]
learning_rate: 0.001
epochs: 1000
save_epoch_freq: 1
INFO:root:
----------model----------
INFO:root:PINN(
  (activation): ReLU()
  (loss_function): MSELoss()
  (linears): ModuleList(
    (0): Linear(in_features=2, out_features=20, bias=True)
    (1-3): 3 x Linear(in_features=20, out_features=20, bias=True)
    (4): Linear(in_features=20, out_features=1, bias=True)
  )
)
INFO:root:Number of parameters: 1341
INFO:root:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)
INFO:root:
----------parameters----------
seed: 0
model_path: ./models
output_path: ./outputs
log_path: ./log
layers: [2, 20, 20, 20, 20, 1]
learning_rate: 0.001
epochs: 1000
save_epoch_freq: 1
INFO:root:
----------model----------
INFO:root:PINN(
  (activation): ReLU()
  (loss_function): MSELoss()
  (linears): ModuleList(
    (0): Linear(in_features=2, out_features=20, bias=True)
    (1-3): 3 x Linear(in_features=20, out_features=20, bias=True)
    (4): Linear(in_features=20, out_features=1, bias=True)
  )
)
INFO:root:Number of parameters: 1341
INFO:root:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)
INFO:root:
----------parameters----------
seed: 0
model_path: ./models
output_path: ./outputs
log_path: ./log
layers: [2, 20, 20, 20, 20, 1]
learning_rate: 0.001
epochs: 1000
save_epoch_freq: 1
INFO:root:
----------model----------
INFO:root:PINN(
  (activation): ReLU()
  (loss_function): MSELoss()
  (linears): ModuleList(
    (0): Linear(in_features=2, out_features=20, bias=True)
    (1-3): 3 x Linear(in_features=20, out_features=20, bias=True)
    (4): Linear(in_features=20, out_features=1, bias=True)
  )
)
INFO:root:Number of parameters: 1341
INFO:root:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)
INFO:root:
----------parameters----------
seed: 0
model_path: ./models
output_path: ./outputs
log_path: ./log
layers: [2, 20, 20, 20, 20, 1]
learning_rate: 0.001
epochs: 1000
save_epoch_freq: 1
INFO:root:
----------model----------
INFO:root:PINN(
  (activation): ReLU()
  (loss_function): MSELoss()
  (linears): ModuleList(
    (0): Linear(in_features=2, out_features=20, bias=True)
    (1-3): 3 x Linear(in_features=20, out_features=20, bias=True)
    (4): Linear(in_features=20, out_features=1, bias=True)
  )
)
INFO:root:Number of parameters: 1341
INFO:root:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)
INFO:root:
----------parameters----------
seed: 0
model_path: ./models
output_path: ./outputs
log_path: ./log
layers: [2, 20, 20, 20, 20, 1]
learning_rate: 0.001
epochs: 1000
save_epoch_freq: 1
INFO:root:
----------model----------
INFO:root:PINN(
  (activation): ReLU()
  (loss_function): MSELoss()
  (linears): ModuleList(
    (0): Linear(in_features=2, out_features=20, bias=True)
    (1-3): 3 x Linear(in_features=20, out_features=20, bias=True)
    (4): Linear(in_features=20, out_features=1, bias=True)
  )
)
INFO:root:Number of parameters: 1341
INFO:root:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)
INFO:root:
----------parameters----------
seed: 0
model_path: ./models
output_path: ./outputs
log_path: ./log
layers: [2, 20, 20, 20, 20, 1]
learning_rate: 0.001
epochs: 1000
save_epoch_freq: 1
INFO:root:
----------model----------
INFO:root:PINN(
  (activation): ReLU()
  (loss_function): MSELoss()
  (linears): ModuleList(
    (0): Linear(in_features=2, out_features=20, bias=True)
    (1-3): 3 x Linear(in_features=20, out_features=20, bias=True)
    (4): Linear(in_features=20, out_features=1, bias=True)
  )
)
INFO:root:Number of parameters: 1341
INFO:root:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)
INFO:root:
----------parameters----------
seed: 0
model_path: ./models
output_path: ./outputs
log_path: ./log
layers: [2, 20, 20, 20, 20, 1]
learning_rate: 0.001
epochs: 1000
save_epoch_freq: 1
INFO:root:
----------model----------
INFO:root:PINN(
  (activation): ReLU()
  (loss_function): MSELoss()
  (linears): ModuleList(
    (0): Linear(in_features=2, out_features=20, bias=True)
    (1-3): 3 x Linear(in_features=20, out_features=20, bias=True)
    (4): Linear(in_features=20, out_features=1, bias=True)
  )
)
INFO:root:Number of parameters: 1341
INFO:root:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)
INFO:root:
----------parameters----------
seed: 0
model_path: ./models
output_path: ./outputs
log_path: ./log
layers: [2, 20, 20, 20, 20, 1]
learning_rate: 0.001
epochs: 1000
save_epoch_freq: 1
INFO:root:
----------model----------
INFO:root:PINN(
  (activation): ReLU()
  (loss_function): MSELoss()
  (linears): ModuleList(
    (0): Linear(in_features=2, out_features=20, bias=True)
    (1-3): 3 x Linear(in_features=20, out_features=20, bias=True)
    (4): Linear(in_features=20, out_features=1, bias=True)
  )
)
INFO:root:Number of parameters: 1341
INFO:root:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)
INFO:root:
----------parameters----------
seed: 0
model_path: ./models
output_path: ./outputs
log_path: ./log
layers: [2, 20, 20, 20, 20, 1]
learning_rate: 0.001
epochs: 1000
save_epoch_freq: 1
INFO:root:
----------model----------
INFO:root:PINN(
  (activation): ReLU()
  (loss_function): MSELoss()
  (linears): ModuleList(
    (0): Linear(in_features=2, out_features=20, bias=True)
    (1-3): 3 x Linear(in_features=20, out_features=20, bias=True)
    (4): Linear(in_features=20, out_features=1, bias=True)
  )
)
INFO:root:Number of parameters: 1341
INFO:root:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)
INFO:root:
----------parameters----------
seed: 0
model_path: ./models
output_path: ./outputs
log_path: ./log
layers: [2, 20, 20, 20, 20, 1]
learning_rate: 0.001
epochs: 1000
save_epoch_freq: 1
INFO:root:
----------model----------
INFO:root:PINN(
  (activation): ReLU()
  (loss_function): MSELoss()
  (linears): ModuleList(
    (0): Linear(in_features=2, out_features=20, bias=True)
    (1-3): 3 x Linear(in_features=20, out_features=20, bias=True)
    (4): Linear(in_features=20, out_features=1, bias=True)
  )
)
INFO:root:Number of parameters: 1341
INFO:root:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)
INFO:root:
----------parameters----------
seed: 0
model_path: ./models
output_path: ./outputs
log_path: ./log
layers: [2, 20, 20, 20, 20, 1]
learning_rate: 0.001
epochs: 1000
save_epoch_freq: 1
INFO:root:
----------model----------
INFO:root:PINN(
  (activation): ReLU()
  (loss_function): MSELoss()
  (linears): ModuleList(
    (0): Linear(in_features=2, out_features=20, bias=True)
    (1-3): 3 x Linear(in_features=20, out_features=20, bias=True)
    (4): Linear(in_features=20, out_features=1, bias=True)
  )
)
INFO:root:Number of parameters: 1341
INFO:root:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)
INFO:root:
----------parameters----------
seed: 0
model_path: ./models
output_path: ./outputs
log_path: ./log
layers: [2, 20, 20, 20, 20, 1]
learning_rate: 0.001
epochs: 1000
save_epoch_freq: 1
INFO:root:
----------model----------
INFO:root:PINN(
  (activation): ReLU()
  (loss_function): MSELoss()
  (linears): ModuleList(
    (0): Linear(in_features=2, out_features=20, bias=True)
    (1-3): 3 x Linear(in_features=20, out_features=20, bias=True)
    (4): Linear(in_features=20, out_features=1, bias=True)
  )
)
INFO:root:Number of parameters: 1341
INFO:root:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)
INFO:root:
----------parameters----------
seed: 0
model_path: ./models
output_path: ./outputs
log_path: ./log
layers: [2, 20, 20, 20, 20, 1]
learning_rate: 0.001
epochs: 1000
save_epoch_freq: 1
INFO:root:
----------model----------
INFO:root:PINN(
  (activation): ReLU()
  (loss_function): MSELoss()
  (linears): ModuleList(
    (0): Linear(in_features=2, out_features=20, bias=True)
    (1-3): 3 x Linear(in_features=20, out_features=20, bias=True)
    (4): Linear(in_features=20, out_features=1, bias=True)
  )
)
INFO:root:Number of parameters: 1341
INFO:root:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)
INFO:root:
----------parameters----------
seed: 0
model_path: ./models
output_path: ./outputs
log_path: ./log
layers: [2, 20, 20, 20, 20, 20, 20, 1]
learning_rate: 0.001
epochs: 1000
save_epoch_freq: 1
INFO:root:
----------model----------
INFO:root:PINN(
  (activation): ReLU()
  (loss_function): MSELoss()
  (linears): ModuleList(
    (0): Linear(in_features=2, out_features=20, bias=True)
    (1-5): 5 x Linear(in_features=20, out_features=20, bias=True)
    (6): Linear(in_features=20, out_features=1, bias=True)
  )
)
INFO:root:Number of parameters: 2181
INFO:root:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)
INFO:root:
----------parameters----------
seed: 0
model_path: ./models
output_path: ./outputs
log_path: ./log
layers: [2, 20, 20, 20, 20, 20, 20, 1]
learning_rate: 0.001
epochs: 1000
save_epoch_freq: 1
INFO:root:
----------model----------
INFO:root:PINN(
  (activation): ReLU()
  (loss_function): MSELoss()
  (linears): ModuleList(
    (0): Linear(in_features=2, out_features=20, bias=True)
    (1-5): 5 x Linear(in_features=20, out_features=20, bias=True)
    (6): Linear(in_features=20, out_features=1, bias=True)
  )
)
INFO:root:Number of parameters: 2181
INFO:root:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)
INFO:root:
----------parameters----------
seed: 0
model_path: ./models
output_path: ./outputs
log_path: ./log
layers: [2, 20, 20, 20, 20, 20, 20, 20, 20, 1]
learning_rate: 1e-05
epochs: 1000
save_epoch_freq: 1
INFO:root:
----------model----------
INFO:root:PINN(
  (activation): ReLU()
  (loss_function): MSELoss()
  (linears): ModuleList(
    (0): Linear(in_features=2, out_features=20, bias=True)
    (1-7): 7 x Linear(in_features=20, out_features=20, bias=True)
    (8): Linear(in_features=20, out_features=1, bias=True)
  )
)
INFO:root:Number of parameters: 3021
INFO:root:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1e-05
    maximize: False
    weight_decay: 0
)
INFO:root:
----------parameters----------
seed: 0
model_path: ./models
output_path: ./outputs
log_path: ./log
layers: [2, 20, 20, 20, 20, 20, 20, 20, 20, 1]
learning_rate: 1e-05
epochs: 1000
save_epoch_freq: 1
INFO:root:
----------model----------
INFO:root:PINN(
  (activation): ReLU()
  (loss_function): MSELoss()
  (linears): ModuleList(
    (0): Linear(in_features=2, out_features=20, bias=True)
    (1-7): 7 x Linear(in_features=20, out_features=20, bias=True)
    (8): Linear(in_features=20, out_features=1, bias=True)
  )
)
INFO:root:Number of parameters: 3021
INFO:root:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1e-05
    maximize: False
    weight_decay: 0
)
INFO:root:
----------parameters----------
seed: 0
model_path: ./models
output_path: ./outputs
log_path: ./log
layers: [2, 20, 20, 20, 20, 20, 20, 20, 20, 1]
learning_rate: 1e-05
epochs: 1000
save_epoch_freq: 1
INFO:root:
----------model----------
INFO:root:PINN(
  (activation): ReLU()
  (loss_function): MSELoss()
  (linears): ModuleList(
    (0): Linear(in_features=2, out_features=20, bias=True)
    (1-7): 7 x Linear(in_features=20, out_features=20, bias=True)
    (8): Linear(in_features=20, out_features=1, bias=True)
  )
)
INFO:root:Number of parameters: 3021
INFO:root:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1e-05
    maximize: False
    weight_decay: 0
)
INFO:root:
----------parameters----------
seed: 0
model_path: ./models
output_path: ./outputs
log_path: ./log
layers: [2, 20, 20, 20, 20, 20, 20, 20, 20, 1]
learning_rate: 1e-05
epochs: 1000
save_epoch_freq: 1
INFO:root:
----------model----------
INFO:root:PINN(
  (activation): ReLU()
  (loss_function): MSELoss()
  (linears): ModuleList(
    (0): Linear(in_features=2, out_features=20, bias=True)
    (1-7): 7 x Linear(in_features=20, out_features=20, bias=True)
    (8): Linear(in_features=20, out_features=1, bias=True)
  )
)
INFO:root:Number of parameters: 3021
INFO:root:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1e-05
    maximize: False
    weight_decay: 0
)
INFO:root:
----------parameters----------
seed: 0
model_path: ./models
output_path: ./outputs
log_path: ./log
layers: [2, 20, 20, 20, 20, 20, 20, 20, 20, 1]
learning_rate: 1e-05
epochs: 1000
save_epoch_freq: 1
INFO:root:
----------model----------
INFO:root:PINN(
  (activation): ReLU()
  (loss_function): MSELoss()
  (linears): ModuleList(
    (0): Linear(in_features=2, out_features=20, bias=True)
    (1-7): 7 x Linear(in_features=20, out_features=20, bias=True)
    (8): Linear(in_features=20, out_features=1, bias=True)
  )
)
INFO:root:Number of parameters: 3021
INFO:root:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1e-05
    maximize: False
    weight_decay: 0
)
INFO:root:
----------parameters----------
seed: 0
model_path: ./models
output_path: ./outputs
log_path: ./log
layers: [2, 20, 20, 20, 20, 20, 20, 20, 20, 20, 1]
learning_rate: 1e-05
epochs: 5000
save_epoch_freq: 1
INFO:root:
----------model----------
INFO:root:PINN(
  (activation): ReLU()
  (loss_function): MSELoss()
  (linears): ModuleList(
    (0): Linear(in_features=2, out_features=20, bias=True)
    (1-8): 8 x Linear(in_features=20, out_features=20, bias=True)
    (9): Linear(in_features=20, out_features=1, bias=True)
  )
)
INFO:root:Number of parameters: 3441
INFO:root:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1e-05
    maximize: False
    weight_decay: 0
)
INFO:root:
----------parameters----------
seed: 0
model_path: ./models
output_path: ./outputs
log_path: ./log
layers: [2, 20, 20, 20, 20, 20, 20, 20, 20, 20, 1]
learning_rate: 1e-05
epochs: 5000
save_epoch_freq: 1
INFO:root:
----------model----------
INFO:root:PINN(
  (activation): ReLU()
  (loss_function): MSELoss()
  (linears): ModuleList(
    (0): Linear(in_features=2, out_features=20, bias=True)
    (1-8): 8 x Linear(in_features=20, out_features=20, bias=True)
    (9): Linear(in_features=20, out_features=1, bias=True)
  )
)
INFO:root:Number of parameters: 3441
INFO:root:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1e-05
    maximize: False
    weight_decay: 0
)
INFO:root:
----------parameters----------
seed: 0
model_path: ./models
output_path: ./outputs
log_path: ./log
layers: [2, 20, 20, 20, 20, 20, 20, 20, 20, 20, 1]
learning_rate: 1e-05
epochs: 5000
save_epoch_freq: 1
INFO:root:
----------model----------
INFO:root:PINN(
  (activation): ReLU()
  (loss_function): MSELoss()
  (linears): ModuleList(
    (0): Linear(in_features=2, out_features=20, bias=True)
    (1-8): 8 x Linear(in_features=20, out_features=20, bias=True)
    (9): Linear(in_features=20, out_features=1, bias=True)
  )
)
INFO:root:Number of parameters: 3441
INFO:root:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1e-05
    maximize: False
    weight_decay: 0
)
INFO:root:
----------parameters----------
seed: 0
model_path: ./models
output_path: ./outputs
log_path: ./log
layers: [2, 50, 50, 50, 1]
learning_rate: 1e-05
epochs: 5000
save_epoch_freq: 1
INFO:root:
----------model----------
INFO:root:PINN(
  (activation): ReLU()
  (loss_function): MSELoss()
  (linears): ModuleList(
    (0): Linear(in_features=2, out_features=50, bias=True)
    (1-2): 2 x Linear(in_features=50, out_features=50, bias=True)
    (3): Linear(in_features=50, out_features=1, bias=True)
  )
)
INFO:root:Number of parameters: 5301
INFO:root:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1e-05
    maximize: False
    weight_decay: 0
)
INFO:root:
----------parameters----------
seed: 0
model_path: ./models
output_path: ./outputs
log_path: ./log
layers: [2, 50, 50, 50, 1]
learning_rate: 1e-05
epochs: 5000
save_epoch_freq: 1
INFO:root:
----------parameters----------
seed: 0
model_path: ./models
output_path: ./outputs
log_path: ./log
layers: [2, 50, 50, 50, 1]
learning_rate: 1e-05
epochs: 5000
save_epoch_freq: 1
INFO:root:
----------model----------
INFO:root:PINN(
  (activation): Tanh()
  (loss_function): MSELoss()
  (linears): ModuleList(
    (0): Linear(in_features=2, out_features=50, bias=True)
    (1-2): 2 x Linear(in_features=50, out_features=50, bias=True)
    (3): Linear(in_features=50, out_features=1, bias=True)
  )
)
INFO:root:Number of parameters: 5301
INFO:root:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1e-05
    maximize: False
    weight_decay: 0
)
INFO:root:
----------parameters----------
seed: 0
model_path: ./models
output_path: ./outputs
log_path: ./log
layers: [2, 50, 50, 50, 1]
learning_rate: 1e-05
epochs: 5000
save_epoch_freq: 1
INFO:root:
----------model----------
INFO:root:PINN(
  (activation): ReLU()
  (loss_function): MSELoss()
  (linears): ModuleList(
    (0): Linear(in_features=2, out_features=50, bias=True)
    (1-2): 2 x Linear(in_features=50, out_features=50, bias=True)
    (3): Linear(in_features=50, out_features=1, bias=True)
  )
)
INFO:root:Number of parameters: 5301
INFO:root:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1e-05
    maximize: False
    weight_decay: 0
)
INFO:root:
----------parameters----------
seed: 0
model_path: ./models
output_path: ./outputs
log_path: ./log
layers: [2, 50, 50, 50, 1]
learning_rate: 1e-05
epochs: 5000
save_epoch_freq: 1
INFO:root:
----------model----------
INFO:root:PINN(
  (activation): Tanh()
  (loss_function): MSELoss()
  (linears): ModuleList(
    (0): Linear(in_features=2, out_features=50, bias=True)
    (1-2): 2 x Linear(in_features=50, out_features=50, bias=True)
    (3): Linear(in_features=50, out_features=1, bias=True)
  )
)
INFO:root:Number of parameters: 5301
INFO:root:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1e-05
    maximize: False
    weight_decay: 0
)
INFO:root:
----------parameters----------
seed: 0
model_path: ./models
output_path: ./outputs
log_path: ./log
layers: [2, 50, 50, 50, 1]
learning_rate: 1e-06
epochs: 5000
save_epoch_freq: 1
INFO:root:
----------model----------
INFO:root:PINN(
  (activation): Tanh()
  (loss_function): MSELoss()
  (linears): ModuleList(
    (0): Linear(in_features=2, out_features=50, bias=True)
    (1-2): 2 x Linear(in_features=50, out_features=50, bias=True)
    (3): Linear(in_features=50, out_features=1, bias=True)
  )
)
INFO:root:Number of parameters: 5301
INFO:root:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1e-06
    maximize: False
    weight_decay: 0
)
INFO:root:
----------parameters----------
seed: 0
model_path: ./models
output_path: ./outputs
log_path: ./log
layers: [2, 50, 50, 50, 1]
learning_rate: 1e-06
epochs: 5000
save_epoch_freq: 1
INFO:root:
----------model----------
INFO:root:PINN(
  (activation): Tanh()
  (loss_function): MSELoss()
  (linears): ModuleList(
    (0): Linear(in_features=2, out_features=50, bias=True)
    (1-2): 2 x Linear(in_features=50, out_features=50, bias=True)
    (3): Linear(in_features=50, out_features=1, bias=True)
  )
)
INFO:root:Number of parameters: 5301
INFO:root:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1e-06
    maximize: False
    weight_decay: 0
)
INFO:root:
----------parameters----------
seed: 0
model_path: ./models
output_path: ./outputs
log_path: ./log
layers: [2, 50, 50, 50, 1]
learning_rate: 1e-06
epochs: 5000
save_epoch_freq: 1
INFO:root:
----------parameters----------
seed: 0
model_path: ./models
output_path: ./outputs
log_path: ./log
layers: [2, 50, 50, 50, 1]
learning_rate: 1e-06
epochs: 5000
save_epoch_freq: 1
INFO:root:
----------model----------
INFO:root:PINN(
  (activation): Tanh()
  (loss_function): MSELoss()
  (linears): ModuleList(
    (0): Linear(in_features=2, out_features=50, bias=True)
    (1-2): 2 x Linear(in_features=50, out_features=50, bias=True)
    (3): Linear(in_features=50, out_features=1, bias=True)
  )
)
INFO:root:Number of parameters: 5301
INFO:root:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1e-06
    maximize: False
    weight_decay: 0
)
INFO:root:
----------parameters----------
seed: 0
model_path: ./models
output_path: ./outputs
log_path: ./log
layers: [2, 50, 50, 50, 1]
learning_rate: 0.0001
epochs: 1000
save_epoch_freq: 1
INFO:root:
----------model----------
INFO:root:PINN(
  (activation): Tanh()
  (loss_function): MSELoss()
  (linears): ModuleList(
    (0): Linear(in_features=2, out_features=50, bias=True)
    (1-2): 2 x Linear(in_features=50, out_features=50, bias=True)
    (3): Linear(in_features=50, out_features=1, bias=True)
  )
)
INFO:root:Number of parameters: 5301
INFO:root:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0
)
INFO:root:
----------parameters----------
seed: 0
model_path: ./models
output_path: ./outputs
log_path: ./log
layers: [2, 50, 50, 50, 1]
learning_rate: 1e-05
epochs: 1000
save_epoch_freq: 1
INFO:root:
----------model----------
INFO:root:PINN(
  (activation): Tanh()
  (loss_function): MSELoss()
  (linears): ModuleList(
    (0): Linear(in_features=2, out_features=50, bias=True)
    (1-2): 2 x Linear(in_features=50, out_features=50, bias=True)
    (3): Linear(in_features=50, out_features=1, bias=True)
  )
)
INFO:root:Number of parameters: 5301
INFO:root:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1e-05
    maximize: False
    weight_decay: 0
)
INFO:root:
----------parameters----------
seed: 0
model_path: ./models
output_path: ./outputs
log_path: ./log
layers: [2, 50, 50, 50, 1]
learning_rate: 1e-05
epochs: 1000
save_epoch_freq: 1
INFO:root:
----------model----------
INFO:root:PINN(
  (activation): Tanh()
  (loss_function): MSELoss()
  (linears): ModuleList(
    (0): Linear(in_features=2, out_features=50, bias=True)
    (1-2): 2 x Linear(in_features=50, out_features=50, bias=True)
    (3): Linear(in_features=50, out_features=1, bias=True)
  )
)
INFO:root:Number of parameters: 5301
INFO:root:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1e-05
    maximize: False
    weight_decay: 0
)
INFO:root:
----------parameters----------
seed: 0
model_path: ./models
output_path: ./outputs
log_path: ./log
layers: [2, 50, 50, 50, 1]
learning_rate: 1e-05
epochs: 1000
save_epoch_freq: 1
INFO:root:
----------model----------
INFO:root:PINN(
  (activation): Tanh()
  (loss_function): MSELoss()
  (linears): ModuleList(
    (0): Linear(in_features=2, out_features=50, bias=True)
    (1-2): 2 x Linear(in_features=50, out_features=50, bias=True)
    (3): Linear(in_features=50, out_features=1, bias=True)
  )
)
INFO:root:Number of parameters: 5301
INFO:root:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1e-05
    maximize: False
    weight_decay: 0
)
INFO:root:
----------parameters----------
seed: 0
model_path: ./models
output_path: ./outputs
log_path: ./log
layers: [2, 50, 50, 50, 1]
learning_rate: 1e-05
epochs: 1000
save_epoch_freq: 1
INFO:root:
----------model----------
INFO:root:PINN(
  (activation): Tanh()
  (loss_function): MSELoss()
  (linears): ModuleList(
    (0): Linear(in_features=2, out_features=50, bias=True)
    (1-2): 2 x Linear(in_features=50, out_features=50, bias=True)
    (3): Linear(in_features=50, out_features=1, bias=True)
  )
)
INFO:root:Number of parameters: 5301
INFO:root:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1e-05
    maximize: False
    weight_decay: 0
)
INFO:root:
----------parameters----------
seed: 0
model_path: ./models
output_path: ./outputs
log_path: ./log
layers: [2, 50, 50, 50, 1]
learning_rate: 1e-05
epochs: 1000
save_epoch_freq: 1
INFO:root:
----------model----------
INFO:root:PINN(
  (activation): Tanh()
  (loss_function): MSELoss()
  (linears): ModuleList(
    (0): Linear(in_features=2, out_features=50, bias=True)
    (1-2): 2 x Linear(in_features=50, out_features=50, bias=True)
    (3): Linear(in_features=50, out_features=1, bias=True)
  )
)
INFO:root:Number of parameters: 5301
INFO:root:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1e-05
    maximize: False
    weight_decay: 0
)
INFO:root:
----------parameters----------
seed: 0
model_path: ./models
output_path: ./outputs
log_path: ./log
layers: [2, 50, 50, 50, 1]
learning_rate: 1e-05
epochs: 1000
save_epoch_freq: 1
INFO:root:
----------model----------
INFO:root:PINN(
  (activation): Tanh()
  (loss_function): MSELoss()
  (linears): ModuleList(
    (0): Linear(in_features=2, out_features=50, bias=True)
    (1-2): 2 x Linear(in_features=50, out_features=50, bias=True)
    (3): Linear(in_features=50, out_features=1, bias=True)
  )
)
INFO:root:Number of parameters: 5301
INFO:root:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1e-05
    maximize: False
    weight_decay: 0
)
INFO:root:
----------parameters----------
seed: 0
model_path: ./models
output_path: ./outputs
log_path: ./log
layers: [2, 50, 50, 50, 1]
learning_rate: 1e-05
epochs: 1000
save_epoch_freq: 1
INFO:root:
----------model----------
INFO:root:PINN(
  (activation): Tanh()
  (loss_function): MSELoss()
  (linears): ModuleList(
    (0): Linear(in_features=2, out_features=50, bias=True)
    (1-2): 2 x Linear(in_features=50, out_features=50, bias=True)
    (3): Linear(in_features=50, out_features=1, bias=True)
  )
)
INFO:root:Number of parameters: 5301
INFO:root:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1e-05
    maximize: False
    weight_decay: 0
)
INFO:root:
----------parameters----------
seed: 0
model_path: ./models
output_path: ./outputs
log_path: ./log
layers: [2, 50, 50, 50, 1]
learning_rate: 1e-05
epochs: 1000
save_epoch_freq: 1
INFO:root:
----------model----------
INFO:root:PINN(
  (activation): Tanh()
  (loss_function): MSELoss()
  (linears): ModuleList(
    (0): Linear(in_features=2, out_features=50, bias=True)
    (1-2): 2 x Linear(in_features=50, out_features=50, bias=True)
    (3): Linear(in_features=50, out_features=1, bias=True)
  )
)
INFO:root:Number of parameters: 5301
INFO:root:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1e-05
    maximize: False
    weight_decay: 0
)
INFO:root:
----------parameters----------
seed: 0
model_path: ./models
output_path: ./outputs
log_path: ./log
layers: [2, 50, 50, 50, 1]
learning_rate: 1e-05
epochs: 1000
save_epoch_freq: 1
INFO:root:
----------parameters----------
seed: 0
model_path: ./models
output_path: ./outputs
log_path: ./log
layers: [2, 50, 50, 50, 1]
learning_rate: 1e-05
epochs: 1000
save_epoch_freq: 1
INFO:root:
----------parameters----------
seed: 0
model_path: ./models
output_path: ./outputs
log_path: ./log
layers: [2, 50, 50, 50, 1]
learning_rate: 1e-05
epochs: 1000
save_epoch_freq: 1
INFO:root:
----------parameters----------
seed: 0
model_path: ./models
output_path: ./outputs
log_path: ./log
layers: [2, 50, 50, 50, 1]
learning_rate: 1e-05
epochs: 1000
save_epoch_freq: 1
INFO:root:
----------model----------
INFO:root:PINN(
  (activation): Tanh()
  (loss_function): MSELoss()
  (linears): ModuleList(
    (0): Linear(in_features=2, out_features=50, bias=True)
    (1-2): 2 x Linear(in_features=50, out_features=50, bias=True)
    (3): Linear(in_features=50, out_features=1, bias=True)
  )
)
INFO:root:Number of parameters: 5301
INFO:root:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1e-05
    maximize: False
    weight_decay: 0
)
INFO:root:
----------parameters----------
seed: 0
model_path: ./models
output_path: ./outputs
log_path: ./log
layers: [2, 50, 50, 50, 1]
learning_rate: 1e-05
epochs: 10000
save_epoch_freq: 1
INFO:root:
----------model----------
INFO:root:PINN(
  (activation): Tanh()
  (loss_function): MSELoss()
  (linears): ModuleList(
    (0): Linear(in_features=2, out_features=50, bias=True)
    (1-2): 2 x Linear(in_features=50, out_features=50, bias=True)
    (3): Linear(in_features=50, out_features=1, bias=True)
  )
)
INFO:root:Number of parameters: 5301
INFO:root:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1e-05
    maximize: False
    weight_decay: 0
)
INFO:root:
----------parameters----------
seed: 0
model_path: ./models
output_path: ./outputs
log_path: ./log
layers: [2, 50, 50, 50, 1]
learning_rate: 0.001
epochs: 10000
save_epoch_freq: 1
INFO:root:
----------model----------
INFO:root:PINN(
  (activation): Tanh()
  (loss_function): MSELoss()
  (linears): ModuleList(
    (0): Linear(in_features=2, out_features=50, bias=True)
    (1-2): 2 x Linear(in_features=50, out_features=50, bias=True)
    (3): Linear(in_features=50, out_features=1, bias=True)
  )
)
INFO:root:Number of parameters: 5301
INFO:root:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)
INFO:root:
----------parameters----------
seed: 0
model_path: ./models
output_path: ./outputs
log_path: ./log
layers: [2, 50, 50, 50, 1]
learning_rate: 0.001
epochs: 1000
save_epoch_freq: 1
INFO:root:
----------model----------
INFO:root:PINN(
  (activation): Tanh()
  (loss_function): MSELoss()
  (linears): ModuleList(
    (0): Linear(in_features=2, out_features=50, bias=True)
    (1-2): 2 x Linear(in_features=50, out_features=50, bias=True)
    (3): Linear(in_features=50, out_features=1, bias=True)
  )
)
INFO:root:Number of parameters: 5301
INFO:root:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)
INFO:root:
----------parameters----------
seed: 0
model_path: ./models
output_path: ./outputs
log_path: ./log
layers: [2, 50, 50, 50, 1]
learning_rate: 0.001
epochs: 1000
save_epoch_freq: 1
INFO:root:
----------model----------
INFO:root:PINN(
  (activation): Tanh()
  (loss_function): MSELoss()
  (linears): ModuleList(
    (0): Linear(in_features=2, out_features=50, bias=True)
    (1-2): 2 x Linear(in_features=50, out_features=50, bias=True)
    (3): Linear(in_features=50, out_features=1, bias=True)
  )
)
INFO:root:Number of parameters: 5301
INFO:root:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)
INFO:root:
----------parameters----------
seed: 0
model_path: ./models
output_path: ./outputs
log_path: ./log
layers: [2, 50, 50, 50, 1]
learning_rate: 0.001
epochs: 1000
save_epoch_freq: 1
INFO:root:
----------model----------
INFO:root:PINN(
  (activation): Tanh()
  (loss_function): MSELoss()
  (linears): ModuleList(
    (0): Linear(in_features=2, out_features=50, bias=True)
    (1-2): 2 x Linear(in_features=50, out_features=50, bias=True)
    (3): Linear(in_features=50, out_features=1, bias=True)
  )
)
INFO:root:Number of parameters: 5301
INFO:root:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)
INFO:root:
----------parameters----------
seed: 0
model_path: ./models
output_path: ./outputs
log_path: ./log
layers: [2, 50, 50, 50, 1]
learning_rate: 0.001
epochs: 2000
save_epoch_freq: 1
INFO:root:
----------model----------
INFO:root:PINN(
  (activation): Tanh()
  (loss_function): MSELoss()
  (linears): ModuleList(
    (0): Linear(in_features=2, out_features=50, bias=True)
    (1-2): 2 x Linear(in_features=50, out_features=50, bias=True)
    (3): Linear(in_features=50, out_features=1, bias=True)
  )
)
INFO:root:Number of parameters: 5301
INFO:root:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)
INFO:root:
----------parameters----------
seed: 0
model_path: ./models
output_path: ./outputs
log_path: ./log
layers: [2, 50, 50, 50, 50, 1]
learning_rate: 0.001
epochs: 2000
save_epoch_freq: 1
INFO:root:
----------model----------
INFO:root:PINN(
  (activation): Tanh()
  (loss_function): MSELoss()
  (linears): ModuleList(
    (0): Linear(in_features=2, out_features=50, bias=True)
    (1-3): 3 x Linear(in_features=50, out_features=50, bias=True)
    (4): Linear(in_features=50, out_features=1, bias=True)
  )
)
INFO:root:Number of parameters: 7851
INFO:root:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)
INFO:root:
----------parameters----------
seed: 0
model_path: ./models
output_path: ./outputs
log_path: ./log
layers: [2, 50, 50, 50, 50, 1]
learning_rate: 0.001
epochs: 5000
save_epoch_freq: 1
INFO:root:
----------model----------
INFO:root:PINN(
  (activation): Tanh()
  (loss_function): MSELoss()
  (linears): ModuleList(
    (0): Linear(in_features=2, out_features=50, bias=True)
    (1-3): 3 x Linear(in_features=50, out_features=50, bias=True)
    (4): Linear(in_features=50, out_features=1, bias=True)
  )
)
INFO:root:Number of parameters: 7851
INFO:root:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)
INFO:root:
----------parameters----------
seed: 0
model_path: ./models
output_path: ./outputs
log_path: ./log
layers: [2, 50, 50, 50, 1]
learning_rate: 0.0001
epochs: 5000
save_epoch_freq: 1
INFO:root:
----------model----------
INFO:root:PINN(
  (activation): Tanh()
  (loss_function): MSELoss()
  (linears): ModuleList(
    (0): Linear(in_features=2, out_features=50, bias=True)
    (1-2): 2 x Linear(in_features=50, out_features=50, bias=True)
    (3): Linear(in_features=50, out_features=1, bias=True)
  )
)
INFO:root:Number of parameters: 5301
INFO:root:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0
)
INFO:root:
----------parameters----------
seed: 1
model_path: ./models
output_path: ./outputs
log_path: ./log
layers: [2, 50, 50, 50, 1]
learning_rate: 0.0001
epochs: 5000
save_epoch_freq: 1
INFO:root:
----------model----------
INFO:root:PINN(
  (activation): Tanh()
  (loss_function): MSELoss()
  (linears): ModuleList(
    (0): Linear(in_features=2, out_features=50, bias=True)
    (1-2): 2 x Linear(in_features=50, out_features=50, bias=True)
    (3): Linear(in_features=50, out_features=1, bias=True)
  )
)
INFO:root:Number of parameters: 5301
INFO:root:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0
)
INFO:root:
----------parameters----------
seed: 1
model_path: ./models
output_path: ./outputs
log_path: ./log
layers: [2, 50, 50, 50, 1]
learning_rate: 0.00025
epochs: 5000
save_epoch_freq: 1
INFO:root:
----------model----------
INFO:root:PINN(
  (activation): Tanh()
  (loss_function): MSELoss()
  (linears): ModuleList(
    (0): Linear(in_features=2, out_features=50, bias=True)
    (1-2): 2 x Linear(in_features=50, out_features=50, bias=True)
    (3): Linear(in_features=50, out_features=1, bias=True)
  )
)
INFO:root:Number of parameters: 5301
INFO:root:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.00025
    maximize: False
    weight_decay: 0
)
INFO:root:
----------parameters----------
seed: 1
model_path: ./models
output_path: ./outputs
log_path: ./log
layers: [2, 50, 50, 50, 1]
learning_rate: 0.00025
epochs: 5000
save_epoch_freq: 1
INFO:root:
----------model----------
INFO:root:PINN(
  (activation): Tanh()
  (loss_function): MSELoss()
  (linears): ModuleList(
    (0): Linear(in_features=2, out_features=50, bias=True)
    (1-2): 2 x Linear(in_features=50, out_features=50, bias=True)
    (3): Linear(in_features=50, out_features=1, bias=True)
  )
)
INFO:root:Number of parameters: 5301
INFO:root:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.00025
    maximize: False
    weight_decay: 0
)
INFO:root:
----------parameters----------
seed: 1
model_path: ./models
output_path: ./outputs
log_path: ./log
layers: [2, 50, 50, 50, 1]
learning_rate: 1.5e-05
epochs: 10000
save_epoch_freq: 1
INFO:root:
----------model----------
INFO:root:PINN(
  (activation): Tanh()
  (loss_function): MSELoss()
  (linears): ModuleList(
    (0): Linear(in_features=2, out_features=50, bias=True)
    (1-2): 2 x Linear(in_features=50, out_features=50, bias=True)
    (3): Linear(in_features=50, out_features=1, bias=True)
  )
)
INFO:root:Number of parameters: 5301
INFO:root:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.5e-05
    maximize: False
    weight_decay: 0
)
INFO:root:
----------parameters----------
seed: 1
model_path: ./models
output_path: ./outputs
log_path: ./log
layers: [2, 50, 50, 50, 1]
learning_rate: 6.5e-05
epochs: 10000
save_epoch_freq: 1
INFO:root:
----------model----------
INFO:root:PINN(
  (activation): Tanh()
  (loss_function): MSELoss()
  (linears): ModuleList(
    (0): Linear(in_features=2, out_features=50, bias=True)
    (1-2): 2 x Linear(in_features=50, out_features=50, bias=True)
    (3): Linear(in_features=50, out_features=1, bias=True)
  )
)
INFO:root:Number of parameters: 5301
INFO:root:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 6.5e-05
    maximize: False
    weight_decay: 0
)
INFO:root:
----------parameters----------
seed: 1
model_path: ./models
output_path: ./outputs
log_path: ./log
layers: [2, 50, 50, 50, 1]
learning_rate: 6.5e-05
epochs: 10000
save_epoch_freq: 1
INFO:root:
----------model----------
INFO:root:PINN(
  (activation): Tanh()
  (loss_function): MSELoss()
  (linears): ModuleList(
    (0): Linear(in_features=2, out_features=50, bias=True)
    (1-2): 2 x Linear(in_features=50, out_features=50, bias=True)
    (3): Linear(in_features=50, out_features=1, bias=True)
  )
)
INFO:root:Number of parameters: 5301
INFO:root:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 6.5e-05
    maximize: False
    weight_decay: 0
)
INFO:root:
----------parameters----------
seed: 1
model_path: ./models
output_path: ./outputs
log_path: ./log
layers: [2, 50, 50, 50, 1]
learning_rate: 6.5e-05
epochs: 10000
save_epoch_freq: 1
INFO:root:
----------model----------
INFO:root:PINN(
  (activation): ReLU()
  (loss_function): MSELoss()
  (linears): ModuleList(
    (0): Linear(in_features=2, out_features=50, bias=True)
    (1-2): 2 x Linear(in_features=50, out_features=50, bias=True)
    (3): Linear(in_features=50, out_features=1, bias=True)
  )
)
INFO:root:Number of parameters: 5301
INFO:root:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 6.5e-05
    maximize: False
    weight_decay: 0
)
INFO:root:
----------parameters----------
seed: 1
model_path: ./models
output_path: ./outputs
log_path: ./log
layers: [2, 50, 50, 50, 1]
learning_rate: 6.5e-05
epochs: 10000
save_epoch_freq: 1
INFO:root:
----------model----------
INFO:root:PINN(
  (activation): ReLU()
  (loss_function): MSELoss()
  (linears): ModuleList(
    (0): Linear(in_features=2, out_features=50, bias=True)
    (1-2): 2 x Linear(in_features=50, out_features=50, bias=True)
    (3): Linear(in_features=50, out_features=1, bias=True)
  )
)
INFO:root:Number of parameters: 5301
INFO:root:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 6.5e-05
    maximize: False
    weight_decay: 0
)
INFO:root:
----------parameters----------
seed: 0
model_path: ./models
output_path: ./outputs
log_path: ./log
layers: [2, 50, 50, 50, 50, 50, 50, 1]
learning_rate: 6.5e-05
epochs: 10000
save_epoch_freq: 1
INFO:root:
----------model----------
INFO:root:PINN(
  (activation): ReLU()
  (loss_function): MSELoss()
  (linears): ModuleList(
    (0): Linear(in_features=2, out_features=50, bias=True)
    (1-5): 5 x Linear(in_features=50, out_features=50, bias=True)
    (6): Linear(in_features=50, out_features=1, bias=True)
  )
)
INFO:root:Number of parameters: 12951
INFO:root:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 6.5e-05
    maximize: False
    weight_decay: 0
)
INFO:root:
----------parameters----------
seed: 0
model_path: ./models
output_path: ./outputs
log_path: ./log
layers: [2, 8, 16, 32, 64, 32, 16, 8, 1]
learning_rate: 6.5e-05
epochs: 2000
save_epoch_freq: 1
INFO:root:
----------model----------
INFO:root:PINN(
  (activation): ReLU()
  (loss_function): MSELoss()
  (linears): ModuleList(
    (0): Linear(in_features=2, out_features=8, bias=True)
    (1): Linear(in_features=8, out_features=16, bias=True)
    (2): Linear(in_features=16, out_features=32, bias=True)
    (3): Linear(in_features=32, out_features=64, bias=True)
    (4): Linear(in_features=64, out_features=32, bias=True)
    (5): Linear(in_features=32, out_features=16, bias=True)
    (6): Linear(in_features=16, out_features=8, bias=True)
    (7): Linear(in_features=8, out_features=1, bias=True)
  )
)
INFO:root:Number of parameters: 5577
INFO:root:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 6.5e-05
    maximize: False
    weight_decay: 0
)
INFO:root:
----------parameters----------
seed: 0
model_path: ./models
output_path: ./outputs
log_path: ./log
layers: [2, 8, 16, 32, 64, 32, 16, 8, 1]
learning_rate: 0.0015
epochs: 2000
save_epoch_freq: 1
INFO:root:
----------model----------
INFO:root:PINN(
  (activation): ReLU()
  (loss_function): MSELoss()
  (linears): ModuleList(
    (0): Linear(in_features=2, out_features=8, bias=True)
    (1): Linear(in_features=8, out_features=16, bias=True)
    (2): Linear(in_features=16, out_features=32, bias=True)
    (3): Linear(in_features=32, out_features=64, bias=True)
    (4): Linear(in_features=64, out_features=32, bias=True)
    (5): Linear(in_features=32, out_features=16, bias=True)
    (6): Linear(in_features=16, out_features=8, bias=True)
    (7): Linear(in_features=8, out_features=1, bias=True)
  )
)
INFO:root:Number of parameters: 5577
INFO:root:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0015
    maximize: False
    weight_decay: 0
)
INFO:root:
----------parameters----------
seed: 0
model_path: ./models
output_path: ./outputs
log_path: ./log
layers: [2, 8, 16, 32, 64, 32, 16, 8, 1]
learning_rate: 0.00015
epochs: 1000
save_epoch_freq: 1
INFO:root:
----------model----------
INFO:root:PINN(
  (activation): ReLU()
  (loss_function): MSELoss()
  (linears): ModuleList(
    (0): Linear(in_features=2, out_features=8, bias=True)
    (1): Linear(in_features=8, out_features=16, bias=True)
    (2): Linear(in_features=16, out_features=32, bias=True)
    (3): Linear(in_features=32, out_features=64, bias=True)
    (4): Linear(in_features=64, out_features=32, bias=True)
    (5): Linear(in_features=32, out_features=16, bias=True)
    (6): Linear(in_features=16, out_features=8, bias=True)
    (7): Linear(in_features=8, out_features=1, bias=True)
  )
)
INFO:root:Number of parameters: 5577
INFO:root:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.00015
    maximize: False
    weight_decay: 0
)
INFO:root:
----------parameters----------
seed: 0
model_path: ./models
output_path: ./outputs
log_path: ./log
layers: [2, 8, 16, 32, 64, 32, 16, 8, 1]
learning_rate: 0.00015
epochs: 1000
save_epoch_freq: 1
INFO:root:
----------model----------
INFO:root:PINN(
  (activation): ReLU()
  (loss_function): MSELoss()
  (linears): ModuleList(
    (0): Linear(in_features=2, out_features=8, bias=True)
    (1): Linear(in_features=8, out_features=16, bias=True)
    (2): Linear(in_features=16, out_features=32, bias=True)
    (3): Linear(in_features=32, out_features=64, bias=True)
    (4): Linear(in_features=64, out_features=32, bias=True)
    (5): Linear(in_features=32, out_features=16, bias=True)
    (6): Linear(in_features=16, out_features=8, bias=True)
    (7): Linear(in_features=8, out_features=1, bias=True)
  )
)
INFO:root:Number of parameters: 5577
INFO:root:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.00015
    maximize: False
    weight_decay: 0
)
INFO:root:
----------parameters----------
seed: 0
model_path: ./models
output_path: ./outputs
log_path: ./log
layers: [2, 8, 16, 32, 64, 64, 32, 16, 8, 1]
learning_rate: 0.00015
epochs: 10000
save_epoch_freq: 1
INFO:root:
----------model----------
INFO:root:PINN(
  (activation): ReLU()
  (loss_function): MSELoss()
  (linears): ModuleList(
    (0): Linear(in_features=2, out_features=8, bias=True)
    (1): Linear(in_features=8, out_features=16, bias=True)
    (2): Linear(in_features=16, out_features=32, bias=True)
    (3): Linear(in_features=32, out_features=64, bias=True)
    (4): Linear(in_features=64, out_features=64, bias=True)
    (5): Linear(in_features=64, out_features=32, bias=True)
    (6): Linear(in_features=32, out_features=16, bias=True)
    (7): Linear(in_features=16, out_features=8, bias=True)
    (8): Linear(in_features=8, out_features=1, bias=True)
  )
)
INFO:root:Number of parameters: 9737
INFO:root:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.00015
    maximize: False
    weight_decay: 0
)
INFO:root:
----------parameters----------
seed: 0
model_path: ./models
output_path: ./outputs
log_path: ./log
layers: [2, 8, 16, 32, 64, 64, 32, 16, 8, 1]
learning_rate: 1.5e-05
epochs: 10000
save_epoch_freq: 1
INFO:root:
----------model----------
INFO:root:PINN(
  (activation): ReLU()
  (loss_function): MSELoss()
  (linears): ModuleList(
    (0): Linear(in_features=2, out_features=8, bias=True)
    (1): Linear(in_features=8, out_features=16, bias=True)
    (2): Linear(in_features=16, out_features=32, bias=True)
    (3): Linear(in_features=32, out_features=64, bias=True)
    (4): Linear(in_features=64, out_features=64, bias=True)
    (5): Linear(in_features=64, out_features=32, bias=True)
    (6): Linear(in_features=32, out_features=16, bias=True)
    (7): Linear(in_features=16, out_features=8, bias=True)
    (8): Linear(in_features=8, out_features=1, bias=True)
  )
)
INFO:root:Number of parameters: 9737
INFO:root:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.5e-05
    maximize: False
    weight_decay: 0
)
INFO:root:
----------parameters----------
seed: 0
model_path: ./models
output_path: ./outputs
log_path: ./log
layers: [2, 8, 16, 32, 64, 64, 32, 16, 8, 1]
learning_rate: 0.00015
epochs: 2500
save_epoch_freq: 1
INFO:root:
----------model----------
INFO:root:PINN(
  (activation): ReLU()
  (loss_function): MSELoss()
  (linears): ModuleList(
    (0): Linear(in_features=2, out_features=8, bias=True)
    (1): Linear(in_features=8, out_features=16, bias=True)
    (2): Linear(in_features=16, out_features=32, bias=True)
    (3): Linear(in_features=32, out_features=64, bias=True)
    (4): Linear(in_features=64, out_features=64, bias=True)
    (5): Linear(in_features=64, out_features=32, bias=True)
    (6): Linear(in_features=32, out_features=16, bias=True)
    (7): Linear(in_features=16, out_features=8, bias=True)
    (8): Linear(in_features=8, out_features=1, bias=True)
  )
)
INFO:root:Number of parameters: 9737
INFO:root:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.00015
    maximize: False
    weight_decay: 0
)
INFO:root:
----------parameters----------
seed: 0
model_path: ./models
output_path: ./outputs
log_path: ./log
layers: [2, 8, 16, 32, 64, 64, 32, 16, 8, 1]
learning_rate: 0.00015
epochs: 2500
save_epoch_freq: 1
INFO:root:
----------model----------
INFO:root:PINN(
  (activation): ReLU()
  (loss_function): MSELoss()
  (linears): ModuleList(
    (0): Linear(in_features=2, out_features=8, bias=True)
    (1): Linear(in_features=8, out_features=16, bias=True)
    (2): Linear(in_features=16, out_features=32, bias=True)
    (3): Linear(in_features=32, out_features=64, bias=True)
    (4): Linear(in_features=64, out_features=64, bias=True)
    (5): Linear(in_features=64, out_features=32, bias=True)
    (6): Linear(in_features=32, out_features=16, bias=True)
    (7): Linear(in_features=16, out_features=8, bias=True)
    (8): Linear(in_features=8, out_features=1, bias=True)
  )
)
INFO:root:Number of parameters: 9737
INFO:root:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.00015
    maximize: False
    weight_decay: 0
)
INFO:root:
----------parameters----------
seed: 0
model_path: ./models
output_path: ./outputs
log_path: ./log
layers: [2, 8, 16, 32, 64, 64, 32, 16, 8, 1]
learning_rate: 0.00015
epochs: 2500
save_epoch_freq: 1
INFO:root:
----------model----------
INFO:root:PINN(
  (activation): ReLU()
  (loss_function): MSELoss()
  (linears): ModuleList(
    (0): Linear(in_features=2, out_features=8, bias=True)
    (1): Linear(in_features=8, out_features=16, bias=True)
    (2): Linear(in_features=16, out_features=32, bias=True)
    (3): Linear(in_features=32, out_features=64, bias=True)
    (4): Linear(in_features=64, out_features=64, bias=True)
    (5): Linear(in_features=64, out_features=32, bias=True)
    (6): Linear(in_features=32, out_features=16, bias=True)
    (7): Linear(in_features=16, out_features=8, bias=True)
    (8): Linear(in_features=8, out_features=1, bias=True)
  )
)
INFO:root:Number of parameters: 9737
INFO:root:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.00015
    maximize: False
    weight_decay: 0
)
INFO:root:
----------parameters----------
seed: 0
model_path: ./models
output_path: ./outputs
log_path: ./log
layers: [2, 8, 16, 32, 64, 64, 32, 16, 8, 1]
learning_rate: 0.00015
epochs: 2500
save_epoch_freq: 1
INFO:root:
----------model----------
INFO:root:PINN(
  (activation): ReLU()
  (loss_function): MSELoss()
  (linears): ModuleList(
    (0): Linear(in_features=2, out_features=8, bias=True)
    (1): Linear(in_features=8, out_features=16, bias=True)
    (2): Linear(in_features=16, out_features=32, bias=True)
    (3): Linear(in_features=32, out_features=64, bias=True)
    (4): Linear(in_features=64, out_features=64, bias=True)
    (5): Linear(in_features=64, out_features=32, bias=True)
    (6): Linear(in_features=32, out_features=16, bias=True)
    (7): Linear(in_features=16, out_features=8, bias=True)
    (8): Linear(in_features=8, out_features=1, bias=True)
  )
)
INFO:root:Number of parameters: 9737
INFO:root:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.00015
    maximize: False
    weight_decay: 0
)
INFO:root:
----------parameters----------
seed: 0
model_path: ./models
output_path: ./outputs
log_path: ./log
layers: [2, 8, 16, 32, 64, 64, 32, 16, 8, 1]
learning_rate: 0.00015
epochs: 2500
save_epoch_freq: 1
INFO:root:
----------model----------
INFO:root:PINN(
  (activation): ReLU()
  (loss_function): MSELoss()
  (linears): ModuleList(
    (0): Linear(in_features=2, out_features=8, bias=True)
    (1): Linear(in_features=8, out_features=16, bias=True)
    (2): Linear(in_features=16, out_features=32, bias=True)
    (3): Linear(in_features=32, out_features=64, bias=True)
    (4): Linear(in_features=64, out_features=64, bias=True)
    (5): Linear(in_features=64, out_features=32, bias=True)
    (6): Linear(in_features=32, out_features=16, bias=True)
    (7): Linear(in_features=16, out_features=8, bias=True)
    (8): Linear(in_features=8, out_features=1, bias=True)
  )
)
INFO:root:Number of parameters: 9737
INFO:root:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.00015
    maximize: False
    weight_decay: 0.99
)
INFO:root:
----------parameters----------
seed: 0
model_path: ./models
output_path: ./outputs
log_path: ./log
layers: [2, 8, 16, 32, 64, 64, 32, 16, 8, 1]
learning_rate: 0.0025
epochs: 2500
save_epoch_freq: 1
INFO:root:
----------model----------
INFO:root:PINN(
  (activation): ReLU()
  (loss_function): MSELoss()
  (linears): ModuleList(
    (0): Linear(in_features=2, out_features=8, bias=True)
    (1): Linear(in_features=8, out_features=16, bias=True)
    (2): Linear(in_features=16, out_features=32, bias=True)
    (3): Linear(in_features=32, out_features=64, bias=True)
    (4): Linear(in_features=64, out_features=64, bias=True)
    (5): Linear(in_features=64, out_features=32, bias=True)
    (6): Linear(in_features=32, out_features=16, bias=True)
    (7): Linear(in_features=16, out_features=8, bias=True)
    (8): Linear(in_features=8, out_features=1, bias=True)
  )
)
INFO:root:Number of parameters: 9737
INFO:root:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0025
    maximize: False
    weight_decay: 0.99
)
INFO:root:
----------parameters----------
seed: 0
model_path: ./models
output_path: ./outputs
log_path: ./log
layers: [2, 8, 16, 32, 64, 64, 32, 16, 8, 1]
learning_rate: 0.0025
epochs: 2500
save_epoch_freq: 1
INFO:root:
----------model----------
INFO:root:PINN(
  (activation): ReLU()
  (loss_function): MSELoss()
  (linears): ModuleList(
    (0): Linear(in_features=2, out_features=8, bias=True)
    (1): Linear(in_features=8, out_features=16, bias=True)
    (2): Linear(in_features=16, out_features=32, bias=True)
    (3): Linear(in_features=32, out_features=64, bias=True)
    (4): Linear(in_features=64, out_features=64, bias=True)
    (5): Linear(in_features=64, out_features=32, bias=True)
    (6): Linear(in_features=32, out_features=16, bias=True)
    (7): Linear(in_features=16, out_features=8, bias=True)
    (8): Linear(in_features=8, out_features=1, bias=True)
  )
)
INFO:root:Number of parameters: 9737
INFO:root:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0025
    maximize: False
    weight_decay: 0.99
)
INFO:root:
----------parameters----------
seed: 0
model_path: ./models
output_path: ./outputs
log_path: ./log
layers: [2, 8, 16, 32, 64, 64, 32, 16, 8, 1]
learning_rate: 0.0025
epochs: 2500
save_epoch_freq: 1
INFO:root:
----------model----------
INFO:root:PINN(
  (activation): ReLU()
  (loss_function): MSELoss()
  (linears): ModuleList(
    (0): Linear(in_features=2, out_features=8, bias=True)
    (1): Linear(in_features=8, out_features=16, bias=True)
    (2): Linear(in_features=16, out_features=32, bias=True)
    (3): Linear(in_features=32, out_features=64, bias=True)
    (4): Linear(in_features=64, out_features=64, bias=True)
    (5): Linear(in_features=64, out_features=32, bias=True)
    (6): Linear(in_features=32, out_features=16, bias=True)
    (7): Linear(in_features=16, out_features=8, bias=True)
    (8): Linear(in_features=8, out_features=1, bias=True)
  )
)
INFO:root:Number of parameters: 9737
INFO:root:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0025
    maximize: False
    weight_decay: 0.9999
)
INFO:root:
----------parameters----------
seed: 0
model_path: ./models
output_path: ./outputs
log_path: ./log
layers: [2, 8, 16, 32, 64, 64, 32, 16, 8, 1]
learning_rate: 0.0025
epochs: 2500
save_epoch_freq: 1
INFO:root:
----------model----------
INFO:root:PINN(
  (activation): ReLU()
  (loss_function): MSELoss()
  (linears): ModuleList(
    (0): Linear(in_features=2, out_features=8, bias=True)
    (1): Linear(in_features=8, out_features=16, bias=True)
    (2): Linear(in_features=16, out_features=32, bias=True)
    (3): Linear(in_features=32, out_features=64, bias=True)
    (4): Linear(in_features=64, out_features=64, bias=True)
    (5): Linear(in_features=64, out_features=32, bias=True)
    (6): Linear(in_features=32, out_features=16, bias=True)
    (7): Linear(in_features=16, out_features=8, bias=True)
    (8): Linear(in_features=8, out_features=1, bias=True)
  )
)
INFO:root:Number of parameters: 9737
INFO:root:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0025
    maximize: False
    weight_decay: 0
)
INFO:root:
----------parameters----------
seed: 0
model_path: ./models
output_path: ./outputs
log_path: ./log
layers: [2, 8, 16, 32, 64, 64, 32, 16, 8, 1]
learning_rate: 0.0025
epochs: 2500
save_epoch_freq: 1
INFO:root:
----------model----------
INFO:root:PINN(
  (activation): ReLU()
  (loss_function): MSELoss()
  (linears): ModuleList(
    (0): Linear(in_features=2, out_features=8, bias=True)
    (1): Linear(in_features=8, out_features=16, bias=True)
    (2): Linear(in_features=16, out_features=32, bias=True)
    (3): Linear(in_features=32, out_features=64, bias=True)
    (4): Linear(in_features=64, out_features=64, bias=True)
    (5): Linear(in_features=64, out_features=32, bias=True)
    (6): Linear(in_features=32, out_features=16, bias=True)
    (7): Linear(in_features=16, out_features=8, bias=True)
    (8): Linear(in_features=8, out_features=1, bias=True)
  )
)
INFO:root:Number of parameters: 9737
INFO:root:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0025
    maximize: False
    weight_decay: 0.01
)
INFO:root:
----------parameters----------
seed: 0
model_path: ./models
output_path: ./outputs
log_path: ./log
layers: [2, 8, 16, 32, 64, 64, 32, 16, 8, 1]
learning_rate: 0.0025
epochs: 2500
save_epoch_freq: 1
INFO:root:
----------model----------
INFO:root:PINN(
  (activation): ReLU()
  (loss_function): MSELoss()
  (linears): ModuleList(
    (0): Linear(in_features=2, out_features=8, bias=True)
    (1): Linear(in_features=8, out_features=16, bias=True)
    (2): Linear(in_features=16, out_features=32, bias=True)
    (3): Linear(in_features=32, out_features=64, bias=True)
    (4): Linear(in_features=64, out_features=64, bias=True)
    (5): Linear(in_features=64, out_features=32, bias=True)
    (6): Linear(in_features=32, out_features=16, bias=True)
    (7): Linear(in_features=16, out_features=8, bias=True)
    (8): Linear(in_features=8, out_features=1, bias=True)
  )
)
INFO:root:Number of parameters: 9737
INFO:root:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0025
    maximize: False
    weight_decay: 1e-05
)
INFO:root:
----------parameters----------
seed: 1234
model_path: ./models
output_path: ./outputs
log_path: ./log
layers: [2, 8, 16, 32, 64, 64, 32, 16, 8, 1]
learning_rate: 0.0025
epochs: 2500
save_epoch_freq: 1
INFO:root:
----------model----------
INFO:root:PINN(
  (activation): ReLU()
  (loss_function): MSELoss()
  (linears): ModuleList(
    (0): Linear(in_features=2, out_features=8, bias=True)
    (1): Linear(in_features=8, out_features=16, bias=True)
    (2): Linear(in_features=16, out_features=32, bias=True)
    (3): Linear(in_features=32, out_features=64, bias=True)
    (4): Linear(in_features=64, out_features=64, bias=True)
    (5): Linear(in_features=64, out_features=32, bias=True)
    (6): Linear(in_features=32, out_features=16, bias=True)
    (7): Linear(in_features=16, out_features=8, bias=True)
    (8): Linear(in_features=8, out_features=1, bias=True)
  )
)
INFO:root:Number of parameters: 9737
INFO:root:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0025
    maximize: False
    weight_decay: 1e-05
)
INFO:root:
----------parameters----------
seed: 1234
model_path: ./models
output_path: ./outputs
log_path: ./log
layers: [2, 8, 16, 32, 64, 64, 32, 16, 8, 1]
learning_rate: 0.00075
epochs: 2500
save_epoch_freq: 1
INFO:root:
----------model----------
INFO:root:PINN(
  (activation): ReLU()
  (loss_function): MSELoss()
  (linears): ModuleList(
    (0): Linear(in_features=2, out_features=8, bias=True)
    (1): Linear(in_features=8, out_features=16, bias=True)
    (2): Linear(in_features=16, out_features=32, bias=True)
    (3): Linear(in_features=32, out_features=64, bias=True)
    (4): Linear(in_features=64, out_features=64, bias=True)
    (5): Linear(in_features=64, out_features=32, bias=True)
    (6): Linear(in_features=32, out_features=16, bias=True)
    (7): Linear(in_features=16, out_features=8, bias=True)
    (8): Linear(in_features=8, out_features=1, bias=True)
  )
)
INFO:root:Number of parameters: 9737
INFO:root:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.00075
    maximize: False
    weight_decay: 1e-05
)
INFO:root:
----------parameters----------
seed: 1234
model_path: ./models
output_path: ./outputs
log_path: ./log
layers: [2, 8, 16, 32, 64, 64, 32, 16, 8, 1]
learning_rate: 0.00075
epochs: 2500
save_epoch_freq: 1
INFO:root:
----------model----------
INFO:root:PINN(
  (activation): ReLU()
  (loss_function): MSELoss()
  (linears): ModuleList(
    (0): Linear(in_features=2, out_features=8, bias=True)
    (1): Linear(in_features=8, out_features=16, bias=True)
    (2): Linear(in_features=16, out_features=32, bias=True)
    (3): Linear(in_features=32, out_features=64, bias=True)
    (4): Linear(in_features=64, out_features=64, bias=True)
    (5): Linear(in_features=64, out_features=32, bias=True)
    (6): Linear(in_features=32, out_features=16, bias=True)
    (7): Linear(in_features=16, out_features=8, bias=True)
    (8): Linear(in_features=8, out_features=1, bias=True)
  )
)
INFO:root:Number of parameters: 9737
INFO:root:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.00075
    maximize: False
    weight_decay: 0.0
)
INFO:root:
----------parameters----------
seed: 1234
model_path: ./models
output_path: ./outputs
log_path: ./log
layers: [2, 8, 16, 32, 64, 128, 64, 32, 16, 8, 1]
learning_rate: 0.00075
epochs: 2500
save_epoch_freq: 1
INFO:root:
----------model----------
INFO:root:PINN(
  (activation): ReLU()
  (loss_function): MSELoss()
  (linears): ModuleList(
    (0): Linear(in_features=2, out_features=8, bias=True)
    (1): Linear(in_features=8, out_features=16, bias=True)
    (2): Linear(in_features=16, out_features=32, bias=True)
    (3): Linear(in_features=32, out_features=64, bias=True)
    (4): Linear(in_features=64, out_features=128, bias=True)
    (5): Linear(in_features=128, out_features=64, bias=True)
    (6): Linear(in_features=64, out_features=32, bias=True)
    (7): Linear(in_features=32, out_features=16, bias=True)
    (8): Linear(in_features=16, out_features=8, bias=True)
    (9): Linear(in_features=8, out_features=1, bias=True)
  )
)
INFO:root:Number of parameters: 22153
INFO:root:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.00075
    maximize: False
    weight_decay: 0.0
)
INFO:root:
----------parameters----------
seed: 1234
model_path: ./models
output_path: ./outputs
log_path: ./log
layers: [2, 8, 16, 32, 64, 128, 64, 32, 16, 8, 1]
learning_rate: 1.5e-05
epochs: 2500
save_epoch_freq: 1
INFO:root:
----------model----------
INFO:root:PINN(
  (activation): ReLU()
  (loss_function): MSELoss()
  (linears): ModuleList(
    (0): Linear(in_features=2, out_features=8, bias=True)
    (1): Linear(in_features=8, out_features=16, bias=True)
    (2): Linear(in_features=16, out_features=32, bias=True)
    (3): Linear(in_features=32, out_features=64, bias=True)
    (4): Linear(in_features=64, out_features=128, bias=True)
    (5): Linear(in_features=128, out_features=64, bias=True)
    (6): Linear(in_features=64, out_features=32, bias=True)
    (7): Linear(in_features=32, out_features=16, bias=True)
    (8): Linear(in_features=16, out_features=8, bias=True)
    (9): Linear(in_features=8, out_features=1, bias=True)
  )
)
INFO:root:Number of parameters: 22153
INFO:root:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.5e-05
    maximize: False
    weight_decay: 0.0
)
INFO:root:
----------parameters----------
seed: 1234
model_path: ./models
output_path: ./outputs
log_path: ./log
layers: [2, 8, 16, 32, 64, 128, 64, 32, 16, 8, 1]
learning_rate: 1.5e-05
epochs: 2500
save_epoch_freq: 1
INFO:root:
----------model----------
INFO:root:PINN(
  (activation): ReLU()
  (loss_function): MSELoss()
  (linears): ModuleList(
    (0): Linear(in_features=2, out_features=8, bias=True)
    (1): Linear(in_features=8, out_features=16, bias=True)
    (2): Linear(in_features=16, out_features=32, bias=True)
    (3): Linear(in_features=32, out_features=64, bias=True)
    (4): Linear(in_features=64, out_features=128, bias=True)
    (5): Linear(in_features=128, out_features=64, bias=True)
    (6): Linear(in_features=64, out_features=32, bias=True)
    (7): Linear(in_features=32, out_features=16, bias=True)
    (8): Linear(in_features=16, out_features=8, bias=True)
    (9): Linear(in_features=8, out_features=1, bias=True)
  )
)
INFO:root:Number of parameters: 22153
INFO:root:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.5e-05
    maximize: False
    weight_decay: 0.0
)
INFO:root:
----------parameters----------
seed: 1234
model_path: ./models
output_path: ./outputs
log_path: ./log
layers: [2, 8, 16, 32, 64, 128, 64, 32, 16, 8, 1]
learning_rate: 1.5e-05
epochs: 3500
save_epoch_freq: 1
INFO:root:
----------model----------
INFO:root:PINN(
  (activation): ReLU()
  (loss_function): MSELoss()
  (linears): ModuleList(
    (0): Linear(in_features=2, out_features=8, bias=True)
    (1): Linear(in_features=8, out_features=16, bias=True)
    (2): Linear(in_features=16, out_features=32, bias=True)
    (3): Linear(in_features=32, out_features=64, bias=True)
    (4): Linear(in_features=64, out_features=128, bias=True)
    (5): Linear(in_features=128, out_features=64, bias=True)
    (6): Linear(in_features=64, out_features=32, bias=True)
    (7): Linear(in_features=32, out_features=16, bias=True)
    (8): Linear(in_features=16, out_features=8, bias=True)
    (9): Linear(in_features=8, out_features=1, bias=True)
  )
)
INFO:root:Number of parameters: 22153
INFO:root:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.5e-05
    maximize: False
    weight_decay: 0.0
)
INFO:root:
----------parameters----------
seed: 1234
model_path: ./models
output_path: ./outputs
log_path: ./log
layers: [2, 8, 16, 32, 64, 128, 256, 128, 64, 32, 16, 8, 1]
learning_rate: 1.5e-05
epochs: 3500
save_epoch_freq: 1
INFO:root:
----------model----------
INFO:root:PINN(
  (activation): ReLU()
  (loss_function): MSELoss()
  (linears): ModuleList(
    (0): Linear(in_features=2, out_features=8, bias=True)
    (1): Linear(in_features=8, out_features=16, bias=True)
    (2): Linear(in_features=16, out_features=32, bias=True)
    (3): Linear(in_features=32, out_features=64, bias=True)
    (4): Linear(in_features=64, out_features=128, bias=True)
    (5): Linear(in_features=128, out_features=256, bias=True)
    (6): Linear(in_features=256, out_features=128, bias=True)
    (7): Linear(in_features=128, out_features=64, bias=True)
    (8): Linear(in_features=64, out_features=32, bias=True)
    (9): Linear(in_features=32, out_features=16, bias=True)
    (10): Linear(in_features=16, out_features=8, bias=True)
    (11): Linear(in_features=8, out_features=1, bias=True)
  )
)
INFO:root:Number of parameters: 88073
INFO:root:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.5e-05
    maximize: False
    weight_decay: 0.0
)
INFO:root:
----------parameters----------
seed: 1234
model_path: ./models
output_path: ./outputs
log_path: ./log
layers: [2, 8, 16, 32, 64, 128, 256, 128, 64, 32, 16, 8, 1]
learning_rate: 1.5e-05
epochs: 4500
save_epoch_freq: 1
INFO:root:
----------model----------
INFO:root:PINN(
  (activation): Tanh()
  (loss_function): MSELoss()
  (linears): ModuleList(
    (0): Linear(in_features=2, out_features=8, bias=True)
    (1): Linear(in_features=8, out_features=16, bias=True)
    (2): Linear(in_features=16, out_features=32, bias=True)
    (3): Linear(in_features=32, out_features=64, bias=True)
    (4): Linear(in_features=64, out_features=128, bias=True)
    (5): Linear(in_features=128, out_features=256, bias=True)
    (6): Linear(in_features=256, out_features=128, bias=True)
    (7): Linear(in_features=128, out_features=64, bias=True)
    (8): Linear(in_features=64, out_features=32, bias=True)
    (9): Linear(in_features=32, out_features=16, bias=True)
    (10): Linear(in_features=16, out_features=8, bias=True)
    (11): Linear(in_features=8, out_features=1, bias=True)
  )
)
INFO:root:Number of parameters: 88073
INFO:root:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.5e-05
    maximize: False
    weight_decay: 0.0
)
INFO:root:
----------parameters----------
seed: 1234
model_path: ./models
output_path: ./outputs
log_path: ./log
layers: [2, 8, 16, 32, 64, 128, 256, 128, 64, 32, 16, 8, 1]
learning_rate: 1.5e-05
epochs: 4500
save_epoch_freq: 1
INFO:root:
----------model----------
INFO:root:PINN(
  (activation): Tanh()
  (loss_function): MSELoss()
  (linears): ModuleList(
    (0): Linear(in_features=2, out_features=8, bias=True)
    (1): Linear(in_features=8, out_features=16, bias=True)
    (2): Linear(in_features=16, out_features=32, bias=True)
    (3): Linear(in_features=32, out_features=64, bias=True)
    (4): Linear(in_features=64, out_features=128, bias=True)
    (5): Linear(in_features=128, out_features=256, bias=True)
    (6): Linear(in_features=256, out_features=128, bias=True)
    (7): Linear(in_features=128, out_features=64, bias=True)
    (8): Linear(in_features=64, out_features=32, bias=True)
    (9): Linear(in_features=32, out_features=16, bias=True)
    (10): Linear(in_features=16, out_features=8, bias=True)
    (11): Linear(in_features=8, out_features=1, bias=True)
  )
)
INFO:root:Number of parameters: 88073
INFO:root:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.5e-05
    maximize: False
    weight_decay: 0.0
)
INFO:root:
----------parameters----------
seed: 1234
model_path: ./models
output_path: ./outputs
log_path: ./log
layers: [2, 8, 16, 32, 64, 128, 256, 512, 256, 128, 64, 32, 16, 8, 1]
learning_rate: 1.5e-05
epochs: 4500
save_epoch_freq: 1
INFO:root:
----------model----------
INFO:root:PINN(
  (activation): Tanh()
  (loss_function): MSELoss()
  (linears): ModuleList(
    (0): Linear(in_features=2, out_features=8, bias=True)
    (1): Linear(in_features=8, out_features=16, bias=True)
    (2): Linear(in_features=16, out_features=32, bias=True)
    (3): Linear(in_features=32, out_features=64, bias=True)
    (4): Linear(in_features=64, out_features=128, bias=True)
    (5): Linear(in_features=128, out_features=256, bias=True)
    (6): Linear(in_features=256, out_features=512, bias=True)
    (7): Linear(in_features=512, out_features=256, bias=True)
    (8): Linear(in_features=256, out_features=128, bias=True)
    (9): Linear(in_features=128, out_features=64, bias=True)
    (10): Linear(in_features=64, out_features=32, bias=True)
    (11): Linear(in_features=32, out_features=16, bias=True)
    (12): Linear(in_features=16, out_features=8, bias=True)
    (13): Linear(in_features=8, out_features=1, bias=True)
  )
)
INFO:root:Number of parameters: 350985
INFO:root:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.5e-05
    maximize: False
    weight_decay: 0.0
)
INFO:root:
----------parameters----------
seed: 1234
model_path: ./models
output_path: ./outputs
log_path: ./log
layers: [2, 8, 16, 32, 64, 128, 256, 512, 256, 128, 64, 32, 16, 8, 1]
learning_rate: 1.5e-05
epochs: 5500
save_epoch_freq: 1
INFO:root:
----------model----------
INFO:root:PINN(
  (activation): Tanh()
  (loss_function): MSELoss()
  (linears): ModuleList(
    (0): Linear(in_features=2, out_features=8, bias=True)
    (1): Linear(in_features=8, out_features=16, bias=True)
    (2): Linear(in_features=16, out_features=32, bias=True)
    (3): Linear(in_features=32, out_features=64, bias=True)
    (4): Linear(in_features=64, out_features=128, bias=True)
    (5): Linear(in_features=128, out_features=256, bias=True)
    (6): Linear(in_features=256, out_features=512, bias=True)
    (7): Linear(in_features=512, out_features=256, bias=True)
    (8): Linear(in_features=256, out_features=128, bias=True)
    (9): Linear(in_features=128, out_features=64, bias=True)
    (10): Linear(in_features=64, out_features=32, bias=True)
    (11): Linear(in_features=32, out_features=16, bias=True)
    (12): Linear(in_features=16, out_features=8, bias=True)
    (13): Linear(in_features=8, out_features=1, bias=True)
  )
)
INFO:root:Number of parameters: 350985
INFO:root:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.5e-05
    maximize: False
    weight_decay: 0.0
)
INFO:root:
----------parameters----------
seed: 1234
model_path: ./models
output_path: ./outputs
log_path: ./log
layers: [2, 8, 16, 32, 64, 128, 256, 512, 256, 128, 64, 32, 16, 8, 1]
learning_rate: 1.5e-05
epochs: 2500
save_epoch_freq: 1
INFO:root:
----------model----------
INFO:root:PINN(
  (activation): Tanh()
  (loss_function): MSELoss()
  (linears): ModuleList(
    (0): Linear(in_features=2, out_features=8, bias=True)
    (1): Linear(in_features=8, out_features=16, bias=True)
    (2): Linear(in_features=16, out_features=32, bias=True)
    (3): Linear(in_features=32, out_features=64, bias=True)
    (4): Linear(in_features=64, out_features=128, bias=True)
    (5): Linear(in_features=128, out_features=256, bias=True)
    (6): Linear(in_features=256, out_features=512, bias=True)
    (7): Linear(in_features=512, out_features=256, bias=True)
    (8): Linear(in_features=256, out_features=128, bias=True)
    (9): Linear(in_features=128, out_features=64, bias=True)
    (10): Linear(in_features=64, out_features=32, bias=True)
    (11): Linear(in_features=32, out_features=16, bias=True)
    (12): Linear(in_features=16, out_features=8, bias=True)
    (13): Linear(in_features=8, out_features=1, bias=True)
  )
)
INFO:root:Number of parameters: 350985
INFO:root:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.5e-05
    maximize: False
    weight_decay: 0.0
)
INFO:root:
----------parameters----------
seed: 1234
model_path: ./models
output_path: ./outputs
log_path: ./log
layers: [2, 8, 16, 32, 64, 128, 256, 512, 1024, 512, 256, 128, 64, 32, 16, 8, 1]
learning_rate: 1.5e-05
epochs: 3500
save_epoch_freq: 1
INFO:root:
----------model----------
INFO:root:PINN(
  (activation): Tanh()
  (loss_function): MSELoss()
  (linears): ModuleList(
    (0): Linear(in_features=2, out_features=8, bias=True)
    (1): Linear(in_features=8, out_features=16, bias=True)
    (2): Linear(in_features=16, out_features=32, bias=True)
    (3): Linear(in_features=32, out_features=64, bias=True)
    (4): Linear(in_features=64, out_features=128, bias=True)
    (5): Linear(in_features=128, out_features=256, bias=True)
    (6): Linear(in_features=256, out_features=512, bias=True)
    (7): Linear(in_features=512, out_features=1024, bias=True)
    (8): Linear(in_features=1024, out_features=512, bias=True)
    (9): Linear(in_features=512, out_features=256, bias=True)
    (10): Linear(in_features=256, out_features=128, bias=True)
    (11): Linear(in_features=128, out_features=64, bias=True)
    (12): Linear(in_features=64, out_features=32, bias=True)
    (13): Linear(in_features=32, out_features=16, bias=True)
    (14): Linear(in_features=16, out_features=8, bias=True)
    (15): Linear(in_features=8, out_features=1, bias=True)
  )
)
INFO:root:Number of parameters: 1401097
INFO:root:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.5e-05
    maximize: False
    weight_decay: 0.0
)
INFO:root:
----------parameters----------
seed: 1234
model_path: ./models
output_path: ./outputs
log_path: ./log
layers: [2, 8, 16, 32, 64, 128, 256, 512, 1024, 512, 256, 128, 64, 32, 16, 8, 1]
learning_rate: 1.5e-05
epochs: 3500
save_epoch_freq: 1
INFO:root:
----------model----------
INFO:root:PINN(
  (activation): Tanh()
  (loss_function): MSELoss()
  (linears): ModuleList(
    (0): Linear(in_features=2, out_features=8, bias=True)
    (1): Linear(in_features=8, out_features=16, bias=True)
    (2): Linear(in_features=16, out_features=32, bias=True)
    (3): Linear(in_features=32, out_features=64, bias=True)
    (4): Linear(in_features=64, out_features=128, bias=True)
    (5): Linear(in_features=128, out_features=256, bias=True)
    (6): Linear(in_features=256, out_features=512, bias=True)
    (7): Linear(in_features=512, out_features=1024, bias=True)
    (8): Linear(in_features=1024, out_features=512, bias=True)
    (9): Linear(in_features=512, out_features=256, bias=True)
    (10): Linear(in_features=256, out_features=128, bias=True)
    (11): Linear(in_features=128, out_features=64, bias=True)
    (12): Linear(in_features=64, out_features=32, bias=True)
    (13): Linear(in_features=32, out_features=16, bias=True)
    (14): Linear(in_features=16, out_features=8, bias=True)
    (15): Linear(in_features=8, out_features=1, bias=True)
  )
)
INFO:root:Number of parameters: 1401097
INFO:root:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.5e-05
    maximize: False
    weight_decay: 0.0
)
INFO:root:
----------parameters----------
seed: 1234
model_path: ./models
output_path: ./outputs
log_path: ./log
layers: [2, 8, 16, 32, 64, 128, 256, 512, 1024, 512, 256, 128, 64, 32, 16, 8, 1]
learning_rate: 1.5e-05
epochs: 3500
save_epoch_freq: 1
INFO:root:
----------model----------
INFO:root:PINN(
  (activation): Tanh()
  (loss_function): MSELoss()
  (linears): ModuleList(
    (0): Linear(in_features=2, out_features=8, bias=True)
    (1): Linear(in_features=8, out_features=16, bias=True)
    (2): Linear(in_features=16, out_features=32, bias=True)
    (3): Linear(in_features=32, out_features=64, bias=True)
    (4): Linear(in_features=64, out_features=128, bias=True)
    (5): Linear(in_features=128, out_features=256, bias=True)
    (6): Linear(in_features=256, out_features=512, bias=True)
    (7): Linear(in_features=512, out_features=1024, bias=True)
    (8): Linear(in_features=1024, out_features=512, bias=True)
    (9): Linear(in_features=512, out_features=256, bias=True)
    (10): Linear(in_features=256, out_features=128, bias=True)
    (11): Linear(in_features=128, out_features=64, bias=True)
    (12): Linear(in_features=64, out_features=32, bias=True)
    (13): Linear(in_features=32, out_features=16, bias=True)
    (14): Linear(in_features=16, out_features=8, bias=True)
    (15): Linear(in_features=8, out_features=1, bias=True)
  )
)
INFO:root:Number of parameters: 1401097
INFO:root:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.5e-05
    maximize: False
    weight_decay: 0.0
)
INFO:root:
----------parameters----------
seed: 1234
model_path: ./models
output_path: ./outputs
log_path: ./log
layers: [2, 8, 16, 32, 64, 128, 256, 512, 1024, 512, 256, 128, 64, 32, 16, 8, 1]
learning_rate: 1.5e-05
epochs: 3500
save_epoch_freq: 1
INFO:root:
----------model----------
INFO:root:PINN(
  (activation): Tanh()
  (loss_function): MSELoss()
  (linears): ModuleList(
    (0): Linear(in_features=2, out_features=8, bias=True)
    (1): Linear(in_features=8, out_features=16, bias=True)
    (2): Linear(in_features=16, out_features=32, bias=True)
    (3): Linear(in_features=32, out_features=64, bias=True)
    (4): Linear(in_features=64, out_features=128, bias=True)
    (5): Linear(in_features=128, out_features=256, bias=True)
    (6): Linear(in_features=256, out_features=512, bias=True)
    (7): Linear(in_features=512, out_features=1024, bias=True)
    (8): Linear(in_features=1024, out_features=512, bias=True)
    (9): Linear(in_features=512, out_features=256, bias=True)
    (10): Linear(in_features=256, out_features=128, bias=True)
    (11): Linear(in_features=128, out_features=64, bias=True)
    (12): Linear(in_features=64, out_features=32, bias=True)
    (13): Linear(in_features=32, out_features=16, bias=True)
    (14): Linear(in_features=16, out_features=8, bias=True)
    (15): Linear(in_features=8, out_features=1, bias=True)
  )
)
INFO:root:Number of parameters: 1401097
INFO:root:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1.5e-05
    maximize: False
    weight_decay: 0.0
)
INFO:root:
----------parameters----------
seed: 1234
model_path: ./models
output_path: ./outputs
log_path: ./log
layers: [2, 8, 16, 32, 64, 128, 256, 512, 1024, 512, 256, 128, 64, 32, 16, 8, 1]
learning_rate: 0.0015
epochs: 1000
save_epoch_freq: 1
INFO:root:
----------model----------
INFO:root:PINN(
  (activation): Tanh()
  (loss_function): MSELoss()
  (linears): ModuleList(
    (0): Linear(in_features=2, out_features=8, bias=True)
    (1): Linear(in_features=8, out_features=16, bias=True)
    (2): Linear(in_features=16, out_features=32, bias=True)
    (3): Linear(in_features=32, out_features=64, bias=True)
    (4): Linear(in_features=64, out_features=128, bias=True)
    (5): Linear(in_features=128, out_features=256, bias=True)
    (6): Linear(in_features=256, out_features=512, bias=True)
    (7): Linear(in_features=512, out_features=1024, bias=True)
    (8): Linear(in_features=1024, out_features=512, bias=True)
    (9): Linear(in_features=512, out_features=256, bias=True)
    (10): Linear(in_features=256, out_features=128, bias=True)
    (11): Linear(in_features=128, out_features=64, bias=True)
    (12): Linear(in_features=64, out_features=32, bias=True)
    (13): Linear(in_features=32, out_features=16, bias=True)
    (14): Linear(in_features=16, out_features=8, bias=True)
    (15): Linear(in_features=8, out_features=1, bias=True)
  )
)
INFO:root:Number of parameters: 1401097
INFO:root:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0015
    maximize: False
    weight_decay: 0.0
)
INFO:root:
----------parameters----------
seed: 1234
model_path: ./models
output_path: ./outputs
log_path: ./log
layers: [2, 8, 16, 32, 64, 128, 256, 512, 1024, 512, 256, 128, 64, 32, 16, 8, 1]
learning_rate: 0.0015
epochs: 1000
save_epoch_freq: 1
INFO:root:
----------model----------
INFO:root:PINN(
  (activation): Tanh()
  (loss_function): MSELoss()
  (linears): ModuleList(
    (0): Linear(in_features=2, out_features=8, bias=True)
    (1): Linear(in_features=8, out_features=16, bias=True)
    (2): Linear(in_features=16, out_features=32, bias=True)
    (3): Linear(in_features=32, out_features=64, bias=True)
    (4): Linear(in_features=64, out_features=128, bias=True)
    (5): Linear(in_features=128, out_features=256, bias=True)
    (6): Linear(in_features=256, out_features=512, bias=True)
    (7): Linear(in_features=512, out_features=1024, bias=True)
    (8): Linear(in_features=1024, out_features=512, bias=True)
    (9): Linear(in_features=512, out_features=256, bias=True)
    (10): Linear(in_features=256, out_features=128, bias=True)
    (11): Linear(in_features=128, out_features=64, bias=True)
    (12): Linear(in_features=64, out_features=32, bias=True)
    (13): Linear(in_features=32, out_features=16, bias=True)
    (14): Linear(in_features=16, out_features=8, bias=True)
    (15): Linear(in_features=8, out_features=1, bias=True)
  )
)
INFO:root:Number of parameters: 1401097
INFO:root:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0015
    maximize: False
    weight_decay: 0.0
)
INFO:root:
----------parameters----------
seed: 0
model_path: ./models
output_path: ./outputs
log_path: ./log
layers: [2, 8, 16, 32, 64, 128, 256, 512, 1024, 512, 256, 128, 64, 32, 16, 8, 1]
learning_rate: 0.0015
epochs: 1000
save_epoch_freq: 1
INFO:root:
----------model----------
INFO:root:PINN(
  (activation): Tanh()
  (loss_function): MSELoss()
  (linears): ModuleList(
    (0): Linear(in_features=2, out_features=8, bias=True)
    (1): Linear(in_features=8, out_features=16, bias=True)
    (2): Linear(in_features=16, out_features=32, bias=True)
    (3): Linear(in_features=32, out_features=64, bias=True)
    (4): Linear(in_features=64, out_features=128, bias=True)
    (5): Linear(in_features=128, out_features=256, bias=True)
    (6): Linear(in_features=256, out_features=512, bias=True)
    (7): Linear(in_features=512, out_features=1024, bias=True)
    (8): Linear(in_features=1024, out_features=512, bias=True)
    (9): Linear(in_features=512, out_features=256, bias=True)
    (10): Linear(in_features=256, out_features=128, bias=True)
    (11): Linear(in_features=128, out_features=64, bias=True)
    (12): Linear(in_features=64, out_features=32, bias=True)
    (13): Linear(in_features=32, out_features=16, bias=True)
    (14): Linear(in_features=16, out_features=8, bias=True)
    (15): Linear(in_features=8, out_features=1, bias=True)
  )
)
INFO:root:Number of parameters: 1401097
INFO:root:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0015
    maximize: False
    weight_decay: 0.0
)
INFO:root:
----------parameters----------
seed: 0
model_path: ./models
output_path: ./outputs
log_path: ./log
layers: [2, 8, 16, 32, 64, 128, 256, 512, 512, 256, 128, 64, 32, 16, 8, 1]
learning_rate: 0.0015
epochs: 1000
save_epoch_freq: 1
INFO:root:
----------model----------
INFO:root:PINN(
  (activation): Tanh()
  (loss_function): MSELoss()
  (linears): ModuleList(
    (0): Linear(in_features=2, out_features=8, bias=True)
    (1): Linear(in_features=8, out_features=16, bias=True)
    (2): Linear(in_features=16, out_features=32, bias=True)
    (3): Linear(in_features=32, out_features=64, bias=True)
    (4): Linear(in_features=64, out_features=128, bias=True)
    (5): Linear(in_features=128, out_features=256, bias=True)
    (6): Linear(in_features=256, out_features=512, bias=True)
    (7): Linear(in_features=512, out_features=512, bias=True)
    (8): Linear(in_features=512, out_features=256, bias=True)
    (9): Linear(in_features=256, out_features=128, bias=True)
    (10): Linear(in_features=128, out_features=64, bias=True)
    (11): Linear(in_features=64, out_features=32, bias=True)
    (12): Linear(in_features=32, out_features=16, bias=True)
    (13): Linear(in_features=16, out_features=8, bias=True)
    (14): Linear(in_features=8, out_features=1, bias=True)
  )
)
INFO:root:Number of parameters: 613641
INFO:root:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0015
    maximize: False
    weight_decay: 0.0
)
INFO:root:
----------parameters----------
seed: 0
model_path: ./models
output_path: ./outputs
log_path: ./log
layers: [2, 8, 16, 32, 64, 128, 256, 512, 512, 256, 128, 64, 32, 16, 8, 1]
learning_rate: 0.0015
epochs: 1000
save_epoch_freq: 1
INFO:root:
----------model----------
INFO:root:PINN(
  (activation): Tanh()
  (loss_function): MSELoss()
  (linears): ModuleList(
    (0): Linear(in_features=2, out_features=8, bias=True)
    (1): Linear(in_features=8, out_features=16, bias=True)
    (2): Linear(in_features=16, out_features=32, bias=True)
    (3): Linear(in_features=32, out_features=64, bias=True)
    (4): Linear(in_features=64, out_features=128, bias=True)
    (5): Linear(in_features=128, out_features=256, bias=True)
    (6): Linear(in_features=256, out_features=512, bias=True)
    (7): Linear(in_features=512, out_features=512, bias=True)
    (8): Linear(in_features=512, out_features=256, bias=True)
    (9): Linear(in_features=256, out_features=128, bias=True)
    (10): Linear(in_features=128, out_features=64, bias=True)
    (11): Linear(in_features=64, out_features=32, bias=True)
    (12): Linear(in_features=32, out_features=16, bias=True)
    (13): Linear(in_features=16, out_features=8, bias=True)
    (14): Linear(in_features=8, out_features=1, bias=True)
  )
)
INFO:root:Number of parameters: 613641
INFO:root:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0015
    maximize: False
    weight_decay: 0.0
)
INFO:root:
----------parameters----------
seed: 0
model_path: ./models
output_path: ./outputs
log_path: ./log
layers: [2, 8, 16, 32, 64, 128, 256, 512, 512, 256, 128, 64, 32, 16, 8, 1]
learning_rate: 0.015
epochs: 1000
save_epoch_freq: 1
INFO:root:
----------model----------
INFO:root:PINN(
  (activation): Tanh()
  (loss_function): MSELoss()
  (linears): ModuleList(
    (0): Linear(in_features=2, out_features=8, bias=True)
    (1): Linear(in_features=8, out_features=16, bias=True)
    (2): Linear(in_features=16, out_features=32, bias=True)
    (3): Linear(in_features=32, out_features=64, bias=True)
    (4): Linear(in_features=64, out_features=128, bias=True)
    (5): Linear(in_features=128, out_features=256, bias=True)
    (6): Linear(in_features=256, out_features=512, bias=True)
    (7): Linear(in_features=512, out_features=512, bias=True)
    (8): Linear(in_features=512, out_features=256, bias=True)
    (9): Linear(in_features=256, out_features=128, bias=True)
    (10): Linear(in_features=128, out_features=64, bias=True)
    (11): Linear(in_features=64, out_features=32, bias=True)
    (12): Linear(in_features=32, out_features=16, bias=True)
    (13): Linear(in_features=16, out_features=8, bias=True)
    (14): Linear(in_features=8, out_features=1, bias=True)
  )
)
INFO:root:Number of parameters: 613641
INFO:root:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.015
    maximize: False
    weight_decay: 0.0
)
INFO:root:
----------parameters----------
seed: 0
model_path: ./models
output_path: ./outputs
log_path: ./log
layers: [2, 8, 16, 32, 64, 128, 256, 512, 512, 256, 128, 64, 32, 16, 8, 1]
learning_rate: 0.0015
epochs: 1000
save_epoch_freq: 1
INFO:root:
----------model----------
INFO:root:PINN(
  (activation): Tanh()
  (loss_function): MSELoss()
  (linears): ModuleList(
    (0): Linear(in_features=2, out_features=8, bias=True)
    (1): Linear(in_features=8, out_features=16, bias=True)
    (2): Linear(in_features=16, out_features=32, bias=True)
    (3): Linear(in_features=32, out_features=64, bias=True)
    (4): Linear(in_features=64, out_features=128, bias=True)
    (5): Linear(in_features=128, out_features=256, bias=True)
    (6): Linear(in_features=256, out_features=512, bias=True)
    (7): Linear(in_features=512, out_features=512, bias=True)
    (8): Linear(in_features=512, out_features=256, bias=True)
    (9): Linear(in_features=256, out_features=128, bias=True)
    (10): Linear(in_features=128, out_features=64, bias=True)
    (11): Linear(in_features=64, out_features=32, bias=True)
    (12): Linear(in_features=32, out_features=16, bias=True)
    (13): Linear(in_features=16, out_features=8, bias=True)
    (14): Linear(in_features=8, out_features=1, bias=True)
  )
)
INFO:root:Number of parameters: 613641
INFO:root:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0015
    maximize: False
    weight_decay: 0.0
)
INFO:root:
----------parameters----------
seed: 0
model_path: ./models
output_path: ./outputs
log_path: ./log
layers: [2, 8, 16, 32, 64, 128, 256, 512, 512, 256, 128, 64, 32, 16, 8, 1]
learning_rate: 0.0015
epochs: 1000
save_epoch_freq: 1
INFO:root:
----------parameters----------
seed: 0
model_path: ./models
output_path: ./outputs
log_path: ./log
layers: [2, 8, 16, 32, 64, 128, 256, 512, 512, 256, 128, 64, 32, 16, 8, 1]
learning_rate: 0.00015
epochs: 2000
save_epoch_freq: 1
INFO:root:
----------model----------
INFO:root:PINN(
  (activation): Tanh()
  (loss_function): MSELoss()
  (linears): ModuleList(
    (0): Linear(in_features=2, out_features=8, bias=True)
    (1): Linear(in_features=8, out_features=16, bias=True)
    (2): Linear(in_features=16, out_features=32, bias=True)
    (3): Linear(in_features=32, out_features=64, bias=True)
    (4): Linear(in_features=64, out_features=128, bias=True)
    (5): Linear(in_features=128, out_features=256, bias=True)
    (6): Linear(in_features=256, out_features=512, bias=True)
    (7): Linear(in_features=512, out_features=512, bias=True)
    (8): Linear(in_features=512, out_features=256, bias=True)
    (9): Linear(in_features=256, out_features=128, bias=True)
    (10): Linear(in_features=128, out_features=64, bias=True)
    (11): Linear(in_features=64, out_features=32, bias=True)
    (12): Linear(in_features=32, out_features=16, bias=True)
    (13): Linear(in_features=16, out_features=8, bias=True)
    (14): Linear(in_features=8, out_features=1, bias=True)
  )
)
INFO:root:Number of parameters: 613641
INFO:root:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.00015
    maximize: False
    weight_decay: 0.0
)
INFO:root:
----------parameters----------
seed: 0
model_path: ./models
output_path: ./outputs
log_path: ./log
layers: [2, 8, 16, 32, 64, 128, 256, 256, 128, 64, 32, 16, 8, 1]
learning_rate: 0.00015
epochs: 2000
save_epoch_freq: 1
INFO:root:
----------model----------
INFO:root:PINN(
  (activation): Tanh()
  (loss_function): MSELoss()
  (linears): ModuleList(
    (0): Linear(in_features=2, out_features=8, bias=True)
    (1): Linear(in_features=8, out_features=16, bias=True)
    (2): Linear(in_features=16, out_features=32, bias=True)
    (3): Linear(in_features=32, out_features=64, bias=True)
    (4): Linear(in_features=64, out_features=128, bias=True)
    (5): Linear(in_features=128, out_features=256, bias=True)
    (6): Linear(in_features=256, out_features=256, bias=True)
    (7): Linear(in_features=256, out_features=128, bias=True)
    (8): Linear(in_features=128, out_features=64, bias=True)
    (9): Linear(in_features=64, out_features=32, bias=True)
    (10): Linear(in_features=32, out_features=16, bias=True)
    (11): Linear(in_features=16, out_features=8, bias=True)
    (12): Linear(in_features=8, out_features=1, bias=True)
  )
)
INFO:root:Number of parameters: 153865
INFO:root:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.00015
    maximize: False
    weight_decay: 0.0
)
INFO:root:
----------parameters----------
seed: 0
model_path: ./models
output_path: ./outputs
log_path: ./log
layers: [2, 8, 16, 32, 64, 128, 256, 128, 64, 32, 16, 8, 1]
learning_rate: 0.001
epochs: 2000
save_epoch_freq: 1
INFO:root:
----------model----------
INFO:root:PINN(
  (activation): Tanh()
  (loss_function): MSELoss()
  (linears): ModuleList(
    (0): Linear(in_features=2, out_features=8, bias=True)
    (1): Linear(in_features=8, out_features=16, bias=True)
    (2): Linear(in_features=16, out_features=32, bias=True)
    (3): Linear(in_features=32, out_features=64, bias=True)
    (4): Linear(in_features=64, out_features=128, bias=True)
    (5): Linear(in_features=128, out_features=256, bias=True)
    (6): Linear(in_features=256, out_features=128, bias=True)
    (7): Linear(in_features=128, out_features=64, bias=True)
    (8): Linear(in_features=64, out_features=32, bias=True)
    (9): Linear(in_features=32, out_features=16, bias=True)
    (10): Linear(in_features=16, out_features=8, bias=True)
    (11): Linear(in_features=8, out_features=1, bias=True)
  )
)
INFO:root:Number of parameters: 88073
INFO:root:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0.0
)
INFO:root:
----------parameters----------
seed: 0
model_path: ./models
output_path: ./outputs
log_path: ./log
layers: [2, 8, 16, 32, 64, 128, 256, 128, 64, 32, 16, 8, 1]
learning_rate: 0.001
epochs: 2000
save_epoch_freq: 1
INFO:root:
----------model----------
INFO:root:PINN(
  (activation): Tanh()
  (loss_function): MSELoss()
  (linears): ModuleList(
    (0): Linear(in_features=2, out_features=8, bias=True)
    (1): Linear(in_features=8, out_features=16, bias=True)
    (2): Linear(in_features=16, out_features=32, bias=True)
    (3): Linear(in_features=32, out_features=64, bias=True)
    (4): Linear(in_features=64, out_features=128, bias=True)
    (5): Linear(in_features=128, out_features=256, bias=True)
    (6): Linear(in_features=256, out_features=128, bias=True)
    (7): Linear(in_features=128, out_features=64, bias=True)
    (8): Linear(in_features=64, out_features=32, bias=True)
    (9): Linear(in_features=32, out_features=16, bias=True)
    (10): Linear(in_features=16, out_features=8, bias=True)
    (11): Linear(in_features=8, out_features=1, bias=True)
  )
)
INFO:root:Number of parameters: 88073
INFO:root:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0.0
)
INFO:root:
----------parameters----------
seed: 0
model_path: ./models
output_path: ./outputs
log_path: ./log
layers: [2, 8, 16, 32, 64, 128, 256, 128, 64, 32, 16, 8, 1]
learning_rate: 0.001
epochs: 2000
save_epoch_freq: 1
INFO:root:
----------model----------
INFO:root:PINN(
  (activation): Tanh()
  (loss_function): MSELoss()
  (linears): ModuleList(
    (0): Linear(in_features=2, out_features=8, bias=True)
    (1): Linear(in_features=8, out_features=16, bias=True)
    (2): Linear(in_features=16, out_features=32, bias=True)
    (3): Linear(in_features=32, out_features=64, bias=True)
    (4): Linear(in_features=64, out_features=128, bias=True)
    (5): Linear(in_features=128, out_features=256, bias=True)
    (6): Linear(in_features=256, out_features=128, bias=True)
    (7): Linear(in_features=128, out_features=64, bias=True)
    (8): Linear(in_features=64, out_features=32, bias=True)
    (9): Linear(in_features=32, out_features=16, bias=True)
    (10): Linear(in_features=16, out_features=8, bias=True)
    (11): Linear(in_features=8, out_features=1, bias=True)
  )
)
INFO:root:Number of parameters: 88073
INFO:root:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0.0
)
INFO:root:
----------parameters----------
seed: 0
model_path: ./models
output_path: ./outputs
log_path: ./log
layers: [2, 8, 16, 32, 64, 128, 256, 128, 64, 32, 16, 8, 1]
learning_rate: 0.001
epochs: 2000
save_epoch_freq: 1
INFO:root:
----------parameters----------
seed: 0
model_path: ./models
output_path: ./outputs
log_path: ./log
layers: [2, 8, 16, 32, 64, 128, 256, 128, 64, 32, 16, 8, 1]
learning_rate: 0.001
epochs: 2000
save_epoch_freq: 1
INFO:root:
----------parameters----------
seed: 0
model_path: ./models
output_path: ./outputs
log_path: ./log
layers: [2, 8, 16, 32, 64, 128, 256, 128, 64, 32, 16, 8, 1]
learning_rate: 0.001
epochs: 2000
save_epoch_freq: 1
INFO:root:
----------model----------
INFO:root:PINN(
  (activation): Tanh()
  (loss_function): MSELoss()
  (linears): ModuleList(
    (0): Linear(in_features=2, out_features=8, bias=True)
    (1): Linear(in_features=8, out_features=16, bias=True)
    (2): Linear(in_features=16, out_features=32, bias=True)
    (3): Linear(in_features=32, out_features=64, bias=True)
    (4): Linear(in_features=64, out_features=128, bias=True)
    (5): Linear(in_features=128, out_features=256, bias=True)
    (6): Linear(in_features=256, out_features=128, bias=True)
    (7): Linear(in_features=128, out_features=64, bias=True)
    (8): Linear(in_features=64, out_features=32, bias=True)
    (9): Linear(in_features=32, out_features=16, bias=True)
    (10): Linear(in_features=16, out_features=8, bias=True)
    (11): Linear(in_features=8, out_features=1, bias=True)
  )
)
INFO:root:Number of parameters: 88073
INFO:root:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0.0
)
INFO:root:
----------parameters----------
seed: 0
model_path: ./models
output_path: ./outputs
log_path: ./log
layers: [2, 8, 16, 32, 64, 128, 256, 128, 64, 32, 16, 8, 1]
learning_rate: 0.0005
epochs: 2000
save_epoch_freq: 1
INFO:root:
----------model----------
INFO:root:PINN(
  (activation): Tanh()
  (loss_function): MSELoss()
  (linears): ModuleList(
    (0): Linear(in_features=2, out_features=8, bias=True)
    (1): Linear(in_features=8, out_features=16, bias=True)
    (2): Linear(in_features=16, out_features=32, bias=True)
    (3): Linear(in_features=32, out_features=64, bias=True)
    (4): Linear(in_features=64, out_features=128, bias=True)
    (5): Linear(in_features=128, out_features=256, bias=True)
    (6): Linear(in_features=256, out_features=128, bias=True)
    (7): Linear(in_features=128, out_features=64, bias=True)
    (8): Linear(in_features=64, out_features=32, bias=True)
    (9): Linear(in_features=32, out_features=16, bias=True)
    (10): Linear(in_features=16, out_features=8, bias=True)
    (11): Linear(in_features=8, out_features=1, bias=True)
  )
)
INFO:root:Number of parameters: 88073
INFO:root:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0005
    maximize: False
    weight_decay: 0.0
)
INFO:root:
----------parameters----------
seed: 0
model_path: ./models
output_path: ./outputs
log_path: ./log
layers: [2, 8, 16, 32, 64, 128, 64, 32, 16, 8, 1]
learning_rate: 0.0005
epochs: 2000
save_epoch_freq: 1
INFO:root:
----------model----------
INFO:root:PINN(
  (activation): Tanh()
  (loss_function): MSELoss()
  (linears): ModuleList(
    (0): Linear(in_features=2, out_features=8, bias=True)
    (1): Linear(in_features=8, out_features=16, bias=True)
    (2): Linear(in_features=16, out_features=32, bias=True)
    (3): Linear(in_features=32, out_features=64, bias=True)
    (4): Linear(in_features=64, out_features=128, bias=True)
    (5): Linear(in_features=128, out_features=64, bias=True)
    (6): Linear(in_features=64, out_features=32, bias=True)
    (7): Linear(in_features=32, out_features=16, bias=True)
    (8): Linear(in_features=16, out_features=8, bias=True)
    (9): Linear(in_features=8, out_features=1, bias=True)
  )
)
INFO:root:Number of parameters: 22153
INFO:root:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0005
    maximize: False
    weight_decay: 0.0
)
INFO:root:
----------parameters----------
seed: 0
model_path: ./models
output_path: ./outputs
log_path: ./log
layers: [2, 8, 16, 32, 64, 128, 64, 32, 16, 8, 1]
learning_rate: 0.0005
epochs: 2000
save_epoch_freq: 1
INFO:root:
----------model----------
INFO:root:PINN(
  (activation): Tanh()
  (loss_function): MSELoss()
  (linears): ModuleList(
    (0): Linear(in_features=2, out_features=8, bias=True)
    (1): Linear(in_features=8, out_features=16, bias=True)
    (2): Linear(in_features=16, out_features=32, bias=True)
    (3): Linear(in_features=32, out_features=64, bias=True)
    (4): Linear(in_features=64, out_features=128, bias=True)
    (5): Linear(in_features=128, out_features=64, bias=True)
    (6): Linear(in_features=64, out_features=32, bias=True)
    (7): Linear(in_features=32, out_features=16, bias=True)
    (8): Linear(in_features=16, out_features=8, bias=True)
    (9): Linear(in_features=8, out_features=1, bias=True)
  )
)
INFO:root:Number of parameters: 22153
INFO:root:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0005
    maximize: False
    weight_decay: 0.0
)
INFO:root:
----------parameters----------
seed: 0
model_path: ./models
output_path: ./outputs
log_path: ./log
layers: [2, 8, 16, 32, 64, 128, 64, 32, 16, 8, 1]
learning_rate: 0.0005
epochs: 2000
save_epoch_freq: 1
INFO:root:
----------model----------
INFO:root:PINN(
  (activation): Tanh()
  (loss_function): MSELoss()
  (linears): ModuleList(
    (0): Linear(in_features=2, out_features=8, bias=True)
    (1): Linear(in_features=8, out_features=16, bias=True)
    (2): Linear(in_features=16, out_features=32, bias=True)
    (3): Linear(in_features=32, out_features=64, bias=True)
    (4): Linear(in_features=64, out_features=128, bias=True)
    (5): Linear(in_features=128, out_features=64, bias=True)
    (6): Linear(in_features=64, out_features=32, bias=True)
    (7): Linear(in_features=32, out_features=16, bias=True)
    (8): Linear(in_features=16, out_features=8, bias=True)
    (9): Linear(in_features=8, out_features=1, bias=True)
  )
)
INFO:root:Number of parameters: 22153
INFO:root:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0005
    maximize: False
    weight_decay: 0.0
)
INFO:root:
----------parameters----------
seed: 0
model_path: ./models
output_path: ./outputs
log_path: ./log
layers: [2, 8, 16, 32, 64, 128, 64, 32, 16, 8, 1]
learning_rate: 1e-05
epochs: 5000
save_epoch_freq: 1
INFO:root:
----------model----------
INFO:root:PINN(
  (activation): Tanh()
  (loss_function): MSELoss()
  (linears): ModuleList(
    (0): Linear(in_features=2, out_features=8, bias=True)
    (1): Linear(in_features=8, out_features=16, bias=True)
    (2): Linear(in_features=16, out_features=32, bias=True)
    (3): Linear(in_features=32, out_features=64, bias=True)
    (4): Linear(in_features=64, out_features=128, bias=True)
    (5): Linear(in_features=128, out_features=64, bias=True)
    (6): Linear(in_features=64, out_features=32, bias=True)
    (7): Linear(in_features=32, out_features=16, bias=True)
    (8): Linear(in_features=16, out_features=8, bias=True)
    (9): Linear(in_features=8, out_features=1, bias=True)
  )
)
INFO:root:Number of parameters: 22153
INFO:root:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1e-05
    maximize: False
    weight_decay: 0.0
)
INFO:root:
----------parameters----------
seed: 0
model_path: ./models
output_path: ./outputs
log_path: ./log
layers: [2, 8, 16, 32, 64, 128, 64, 32, 16, 8, 1]
learning_rate: 0.0002
epochs: 5000
save_epoch_freq: 1
INFO:root:
----------model----------
INFO:root:PINN(
  (activation): Tanh()
  (loss_function): MSELoss()
  (linears): ModuleList(
    (0): Linear(in_features=2, out_features=8, bias=True)
    (1): Linear(in_features=8, out_features=16, bias=True)
    (2): Linear(in_features=16, out_features=32, bias=True)
    (3): Linear(in_features=32, out_features=64, bias=True)
    (4): Linear(in_features=64, out_features=128, bias=True)
    (5): Linear(in_features=128, out_features=64, bias=True)
    (6): Linear(in_features=64, out_features=32, bias=True)
    (7): Linear(in_features=32, out_features=16, bias=True)
    (8): Linear(in_features=16, out_features=8, bias=True)
    (9): Linear(in_features=8, out_features=1, bias=True)
  )
)
INFO:root:Number of parameters: 22153
INFO:root:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0002
    maximize: False
    weight_decay: 0.0
)
INFO:root:
----------parameters----------
seed: 0
model_path: ./models
output_path: ./outputs
log_path: ./log
layers: [2, 8, 16, 32, 64, 128, 256, 128, 64, 32, 16, 8, 1]
learning_rate: 0.0002
epochs: 5000
save_epoch_freq: 1
INFO:root:
----------model----------
INFO:root:PINN(
  (activation): Tanh()
  (loss_function): MSELoss()
  (linears): ModuleList(
    (0): Linear(in_features=2, out_features=8, bias=True)
    (1): Linear(in_features=8, out_features=16, bias=True)
    (2): Linear(in_features=16, out_features=32, bias=True)
    (3): Linear(in_features=32, out_features=64, bias=True)
    (4): Linear(in_features=64, out_features=128, bias=True)
    (5): Linear(in_features=128, out_features=256, bias=True)
    (6): Linear(in_features=256, out_features=128, bias=True)
    (7): Linear(in_features=128, out_features=64, bias=True)
    (8): Linear(in_features=64, out_features=32, bias=True)
    (9): Linear(in_features=32, out_features=16, bias=True)
    (10): Linear(in_features=16, out_features=8, bias=True)
    (11): Linear(in_features=8, out_features=1, bias=True)
  )
)
INFO:root:Number of parameters: 88073
INFO:root:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0002
    maximize: False
    weight_decay: 0.0
)
INFO:root:
----------parameters----------
seed: 0
model_path: ./models
output_path: ./outputs
log_path: ./log
layers: [2, 8, 16, 32, 64, 128, 256, 128, 64, 32, 16, 8, 1]
learning_rate: 0.0002
epochs: 5000
save_epoch_freq: 1
INFO:root:
----------model----------
INFO:root:PINN(
  (activation): Tanh()
  (loss_function): MSELoss()
  (linears): ModuleList(
    (0): Linear(in_features=2, out_features=8, bias=True)
    (1): Linear(in_features=8, out_features=16, bias=True)
    (2): Linear(in_features=16, out_features=32, bias=True)
    (3): Linear(in_features=32, out_features=64, bias=True)
    (4): Linear(in_features=64, out_features=128, bias=True)
    (5): Linear(in_features=128, out_features=256, bias=True)
    (6): Linear(in_features=256, out_features=128, bias=True)
    (7): Linear(in_features=128, out_features=64, bias=True)
    (8): Linear(in_features=64, out_features=32, bias=True)
    (9): Linear(in_features=32, out_features=16, bias=True)
    (10): Linear(in_features=16, out_features=8, bias=True)
    (11): Linear(in_features=8, out_features=1, bias=True)
  )
)
INFO:root:Number of parameters: 88073
INFO:root:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0002
    maximize: False
    weight_decay: 0.0
)
INFO:root:
----------parameters----------
seed: 0
model_path: ./models
output_path: ./outputs
log_path: ./log
layers: [2, 8, 16, 32, 64, 128, 256, 128, 64, 32, 16, 8, 1]
learning_rate: 0.0002
epochs: 5000
save_epoch_freq: 1
INFO:root:
----------model----------
INFO:root:PINN(
  (activation): Tanh()
  (loss_function): MSELoss()
  (linears): ModuleList(
    (0): Linear(in_features=2, out_features=8, bias=True)
    (1): Linear(in_features=8, out_features=16, bias=True)
    (2): Linear(in_features=16, out_features=32, bias=True)
    (3): Linear(in_features=32, out_features=64, bias=True)
    (4): Linear(in_features=64, out_features=128, bias=True)
    (5): Linear(in_features=128, out_features=256, bias=True)
    (6): Linear(in_features=256, out_features=128, bias=True)
    (7): Linear(in_features=128, out_features=64, bias=True)
    (8): Linear(in_features=64, out_features=32, bias=True)
    (9): Linear(in_features=32, out_features=16, bias=True)
    (10): Linear(in_features=16, out_features=8, bias=True)
    (11): Linear(in_features=8, out_features=1, bias=True)
  )
)
INFO:root:Number of parameters: 88073
INFO:root:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0002
    maximize: False
    weight_decay: 0.0
)
INFO:root:
----------parameters----------
seed: 0
model_path: ./models
output_path: ./outputs
log_path: ./log
layers: [2, 8, 16, 32, 64, 128, 256, 128, 64, 32, 16, 8, 1]
learning_rate: 0.0002
epochs: 5000
save_epoch_freq: 1
INFO:root:
----------model----------
INFO:root:PINN(
  (activation): Tanh()
  (loss_function): MSELoss()
  (linears): ModuleList(
    (0): Linear(in_features=2, out_features=8, bias=True)
    (1): Linear(in_features=8, out_features=16, bias=True)
    (2): Linear(in_features=16, out_features=32, bias=True)
    (3): Linear(in_features=32, out_features=64, bias=True)
    (4): Linear(in_features=64, out_features=128, bias=True)
    (5): Linear(in_features=128, out_features=256, bias=True)
    (6): Linear(in_features=256, out_features=128, bias=True)
    (7): Linear(in_features=128, out_features=64, bias=True)
    (8): Linear(in_features=64, out_features=32, bias=True)
    (9): Linear(in_features=32, out_features=16, bias=True)
    (10): Linear(in_features=16, out_features=8, bias=True)
    (11): Linear(in_features=8, out_features=1, bias=True)
  )
)
INFO:root:Number of parameters: 88073
INFO:root:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0002
    maximize: False
    weight_decay: 0.0
)
INFO:root:
----------parameters----------
seed: 0
model_path: ./models
output_path: ./outputs
log_path: ./log
layers: [2, 8, 16, 32, 64, 128, 256, 128, 64, 32, 16, 8, 1]
learning_rate: 0.0001
epochs: 1000
save_epoch_freq: 1
INFO:root:
----------model----------
INFO:root:PINN(
  (activation): Tanh()
  (loss_function): MSELoss()
  (linears): ModuleList(
    (0): Linear(in_features=2, out_features=8, bias=True)
    (1): Linear(in_features=8, out_features=16, bias=True)
    (2): Linear(in_features=16, out_features=32, bias=True)
    (3): Linear(in_features=32, out_features=64, bias=True)
    (4): Linear(in_features=64, out_features=128, bias=True)
    (5): Linear(in_features=128, out_features=256, bias=True)
    (6): Linear(in_features=256, out_features=128, bias=True)
    (7): Linear(in_features=128, out_features=64, bias=True)
    (8): Linear(in_features=64, out_features=32, bias=True)
    (9): Linear(in_features=32, out_features=16, bias=True)
    (10): Linear(in_features=16, out_features=8, bias=True)
    (11): Linear(in_features=8, out_features=1, bias=True)
  )
)
INFO:root:Number of parameters: 88073
INFO:root:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.0
)
INFO:root:
----------parameters----------
seed: 0
model_path: ./models
output_path: ./outputs
log_path: ./log
layers: [2, 8, 16, 32, 64, 128, 256, 128, 64, 32, 16, 8, 1]
learning_rate: 0.0001
epochs: 1000
save_epoch_freq: 100
INFO:root:
----------model----------
INFO:root:PINN(
  (activation): Tanh()
  (loss_function): MSELoss()
  (linears): ModuleList(
    (0): Linear(in_features=2, out_features=8, bias=True)
    (1): Linear(in_features=8, out_features=16, bias=True)
    (2): Linear(in_features=16, out_features=32, bias=True)
    (3): Linear(in_features=32, out_features=64, bias=True)
    (4): Linear(in_features=64, out_features=128, bias=True)
    (5): Linear(in_features=128, out_features=256, bias=True)
    (6): Linear(in_features=256, out_features=128, bias=True)
    (7): Linear(in_features=128, out_features=64, bias=True)
    (8): Linear(in_features=64, out_features=32, bias=True)
    (9): Linear(in_features=32, out_features=16, bias=True)
    (10): Linear(in_features=16, out_features=8, bias=True)
    (11): Linear(in_features=8, out_features=1, bias=True)
  )
)
INFO:root:Number of parameters: 88073
INFO:root:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.0
)
INFO:root:
----------parameters----------
seed: 0
model_path: ./models
output_path: ./outputs
log_path: ./log
layers: [2, 8, 16, 32, 64, 128, 256, 128, 64, 32, 16, 8, 1]
learning_rate: 0.0001
epochs: 1500
save_epoch_freq: 100
INFO:root:
----------model----------
INFO:root:PINN(
  (activation): Tanh()
  (loss_function): MSELoss()
  (linears): ModuleList(
    (0): Linear(in_features=2, out_features=8, bias=True)
    (1): Linear(in_features=8, out_features=16, bias=True)
    (2): Linear(in_features=16, out_features=32, bias=True)
    (3): Linear(in_features=32, out_features=64, bias=True)
    (4): Linear(in_features=64, out_features=128, bias=True)
    (5): Linear(in_features=128, out_features=256, bias=True)
    (6): Linear(in_features=256, out_features=128, bias=True)
    (7): Linear(in_features=128, out_features=64, bias=True)
    (8): Linear(in_features=64, out_features=32, bias=True)
    (9): Linear(in_features=32, out_features=16, bias=True)
    (10): Linear(in_features=16, out_features=8, bias=True)
    (11): Linear(in_features=8, out_features=1, bias=True)
  )
)
INFO:root:Number of parameters: 88073
INFO:root:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.0
)
INFO:root:
----------parameters----------
seed: 0
model_path: ./models
output_path: ./outputs
log_path: ./log
layers: [2, 8, 16, 32, 64, 128, 256, 128, 64, 32, 16, 8, 1]
learning_rate: 0.0001
epochs: 1500
save_epoch_freq: 100
INFO:root:
----------model----------
INFO:root:PINN(
  (activation): Tanh()
  (loss_function): MSELoss()
  (linears): ModuleList(
    (0): Linear(in_features=2, out_features=8, bias=True)
    (1): Linear(in_features=8, out_features=16, bias=True)
    (2): Linear(in_features=16, out_features=32, bias=True)
    (3): Linear(in_features=32, out_features=64, bias=True)
    (4): Linear(in_features=64, out_features=128, bias=True)
    (5): Linear(in_features=128, out_features=256, bias=True)
    (6): Linear(in_features=256, out_features=128, bias=True)
    (7): Linear(in_features=128, out_features=64, bias=True)
    (8): Linear(in_features=64, out_features=32, bias=True)
    (9): Linear(in_features=32, out_features=16, bias=True)
    (10): Linear(in_features=16, out_features=8, bias=True)
    (11): Linear(in_features=8, out_features=1, bias=True)
  )
)
INFO:root:Number of parameters: 88073
INFO:root:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.0
)
INFO:root:
----------parameters----------
seed: 0
model_path: ./models
output_path: ./outputs
log_path: ./log
layers: [2, 8, 16, 32, 64, 128, 256, 128, 64, 32, 16, 8, 1]
learning_rate: 0.0001
epochs: 1500
log_epoch_freq: 100
save_epoch_freq: 500
INFO:root:
----------model----------
INFO:root:PINN(
  (activation): Tanh()
  (loss_function): MSELoss()
  (linears): ModuleList(
    (0): Linear(in_features=2, out_features=8, bias=True)
    (1): Linear(in_features=8, out_features=16, bias=True)
    (2): Linear(in_features=16, out_features=32, bias=True)
    (3): Linear(in_features=32, out_features=64, bias=True)
    (4): Linear(in_features=64, out_features=128, bias=True)
    (5): Linear(in_features=128, out_features=256, bias=True)
    (6): Linear(in_features=256, out_features=128, bias=True)
    (7): Linear(in_features=128, out_features=64, bias=True)
    (8): Linear(in_features=64, out_features=32, bias=True)
    (9): Linear(in_features=32, out_features=16, bias=True)
    (10): Linear(in_features=16, out_features=8, bias=True)
    (11): Linear(in_features=8, out_features=1, bias=True)
  )
)
INFO:root:Number of parameters: 88073
INFO:root:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.0
)
INFO:root:
----------parameters----------
seed: 0
model_path: ./models
output_path: ./outputs
log_path: ./log
layers: [2, 8, 16, 32, 64, 128, 256, 128, 64, 32, 16, 8, 1]
learning_rate: 0.0001
epochs: 1500
log_epoch_freq: 100
save_epoch_freq: 500
INFO:root:
----------model----------
INFO:root:PINN(
  (activation): Tanh()
  (loss_function): MSELoss()
  (linears): ModuleList(
    (0): Linear(in_features=2, out_features=8, bias=True)
    (1): Linear(in_features=8, out_features=16, bias=True)
    (2): Linear(in_features=16, out_features=32, bias=True)
    (3): Linear(in_features=32, out_features=64, bias=True)
    (4): Linear(in_features=64, out_features=128, bias=True)
    (5): Linear(in_features=128, out_features=256, bias=True)
    (6): Linear(in_features=256, out_features=128, bias=True)
    (7): Linear(in_features=128, out_features=64, bias=True)
    (8): Linear(in_features=64, out_features=32, bias=True)
    (9): Linear(in_features=32, out_features=16, bias=True)
    (10): Linear(in_features=16, out_features=8, bias=True)
    (11): Linear(in_features=8, out_features=1, bias=True)
  )
)
INFO:root:Number of parameters: 88073
INFO:root:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.0
)
INFO:root:
----------parameters----------
seed: 0
model_path: ./models
output_path: ./outputs
log_path: ./log
layers: [2, 8, 16, 32, 64, 128, 256, 128, 64, 32, 16, 8, 1]
learning_rate: 0.0001
epochs: 1500
log_epoch_freq: 100
save_epoch_freq: 500
INFO:root:
----------model----------
INFO:root:PINN(
  (activation): Tanh()
  (loss_function): MSELoss()
  (linears): ModuleList(
    (0): Linear(in_features=2, out_features=8, bias=True)
    (1): Linear(in_features=8, out_features=16, bias=True)
    (2): Linear(in_features=16, out_features=32, bias=True)
    (3): Linear(in_features=32, out_features=64, bias=True)
    (4): Linear(in_features=64, out_features=128, bias=True)
    (5): Linear(in_features=128, out_features=256, bias=True)
    (6): Linear(in_features=256, out_features=128, bias=True)
    (7): Linear(in_features=128, out_features=64, bias=True)
    (8): Linear(in_features=64, out_features=32, bias=True)
    (9): Linear(in_features=32, out_features=16, bias=True)
    (10): Linear(in_features=16, out_features=8, bias=True)
    (11): Linear(in_features=8, out_features=1, bias=True)
  )
)
INFO:root:Number of parameters: 88073
INFO:root:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.0
)
INFO:root:
----------parameters----------
seed: 0
model_path: ./models
output_path: ./outputs
log_path: ./log
layers: [2, 8, 16, 32, 64, 128, 256, 128, 64, 32, 16, 8, 1]
learning_rate: 0.0001
epochs: 1500
log_epoch_freq: 100
save_epoch_freq: 500
INFO:root:
----------model----------
INFO:root:PINN(
  (activation): Tanh()
  (loss_function): MSELoss()
  (linears): ModuleList(
    (0): Linear(in_features=2, out_features=8, bias=True)
    (1): Linear(in_features=8, out_features=16, bias=True)
    (2): Linear(in_features=16, out_features=32, bias=True)
    (3): Linear(in_features=32, out_features=64, bias=True)
    (4): Linear(in_features=64, out_features=128, bias=True)
    (5): Linear(in_features=128, out_features=256, bias=True)
    (6): Linear(in_features=256, out_features=128, bias=True)
    (7): Linear(in_features=128, out_features=64, bias=True)
    (8): Linear(in_features=64, out_features=32, bias=True)
    (9): Linear(in_features=32, out_features=16, bias=True)
    (10): Linear(in_features=16, out_features=8, bias=True)
    (11): Linear(in_features=8, out_features=1, bias=True)
  )
)
INFO:root:Number of parameters: 88073
INFO:root:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.0
)
INFO:root:
----------parameters----------
seed: 0
model_path: ./models
output_path: ./outputs
log_path: ./log
layers: [2, 8, 16, 32, 64, 128, 256, 512, 256, 128, 64, 32, 16, 8, 1]
learning_rate: 0.0001
epochs: 1500
log_epoch_freq: 100
save_epoch_freq: 500
INFO:root:
----------model----------
INFO:root:PINN(
  (activation): Tanh()
  (loss_function): MSELoss()
  (linears): ModuleList(
    (0): Linear(in_features=2, out_features=8, bias=True)
    (1): Linear(in_features=8, out_features=16, bias=True)
    (2): Linear(in_features=16, out_features=32, bias=True)
    (3): Linear(in_features=32, out_features=64, bias=True)
    (4): Linear(in_features=64, out_features=128, bias=True)
    (5): Linear(in_features=128, out_features=256, bias=True)
    (6): Linear(in_features=256, out_features=512, bias=True)
    (7): Linear(in_features=512, out_features=256, bias=True)
    (8): Linear(in_features=256, out_features=128, bias=True)
    (9): Linear(in_features=128, out_features=64, bias=True)
    (10): Linear(in_features=64, out_features=32, bias=True)
    (11): Linear(in_features=32, out_features=16, bias=True)
    (12): Linear(in_features=16, out_features=8, bias=True)
    (13): Linear(in_features=8, out_features=1, bias=True)
  )
)
INFO:root:Number of parameters: 350985
INFO:root:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.0
)
INFO:root:
----------parameters----------
seed: 0
model_path: ./models
output_path: ./outputs
log_path: ./log
layers: [2, 8, 16, 32, 64, 128, 256, 256, 128, 64, 32, 16, 8, 1]
learning_rate: 0.0001
epochs: 1500
log_epoch_freq: 100
save_epoch_freq: 500
INFO:root:
----------model----------
INFO:root:PINN(
  (activation): Tanh()
  (loss_function): MSELoss()
  (linears): ModuleList(
    (0): Linear(in_features=2, out_features=8, bias=True)
    (1): Linear(in_features=8, out_features=16, bias=True)
    (2): Linear(in_features=16, out_features=32, bias=True)
    (3): Linear(in_features=32, out_features=64, bias=True)
    (4): Linear(in_features=64, out_features=128, bias=True)
    (5): Linear(in_features=128, out_features=256, bias=True)
    (6): Linear(in_features=256, out_features=256, bias=True)
    (7): Linear(in_features=256, out_features=128, bias=True)
    (8): Linear(in_features=128, out_features=64, bias=True)
    (9): Linear(in_features=64, out_features=32, bias=True)
    (10): Linear(in_features=32, out_features=16, bias=True)
    (11): Linear(in_features=16, out_features=8, bias=True)
    (12): Linear(in_features=8, out_features=1, bias=True)
  )
)
INFO:root:Number of parameters: 153865
INFO:root:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.0
)
INFO:root:
----------parameters----------
seed: 0
model_path: ./models
output_path: ./outputs
log_path: ./log
layers: [2, 8, 16, 32, 64, 128, 256, 256, 128, 64, 32, 16, 8, 1]
learning_rate: 0.0001
epochs: 1500
log_epoch_freq: 100
save_epoch_freq: 500
INFO:root:
----------model----------
INFO:root:PINN(
  (activation): Tanh()
  (loss_function): MSELoss()
  (linears): ModuleList(
    (0): Linear(in_features=2, out_features=8, bias=True)
    (1): Linear(in_features=8, out_features=16, bias=True)
    (2): Linear(in_features=16, out_features=32, bias=True)
    (3): Linear(in_features=32, out_features=64, bias=True)
    (4): Linear(in_features=64, out_features=128, bias=True)
    (5): Linear(in_features=128, out_features=256, bias=True)
    (6): Linear(in_features=256, out_features=256, bias=True)
    (7): Linear(in_features=256, out_features=128, bias=True)
    (8): Linear(in_features=128, out_features=64, bias=True)
    (9): Linear(in_features=64, out_features=32, bias=True)
    (10): Linear(in_features=32, out_features=16, bias=True)
    (11): Linear(in_features=16, out_features=8, bias=True)
    (12): Linear(in_features=8, out_features=1, bias=True)
  )
)
INFO:root:Number of parameters: 153865
INFO:root:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.0001
)
INFO:root:
----------parameters----------
seed: 0
model_path: ./models
output_path: ./outputs
log_path: ./log
layers: [2, 8, 16, 32, 64, 128, 256, 256, 128, 64, 32, 16, 8, 1]
learning_rate: 0.0001
epochs: 1500
log_epoch_freq: 100
save_epoch_freq: 500
INFO:root:
----------model----------
INFO:root:PINN(
  (activation): Tanh()
  (loss_function): MSELoss()
  (linears): ModuleList(
    (0): Linear(in_features=2, out_features=8, bias=True)
    (1): Linear(in_features=8, out_features=16, bias=True)
    (2): Linear(in_features=16, out_features=32, bias=True)
    (3): Linear(in_features=32, out_features=64, bias=True)
    (4): Linear(in_features=64, out_features=128, bias=True)
    (5): Linear(in_features=128, out_features=256, bias=True)
    (6): Linear(in_features=256, out_features=256, bias=True)
    (7): Linear(in_features=256, out_features=128, bias=True)
    (8): Linear(in_features=128, out_features=64, bias=True)
    (9): Linear(in_features=64, out_features=32, bias=True)
    (10): Linear(in_features=32, out_features=16, bias=True)
    (11): Linear(in_features=16, out_features=8, bias=True)
    (12): Linear(in_features=8, out_features=1, bias=True)
  )
)
INFO:root:Number of parameters: 153865
INFO:root:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.0001
)
INFO:root:
----------parameters----------
seed: 0
model_path: ./models
output_path: ./outputs
log_path: ./log
layers: [2, 8, 16, 32, 64, 128, 256, 256, 128, 64, 32, 16, 8, 1]
learning_rate: 0.0001
epochs: 1500
log_epoch_freq: 100
save_epoch_freq: 500
INFO:root:
----------model----------
INFO:root:PINN(
  (activation): Tanh()
  (loss_function): MSELoss()
  (linears): ModuleList(
    (0): Linear(in_features=2, out_features=8, bias=True)
    (1): Linear(in_features=8, out_features=16, bias=True)
    (2): Linear(in_features=16, out_features=32, bias=True)
    (3): Linear(in_features=32, out_features=64, bias=True)
    (4): Linear(in_features=64, out_features=128, bias=True)
    (5): Linear(in_features=128, out_features=256, bias=True)
    (6): Linear(in_features=256, out_features=256, bias=True)
    (7): Linear(in_features=256, out_features=128, bias=True)
    (8): Linear(in_features=128, out_features=64, bias=True)
    (9): Linear(in_features=64, out_features=32, bias=True)
    (10): Linear(in_features=32, out_features=16, bias=True)
    (11): Linear(in_features=16, out_features=8, bias=True)
    (12): Linear(in_features=8, out_features=1, bias=True)
  )
)
INFO:root:Number of parameters: 153865
INFO:root:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.0005
)
INFO:root:
----------parameters----------
seed: 0
model_path: ./models
output_path: ./outputs
log_path: ./log
layers: [2, 8, 16, 32, 64, 128, 256, 256, 128, 64, 32, 16, 8, 1]
learning_rate: 0.0001
epochs: 1500
log_epoch_freq: 100
save_epoch_freq: 500
INFO:root:
----------model----------
INFO:root:PINN(
  (activation): Tanh()
  (loss_function): MSELoss()
  (linears): ModuleList(
    (0): Linear(in_features=2, out_features=8, bias=True)
    (1): Linear(in_features=8, out_features=16, bias=True)
    (2): Linear(in_features=16, out_features=32, bias=True)
    (3): Linear(in_features=32, out_features=64, bias=True)
    (4): Linear(in_features=64, out_features=128, bias=True)
    (5): Linear(in_features=128, out_features=256, bias=True)
    (6): Linear(in_features=256, out_features=256, bias=True)
    (7): Linear(in_features=256, out_features=128, bias=True)
    (8): Linear(in_features=128, out_features=64, bias=True)
    (9): Linear(in_features=64, out_features=32, bias=True)
    (10): Linear(in_features=32, out_features=16, bias=True)
    (11): Linear(in_features=16, out_features=8, bias=True)
    (12): Linear(in_features=8, out_features=1, bias=True)
  )
)
INFO:root:Number of parameters: 153865
INFO:root:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.0005
)
INFO:root:
----------parameters----------
seed: 0
model_path: ./models
output_path: ./outputs
log_path: ./log
layers: [2, 8, 16, 32, 64, 128, 256, 256, 128, 64, 32, 16, 8, 1]
learning_rate: 0.0001
epochs: 1500
log_epoch_freq: 100
save_epoch_freq: 500
INFO:root:
----------model----------
INFO:root:PINN(
  (activation): Tanh()
  (loss_function): MSELoss()
  (linears): ModuleList(
    (0): Linear(in_features=2, out_features=8, bias=True)
    (1): Linear(in_features=8, out_features=16, bias=True)
    (2): Linear(in_features=16, out_features=32, bias=True)
    (3): Linear(in_features=32, out_features=64, bias=True)
    (4): Linear(in_features=64, out_features=128, bias=True)
    (5): Linear(in_features=128, out_features=256, bias=True)
    (6): Linear(in_features=256, out_features=256, bias=True)
    (7): Linear(in_features=256, out_features=128, bias=True)
    (8): Linear(in_features=128, out_features=64, bias=True)
    (9): Linear(in_features=64, out_features=32, bias=True)
    (10): Linear(in_features=32, out_features=16, bias=True)
    (11): Linear(in_features=16, out_features=8, bias=True)
    (12): Linear(in_features=8, out_features=1, bias=True)
  )
)
INFO:root:Number of parameters: 153865
INFO:root:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.0001
)
INFO:root:
----------parameters----------
seed: 0
model_path: ./models
output_path: ./outputs
log_path: ./log
layers: [2, 8, 16, 32, 64, 128, 256, 256, 128, 64, 32, 16, 8, 1]
learning_rate: 0.0001
epochs: 1200
log_epoch_freq: 100
save_epoch_freq: 500
INFO:root:
----------model----------
INFO:root:PINN(
  (activation): Tanh()
  (loss_function): MSELoss()
  (linears): ModuleList(
    (0): Linear(in_features=2, out_features=8, bias=True)
    (1): Linear(in_features=8, out_features=16, bias=True)
    (2): Linear(in_features=16, out_features=32, bias=True)
    (3): Linear(in_features=32, out_features=64, bias=True)
    (4): Linear(in_features=64, out_features=128, bias=True)
    (5): Linear(in_features=128, out_features=256, bias=True)
    (6): Linear(in_features=256, out_features=256, bias=True)
    (7): Linear(in_features=256, out_features=128, bias=True)
    (8): Linear(in_features=128, out_features=64, bias=True)
    (9): Linear(in_features=64, out_features=32, bias=True)
    (10): Linear(in_features=32, out_features=16, bias=True)
    (11): Linear(in_features=16, out_features=8, bias=True)
    (12): Linear(in_features=8, out_features=1, bias=True)
  )
)
INFO:root:Number of parameters: 153865
INFO:root:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.0001
)
INFO:root:
----------parameters----------
seed: 0
model_path: ./models
output_path: ./outputs
log_path: ./log
layers: [2, 8, 16, 32, 64, 128, 256, 256, 128, 64, 32, 16, 8, 1]
learning_rate: 0.0001
epochs: 1200
log_epoch_freq: 100
save_epoch_freq: 500
INFO:root:
----------model----------
INFO:root:PINN(
  (activation): Tanh()
  (loss_function): MSELoss()
  (linears): ModuleList(
    (0): Linear(in_features=2, out_features=8, bias=True)
    (1): Linear(in_features=8, out_features=16, bias=True)
    (2): Linear(in_features=16, out_features=32, bias=True)
    (3): Linear(in_features=32, out_features=64, bias=True)
    (4): Linear(in_features=64, out_features=128, bias=True)
    (5): Linear(in_features=128, out_features=256, bias=True)
    (6): Linear(in_features=256, out_features=256, bias=True)
    (7): Linear(in_features=256, out_features=128, bias=True)
    (8): Linear(in_features=128, out_features=64, bias=True)
    (9): Linear(in_features=64, out_features=32, bias=True)
    (10): Linear(in_features=32, out_features=16, bias=True)
    (11): Linear(in_features=16, out_features=8, bias=True)
    (12): Linear(in_features=8, out_features=1, bias=True)
  )
)
INFO:root:Number of parameters: 153865
INFO:root:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.0001
)
INFO:root:
----------parameters----------
seed: 0
model_path: ./models
output_path: ./outputs
log_path: ./log
layers: [2, 8, 16, 32, 64, 128, 256, 256, 128, 64, 32, 16, 8, 1]
learning_rate: 0.0001
epochs: 1200
log_epoch_freq: 100
save_epoch_freq: 500
INFO:root:
----------model----------
INFO:root:PINN(
  (activation): Tanh()
  (loss_function): MSELoss()
  (linears): ModuleList(
    (0): Linear(in_features=2, out_features=8, bias=True)
    (1): Linear(in_features=8, out_features=16, bias=True)
    (2): Linear(in_features=16, out_features=32, bias=True)
    (3): Linear(in_features=32, out_features=64, bias=True)
    (4): Linear(in_features=64, out_features=128, bias=True)
    (5): Linear(in_features=128, out_features=256, bias=True)
    (6): Linear(in_features=256, out_features=256, bias=True)
    (7): Linear(in_features=256, out_features=128, bias=True)
    (8): Linear(in_features=128, out_features=64, bias=True)
    (9): Linear(in_features=64, out_features=32, bias=True)
    (10): Linear(in_features=32, out_features=16, bias=True)
    (11): Linear(in_features=16, out_features=8, bias=True)
    (12): Linear(in_features=8, out_features=1, bias=True)
  )
)
INFO:root:Number of parameters: 153865
INFO:root:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.0001
)
INFO:root:
----------parameters----------
seed: 0
model_path: ./models
output_path: ./outputs
log_path: ./log
layers: [2, 8, 16, 32, 64, 128, 256, 256, 128, 64, 32, 16, 8, 1]
learning_rate: 0.0001
epochs: 1200
log_epoch_freq: 100
save_epoch_freq: 500
INFO:root:
----------model----------
INFO:root:PINN(
  (activation): Tanh()
  (loss_function): MSELoss()
  (linears): ModuleList(
    (0): Linear(in_features=2, out_features=8, bias=True)
    (1): Linear(in_features=8, out_features=16, bias=True)
    (2): Linear(in_features=16, out_features=32, bias=True)
    (3): Linear(in_features=32, out_features=64, bias=True)
    (4): Linear(in_features=64, out_features=128, bias=True)
    (5): Linear(in_features=128, out_features=256, bias=True)
    (6): Linear(in_features=256, out_features=256, bias=True)
    (7): Linear(in_features=256, out_features=128, bias=True)
    (8): Linear(in_features=128, out_features=64, bias=True)
    (9): Linear(in_features=64, out_features=32, bias=True)
    (10): Linear(in_features=32, out_features=16, bias=True)
    (11): Linear(in_features=16, out_features=8, bias=True)
    (12): Linear(in_features=8, out_features=1, bias=True)
  )
)
INFO:root:Number of parameters: 153865
INFO:root:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.0001
)
INFO:root:
----------parameters----------
seed: 0
model_path: ./models
output_path: ./outputs
log_path: ./log
layers: [2, 8, 16, 32, 64, 128, 256, 256, 128, 64, 32, 16, 8, 1]
learning_rate: 0.0001
epochs: 1200
log_epoch_freq: 100
save_epoch_freq: 500
INFO:root:
----------model----------
INFO:root:PINN(
  (activation): Tanh()
  (loss_function): MSELoss()
  (linears): ModuleList(
    (0): Linear(in_features=2, out_features=8, bias=True)
    (1): Linear(in_features=8, out_features=16, bias=True)
    (2): Linear(in_features=16, out_features=32, bias=True)
    (3): Linear(in_features=32, out_features=64, bias=True)
    (4): Linear(in_features=64, out_features=128, bias=True)
    (5): Linear(in_features=128, out_features=256, bias=True)
    (6): Linear(in_features=256, out_features=256, bias=True)
    (7): Linear(in_features=256, out_features=128, bias=True)
    (8): Linear(in_features=128, out_features=64, bias=True)
    (9): Linear(in_features=64, out_features=32, bias=True)
    (10): Linear(in_features=32, out_features=16, bias=True)
    (11): Linear(in_features=16, out_features=8, bias=True)
    (12): Linear(in_features=8, out_features=1, bias=True)
  )
)
INFO:root:Number of parameters: 153865
INFO:root:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.0001
)
INFO:root:
----------parameters----------
seed: 0
model_path: ./models
output_path: ./outputs
log_path: ./log
layers: [2, 8, 16, 32, 64, 128, 256, 256, 128, 64, 32, 16, 8, 1]
learning_rate: 0.0001
epochs: 1200
log_epoch_freq: 100
save_epoch_freq: 500
INFO:root:
----------model----------
INFO:root:PINN(
  (activation): Tanh()
  (loss_function): MSELoss()
  (linears): ModuleList(
    (0): Linear(in_features=2, out_features=8, bias=True)
    (1): Linear(in_features=8, out_features=16, bias=True)
    (2): Linear(in_features=16, out_features=32, bias=True)
    (3): Linear(in_features=32, out_features=64, bias=True)
    (4): Linear(in_features=64, out_features=128, bias=True)
    (5): Linear(in_features=128, out_features=256, bias=True)
    (6): Linear(in_features=256, out_features=256, bias=True)
    (7): Linear(in_features=256, out_features=128, bias=True)
    (8): Linear(in_features=128, out_features=64, bias=True)
    (9): Linear(in_features=64, out_features=32, bias=True)
    (10): Linear(in_features=32, out_features=16, bias=True)
    (11): Linear(in_features=16, out_features=8, bias=True)
    (12): Linear(in_features=8, out_features=1, bias=True)
  )
)
INFO:root:Number of parameters: 153865
INFO:root:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.0001
)
INFO:root:
----------parameters----------
seed: 0
model_path: ./models
output_path: ./outputs
log_path: ./log
layers: [2, 8, 16, 32, 64, 128, 256, 256, 128, 64, 32, 16, 8, 1]
learning_rate: 0.0001
epochs: 1200
log_epoch_freq: 100
save_epoch_freq: 500
INFO:root:
----------model----------
INFO:root:PINN(
  (activation): Tanh()
  (loss_function): MSELoss()
  (linears): ModuleList(
    (0): Linear(in_features=2, out_features=8, bias=True)
    (1): Linear(in_features=8, out_features=16, bias=True)
    (2): Linear(in_features=16, out_features=32, bias=True)
    (3): Linear(in_features=32, out_features=64, bias=True)
    (4): Linear(in_features=64, out_features=128, bias=True)
    (5): Linear(in_features=128, out_features=256, bias=True)
    (6): Linear(in_features=256, out_features=256, bias=True)
    (7): Linear(in_features=256, out_features=128, bias=True)
    (8): Linear(in_features=128, out_features=64, bias=True)
    (9): Linear(in_features=64, out_features=32, bias=True)
    (10): Linear(in_features=32, out_features=16, bias=True)
    (11): Linear(in_features=16, out_features=8, bias=True)
    (12): Linear(in_features=8, out_features=1, bias=True)
  )
)
INFO:root:Number of parameters: 153865
INFO:root:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.0001
)
INFO:root:
----------parameters----------
seed: 0
model_path: ./models
output_path: ./outputs
log_path: ./log
layers: [2, 8, 16, 32, 64, 128, 256, 256, 128, 64, 32, 16, 8, 1]
learning_rate: 0.0001
epochs: 2000
log_epoch_freq: 100
save_epoch_freq: 500
INFO:root:
----------model----------
INFO:root:PINN(
  (activation): Tanh()
  (loss_function): MSELoss()
  (linears): ModuleList(
    (0): Linear(in_features=2, out_features=8, bias=True)
    (1): Linear(in_features=8, out_features=16, bias=True)
    (2): Linear(in_features=16, out_features=32, bias=True)
    (3): Linear(in_features=32, out_features=64, bias=True)
    (4): Linear(in_features=64, out_features=128, bias=True)
    (5): Linear(in_features=128, out_features=256, bias=True)
    (6): Linear(in_features=256, out_features=256, bias=True)
    (7): Linear(in_features=256, out_features=128, bias=True)
    (8): Linear(in_features=128, out_features=64, bias=True)
    (9): Linear(in_features=64, out_features=32, bias=True)
    (10): Linear(in_features=32, out_features=16, bias=True)
    (11): Linear(in_features=16, out_features=8, bias=True)
    (12): Linear(in_features=8, out_features=1, bias=True)
  )
)
INFO:root:Number of parameters: 153865
INFO:root:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.0001
)
INFO:root:
----------parameters----------
seed: 0
model_path: ./models
output_path: ./outputs
log_path: ./log
layers: [2, 8, 16, 32, 64, 128, 256, 256, 128, 64, 32, 16, 8, 1]
learning_rate: 0.0001
epochs: 2000
log_epoch_freq: 100
save_epoch_freq: 500
INFO:root:
----------model----------
INFO:root:PINN(
  (activation): Tanh()
  (loss_function): MSELoss()
  (linears): ModuleList(
    (0): Linear(in_features=2, out_features=8, bias=True)
    (1): Linear(in_features=8, out_features=16, bias=True)
    (2): Linear(in_features=16, out_features=32, bias=True)
    (3): Linear(in_features=32, out_features=64, bias=True)
    (4): Linear(in_features=64, out_features=128, bias=True)
    (5): Linear(in_features=128, out_features=256, bias=True)
    (6): Linear(in_features=256, out_features=256, bias=True)
    (7): Linear(in_features=256, out_features=128, bias=True)
    (8): Linear(in_features=128, out_features=64, bias=True)
    (9): Linear(in_features=64, out_features=32, bias=True)
    (10): Linear(in_features=32, out_features=16, bias=True)
    (11): Linear(in_features=16, out_features=8, bias=True)
    (12): Linear(in_features=8, out_features=1, bias=True)
  )
)
INFO:root:Number of parameters: 153865
INFO:root:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.0
)
INFO:root:
----------parameters----------
seed: 0
model_path: ./models
output_path: ./outputs
log_path: ./log
layers: [2, 8, 16, 32, 64, 128, 256, 256, 128, 64, 32, 16, 8, 1]
learning_rate: 0.0001
epochs: 2000
log_epoch_freq: 100
save_epoch_freq: 500
INFO:root:
----------model----------
INFO:root:PINN(
  (activation): Tanh()
  (loss_function): MSELoss()
  (linears): ModuleList(
    (0): Linear(in_features=2, out_features=8, bias=True)
    (1): Linear(in_features=8, out_features=16, bias=True)
    (2): Linear(in_features=16, out_features=32, bias=True)
    (3): Linear(in_features=32, out_features=64, bias=True)
    (4): Linear(in_features=64, out_features=128, bias=True)
    (5): Linear(in_features=128, out_features=256, bias=True)
    (6): Linear(in_features=256, out_features=256, bias=True)
    (7): Linear(in_features=256, out_features=128, bias=True)
    (8): Linear(in_features=128, out_features=64, bias=True)
    (9): Linear(in_features=64, out_features=32, bias=True)
    (10): Linear(in_features=32, out_features=16, bias=True)
    (11): Linear(in_features=16, out_features=8, bias=True)
    (12): Linear(in_features=8, out_features=1, bias=True)
  )
)
INFO:root:Number of parameters: 153865
INFO:root:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.0
)
INFO:root:
----------parameters----------
seed: 0
model_path: ./models
output_path: ./outputs
log_path: ./log
layers: [2, 8, 16, 32, 64, 128, 256, 256, 128, 64, 32, 16, 8, 1]
learning_rate: 0.0001
epochs: 2000
log_epoch_freq: 100
save_epoch_freq: 500
INFO:root:
----------model----------
INFO:root:PINN(
  (activation): Tanh()
  (loss_function): MSELoss()
  (linears): ModuleList(
    (0): Linear(in_features=2, out_features=8, bias=True)
    (1): Linear(in_features=8, out_features=16, bias=True)
    (2): Linear(in_features=16, out_features=32, bias=True)
    (3): Linear(in_features=32, out_features=64, bias=True)
    (4): Linear(in_features=64, out_features=128, bias=True)
    (5): Linear(in_features=128, out_features=256, bias=True)
    (6): Linear(in_features=256, out_features=256, bias=True)
    (7): Linear(in_features=256, out_features=128, bias=True)
    (8): Linear(in_features=128, out_features=64, bias=True)
    (9): Linear(in_features=64, out_features=32, bias=True)
    (10): Linear(in_features=32, out_features=16, bias=True)
    (11): Linear(in_features=16, out_features=8, bias=True)
    (12): Linear(in_features=8, out_features=1, bias=True)
  )
)
INFO:root:Number of parameters: 153865
INFO:root:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.0
)
INFO:root:
----------parameters----------
seed: 0
model_path: ./models
output_path: ./outputs
log_path: ./log
layers: [2, 8, 16, 32, 64, 128, 256, 256, 128, 64, 32, 16, 8, 1]
learning_rate: 0.0001
epochs: 2500
log_epoch_freq: 100
save_epoch_freq: 500
INFO:root:
----------model----------
INFO:root:PINN(
  (activation): Tanh()
  (loss_function): MSELoss()
  (linears): ModuleList(
    (0): Linear(in_features=2, out_features=8, bias=True)
    (1): Linear(in_features=8, out_features=16, bias=True)
    (2): Linear(in_features=16, out_features=32, bias=True)
    (3): Linear(in_features=32, out_features=64, bias=True)
    (4): Linear(in_features=64, out_features=128, bias=True)
    (5): Linear(in_features=128, out_features=256, bias=True)
    (6): Linear(in_features=256, out_features=256, bias=True)
    (7): Linear(in_features=256, out_features=128, bias=True)
    (8): Linear(in_features=128, out_features=64, bias=True)
    (9): Linear(in_features=64, out_features=32, bias=True)
    (10): Linear(in_features=32, out_features=16, bias=True)
    (11): Linear(in_features=16, out_features=8, bias=True)
    (12): Linear(in_features=8, out_features=1, bias=True)
  )
)
INFO:root:Number of parameters: 153865
INFO:root:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.0
)
INFO:root:
----------parameters----------
seed: 0
model_path: ./models
output_path: ./outputs
log_path: ./log
layers: [2, 8, 16, 32, 64, 128, 256, 256, 128, 64, 32, 16, 8, 1]
learning_rate: 0.0001
epochs: 3000
log_epoch_freq: 100
save_epoch_freq: 500
INFO:root:
----------model----------
INFO:root:PINN(
  (activation): Tanh()
  (loss_function): MSELoss()
  (linears): ModuleList(
    (0): Linear(in_features=2, out_features=8, bias=True)
    (1): Linear(in_features=8, out_features=16, bias=True)
    (2): Linear(in_features=16, out_features=32, bias=True)
    (3): Linear(in_features=32, out_features=64, bias=True)
    (4): Linear(in_features=64, out_features=128, bias=True)
    (5): Linear(in_features=128, out_features=256, bias=True)
    (6): Linear(in_features=256, out_features=256, bias=True)
    (7): Linear(in_features=256, out_features=128, bias=True)
    (8): Linear(in_features=128, out_features=64, bias=True)
    (9): Linear(in_features=64, out_features=32, bias=True)
    (10): Linear(in_features=32, out_features=16, bias=True)
    (11): Linear(in_features=16, out_features=8, bias=True)
    (12): Linear(in_features=8, out_features=1, bias=True)
  )
)
INFO:root:Number of parameters: 153865
INFO:root:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.0
)
INFO:root:
----------parameters----------
seed: 0
model_path: ./models
output_path: ./outputs
log_path: ./log
layers: [2, 8, 16, 32, 64, 128, 256, 256, 128, 64, 32, 16, 8, 1]
learning_rate: 0.0001
epochs: 3000
log_epoch_freq: 100
save_epoch_freq: 500
INFO:root:
----------model----------
INFO:root:PINN(
  (activation): Tanh()
  (loss_function): MSELoss()
  (linears): ModuleList(
    (0): Linear(in_features=2, out_features=8, bias=True)
    (1): Linear(in_features=8, out_features=16, bias=True)
    (2): Linear(in_features=16, out_features=32, bias=True)
    (3): Linear(in_features=32, out_features=64, bias=True)
    (4): Linear(in_features=64, out_features=128, bias=True)
    (5): Linear(in_features=128, out_features=256, bias=True)
    (6): Linear(in_features=256, out_features=256, bias=True)
    (7): Linear(in_features=256, out_features=128, bias=True)
    (8): Linear(in_features=128, out_features=64, bias=True)
    (9): Linear(in_features=64, out_features=32, bias=True)
    (10): Linear(in_features=32, out_features=16, bias=True)
    (11): Linear(in_features=16, out_features=8, bias=True)
    (12): Linear(in_features=8, out_features=1, bias=True)
  )
)
INFO:root:Number of parameters: 153865
INFO:root:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.0
)
INFO:root:
----------parameters----------
seed: 0
model_path: ./models
output_path: ./outputs
log_path: ./log
layers: [2, 8, 16, 32, 64, 128, 256, 256, 128, 64, 32, 16, 8, 1]
learning_rate: 0.0001
epochs: 5000
log_epoch_freq: 100
save_epoch_freq: 500
INFO:root:
----------model----------
INFO:root:PINN(
  (activation): Tanh()
  (loss_function): MSELoss()
  (linears): ModuleList(
    (0): Linear(in_features=2, out_features=8, bias=True)
    (1): Linear(in_features=8, out_features=16, bias=True)
    (2): Linear(in_features=16, out_features=32, bias=True)
    (3): Linear(in_features=32, out_features=64, bias=True)
    (4): Linear(in_features=64, out_features=128, bias=True)
    (5): Linear(in_features=128, out_features=256, bias=True)
    (6): Linear(in_features=256, out_features=256, bias=True)
    (7): Linear(in_features=256, out_features=128, bias=True)
    (8): Linear(in_features=128, out_features=64, bias=True)
    (9): Linear(in_features=64, out_features=32, bias=True)
    (10): Linear(in_features=32, out_features=16, bias=True)
    (11): Linear(in_features=16, out_features=8, bias=True)
    (12): Linear(in_features=8, out_features=1, bias=True)
  )
)
INFO:root:Number of parameters: 153865
INFO:root:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.0
)
INFO:root:
----------parameters----------
seed: 0
model_path: ./models
output_path: ./outputs
log_path: ./log
layers: [2, 8, 16, 32, 64, 128, 256, 256, 128, 64, 32, 16, 8, 1]
learning_rate: 0.0001
epochs: 7000
log_epoch_freq: 100
save_epoch_freq: 500
INFO:root:
----------model----------
INFO:root:PINN(
  (activation): Tanh()
  (loss_function): MSELoss()
  (linears): ModuleList(
    (0): Linear(in_features=2, out_features=8, bias=True)
    (1): Linear(in_features=8, out_features=16, bias=True)
    (2): Linear(in_features=16, out_features=32, bias=True)
    (3): Linear(in_features=32, out_features=64, bias=True)
    (4): Linear(in_features=64, out_features=128, bias=True)
    (5): Linear(in_features=128, out_features=256, bias=True)
    (6): Linear(in_features=256, out_features=256, bias=True)
    (7): Linear(in_features=256, out_features=128, bias=True)
    (8): Linear(in_features=128, out_features=64, bias=True)
    (9): Linear(in_features=64, out_features=32, bias=True)
    (10): Linear(in_features=32, out_features=16, bias=True)
    (11): Linear(in_features=16, out_features=8, bias=True)
    (12): Linear(in_features=8, out_features=1, bias=True)
  )
)
INFO:root:Number of parameters: 153865
INFO:root:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.0
)
INFO:root:
----------parameters----------
seed: 0
model_path: ./models
output_path: ./outputs
log_path: ./log
layers: [2, 8, 16, 32, 64, 128, 256, 512, 512, 256, 128, 64, 32, 16, 8, 1]
learning_rate: 0.0001
epochs: 7000
log_epoch_freq: 100
save_epoch_freq: 500
INFO:root:
----------model----------
INFO:root:PINN(
  (activation): Tanh()
  (loss_function): MSELoss()
  (linears): ModuleList(
    (0): Linear(in_features=2, out_features=8, bias=True)
    (1): Linear(in_features=8, out_features=16, bias=True)
    (2): Linear(in_features=16, out_features=32, bias=True)
    (3): Linear(in_features=32, out_features=64, bias=True)
    (4): Linear(in_features=64, out_features=128, bias=True)
    (5): Linear(in_features=128, out_features=256, bias=True)
    (6): Linear(in_features=256, out_features=512, bias=True)
    (7): Linear(in_features=512, out_features=512, bias=True)
    (8): Linear(in_features=512, out_features=256, bias=True)
    (9): Linear(in_features=256, out_features=128, bias=True)
    (10): Linear(in_features=128, out_features=64, bias=True)
    (11): Linear(in_features=64, out_features=32, bias=True)
    (12): Linear(in_features=32, out_features=16, bias=True)
    (13): Linear(in_features=16, out_features=8, bias=True)
    (14): Linear(in_features=8, out_features=1, bias=True)
  )
)
INFO:root:Number of parameters: 613641
INFO:root:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.0
)
INFO:root:
----------parameters----------
seed: 0
model_path: ./models
output_path: ./outputs
log_path: ./log
layers: [2, 8, 16, 32, 64, 128, 256, 512, 512, 256, 128, 64, 32, 16, 8, 1]
learning_rate: 0.0001
epochs: 7000
log_epoch_freq: 100
save_epoch_freq: 500
INFO:root:
----------model----------
INFO:root:PINN(
  (activation): Tanh()
  (loss_function): MSELoss()
  (linears): ModuleList(
    (0): Linear(in_features=2, out_features=8, bias=True)
    (1): Linear(in_features=8, out_features=16, bias=True)
    (2): Linear(in_features=16, out_features=32, bias=True)
    (3): Linear(in_features=32, out_features=64, bias=True)
    (4): Linear(in_features=64, out_features=128, bias=True)
    (5): Linear(in_features=128, out_features=256, bias=True)
    (6): Linear(in_features=256, out_features=512, bias=True)
    (7): Linear(in_features=512, out_features=512, bias=True)
    (8): Linear(in_features=512, out_features=256, bias=True)
    (9): Linear(in_features=256, out_features=128, bias=True)
    (10): Linear(in_features=128, out_features=64, bias=True)
    (11): Linear(in_features=64, out_features=32, bias=True)
    (12): Linear(in_features=32, out_features=16, bias=True)
    (13): Linear(in_features=16, out_features=8, bias=True)
    (14): Linear(in_features=8, out_features=1, bias=True)
  )
  (batch_norms): ModuleList(
    (0): BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (4): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6-7): 2 x BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (9): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (10): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (11): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (12): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (13): BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (14): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (dropout): Dropout(p=0.1, inplace=False)
)
INFO:root:Number of parameters: 617707
INFO:root:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.0
)
INFO:root:
----------parameters----------
seed: 0
model_path: ./models
output_path: ./outputs
log_path: ./log
layers: [2, 8, 16, 32, 64, 128, 256, 512, 512, 256, 128, 64, 32, 16, 8, 1]
learning_rate: 0.0001
epochs: 7000
log_epoch_freq: 100
save_epoch_freq: 500
INFO:root:
----------model----------
INFO:root:PINN(
  (activation): Tanh()
  (loss_function): MSELoss()
  (linears): ModuleList(
    (0): Linear(in_features=2, out_features=8, bias=True)
    (1): Linear(in_features=8, out_features=16, bias=True)
    (2): Linear(in_features=16, out_features=32, bias=True)
    (3): Linear(in_features=32, out_features=64, bias=True)
    (4): Linear(in_features=64, out_features=128, bias=True)
    (5): Linear(in_features=128, out_features=256, bias=True)
    (6): Linear(in_features=256, out_features=512, bias=True)
    (7): Linear(in_features=512, out_features=512, bias=True)
    (8): Linear(in_features=512, out_features=256, bias=True)
    (9): Linear(in_features=256, out_features=128, bias=True)
    (10): Linear(in_features=128, out_features=64, bias=True)
    (11): Linear(in_features=64, out_features=32, bias=True)
    (12): Linear(in_features=32, out_features=16, bias=True)
    (13): Linear(in_features=16, out_features=8, bias=True)
    (14): Linear(in_features=8, out_features=1, bias=True)
  )
  (batch_norms): ModuleList(
    (0): BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (4): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6-7): 2 x BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (9): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (10): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (11): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (12): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (13): BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (14): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (dropout): Dropout(p=0.0, inplace=False)
)
INFO:root:Number of parameters: 617707
INFO:root:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.0
)
INFO:root:
----------parameters----------
seed: 0
model_path: ./models
output_path: ./outputs
log_path: ./log
layers: [2, 8, 16, 32, 64, 128, 256, 512, 512, 256, 128, 64, 32, 16, 8, 1]
learning_rate: 0.0001
epochs: 7000
log_epoch_freq: 100
save_epoch_freq: 500
INFO:root:
----------model----------
INFO:root:PINN(
  (activation): Tanh()
  (loss_function): MSELoss()
  (linears): ModuleList(
    (0): Linear(in_features=2, out_features=8, bias=True)
    (1): Linear(in_features=8, out_features=16, bias=True)
    (2): Linear(in_features=16, out_features=32, bias=True)
    (3): Linear(in_features=32, out_features=64, bias=True)
    (4): Linear(in_features=64, out_features=128, bias=True)
    (5): Linear(in_features=128, out_features=256, bias=True)
    (6): Linear(in_features=256, out_features=512, bias=True)
    (7): Linear(in_features=512, out_features=512, bias=True)
    (8): Linear(in_features=512, out_features=256, bias=True)
    (9): Linear(in_features=256, out_features=128, bias=True)
    (10): Linear(in_features=128, out_features=64, bias=True)
    (11): Linear(in_features=64, out_features=32, bias=True)
    (12): Linear(in_features=32, out_features=16, bias=True)
    (13): Linear(in_features=16, out_features=8, bias=True)
    (14): Linear(in_features=8, out_features=1, bias=True)
  )
  (batch_norms): ModuleList(
    (0): BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (4): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6-7): 2 x BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (9): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (10): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (11): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (12): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (13): BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (14): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (dropout): Dropout(p=0.0, inplace=False)
)
INFO:root:Number of parameters: 617707
INFO:root:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.0
)
INFO:root:
----------parameters----------
seed: 0
model_path: ./models
output_path: ./outputs
log_path: ./log
layers: [2, 8, 16, 32, 64, 128, 256, 512, 512, 256, 128, 64, 32, 16, 8, 1]
learning_rate: 0.0001
epochs: 7000
log_epoch_freq: 100
save_epoch_freq: 500
INFO:root:
----------model----------
INFO:root:PINN(
  (activation): Tanh()
  (loss_function): MSELoss()
  (linears): ModuleList(
    (0): Linear(in_features=2, out_features=8, bias=True)
    (1): Linear(in_features=8, out_features=16, bias=True)
    (2): Linear(in_features=16, out_features=32, bias=True)
    (3): Linear(in_features=32, out_features=64, bias=True)
    (4): Linear(in_features=64, out_features=128, bias=True)
    (5): Linear(in_features=128, out_features=256, bias=True)
    (6): Linear(in_features=256, out_features=512, bias=True)
    (7): Linear(in_features=512, out_features=512, bias=True)
    (8): Linear(in_features=512, out_features=256, bias=True)
    (9): Linear(in_features=256, out_features=128, bias=True)
    (10): Linear(in_features=128, out_features=64, bias=True)
    (11): Linear(in_features=64, out_features=32, bias=True)
    (12): Linear(in_features=32, out_features=16, bias=True)
    (13): Linear(in_features=16, out_features=8, bias=True)
    (14): Linear(in_features=8, out_features=1, bias=True)
  )
  (batch_norms): ModuleList(
    (0): BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (4): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6-7): 2 x BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (9): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (10): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (11): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (12): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (13): BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (14): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (dropout): Dropout(p=0.0, inplace=False)
)
INFO:root:Number of parameters: 617707
INFO:root:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.0
)
INFO:root:
----------parameters----------
seed: 0
model_path: ./models
output_path: ./outputs
log_path: ./log
layers: [2, 8, 16, 32, 64, 128, 256, 512, 1024, 512, 256, 128, 64, 32, 16, 8, 1]
learning_rate: 0.001
epochs: 7000
log_epoch_freq: 100
save_epoch_freq: 500
INFO:root:
----------model----------
INFO:root:PINN(
  (activation): Tanh()
  (loss_function): MSELoss()
  (linears): ModuleList(
    (0): Linear(in_features=2, out_features=8, bias=True)
    (1): Linear(in_features=8, out_features=16, bias=True)
    (2): Linear(in_features=16, out_features=32, bias=True)
    (3): Linear(in_features=32, out_features=64, bias=True)
    (4): Linear(in_features=64, out_features=128, bias=True)
    (5): Linear(in_features=128, out_features=256, bias=True)
    (6): Linear(in_features=256, out_features=512, bias=True)
    (7): Linear(in_features=512, out_features=1024, bias=True)
    (8): Linear(in_features=1024, out_features=512, bias=True)
    (9): Linear(in_features=512, out_features=256, bias=True)
    (10): Linear(in_features=256, out_features=128, bias=True)
    (11): Linear(in_features=128, out_features=64, bias=True)
    (12): Linear(in_features=64, out_features=32, bias=True)
    (13): Linear(in_features=32, out_features=16, bias=True)
    (14): Linear(in_features=16, out_features=8, bias=True)
    (15): Linear(in_features=8, out_features=1, bias=True)
  )
  (batch_norms): ModuleList(
    (0): BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (4): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (7): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (9): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (10): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (11): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (12): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (13): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (14): BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (15): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (dropout): Dropout(p=0.0, inplace=False)
)
INFO:root:Number of parameters: 1407211
INFO:root:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0.0
)
INFO:root:
----------parameters----------
seed: 0
model_path: ./models
output_path: ./outputs
log_path: ./log
layers: [2, 8, 16, 32, 64, 128, 256, 512, 1024, 512, 256, 128, 64, 32, 16, 8, 1]
learning_rate: 0.001
epochs: 7000
log_epoch_freq: 100
save_epoch_freq: 500
INFO:root:
----------model----------
INFO:root:PINN(
  (activation): Tanh()
  (loss_function): MSELoss()
  (linears): ModuleList(
    (0): Linear(in_features=2, out_features=8, bias=True)
    (1): Linear(in_features=8, out_features=16, bias=True)
    (2): Linear(in_features=16, out_features=32, bias=True)
    (3): Linear(in_features=32, out_features=64, bias=True)
    (4): Linear(in_features=64, out_features=128, bias=True)
    (5): Linear(in_features=128, out_features=256, bias=True)
    (6): Linear(in_features=256, out_features=512, bias=True)
    (7): Linear(in_features=512, out_features=1024, bias=True)
    (8): Linear(in_features=1024, out_features=512, bias=True)
    (9): Linear(in_features=512, out_features=256, bias=True)
    (10): Linear(in_features=256, out_features=128, bias=True)
    (11): Linear(in_features=128, out_features=64, bias=True)
    (12): Linear(in_features=64, out_features=32, bias=True)
    (13): Linear(in_features=32, out_features=16, bias=True)
    (14): Linear(in_features=16, out_features=8, bias=True)
    (15): Linear(in_features=8, out_features=1, bias=True)
  )
  (batch_norms): ModuleList(
    (0): BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (4): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (7): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (9): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (10): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (11): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (12): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (13): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (14): BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (15): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (dropout): Dropout(p=0.0, inplace=False)
)
INFO:root:Number of parameters: 1407211
INFO:root:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0.0
)
INFO:root:
----------parameters----------
seed: 0
model_path: ./models
output_path: ./outputs
log_path: ./log
layers: [2, 8, 16, 32, 64, 128, 256, 512, 1024, 512, 256, 128, 64, 32, 16, 8, 1]
learning_rate: 0.001
epochs: 3000
log_epoch_freq: 100
save_epoch_freq: 500
INFO:root:
----------model----------
INFO:root:PINN(
  (activation): Tanh()
  (loss_function): MSELoss()
  (linears): ModuleList(
    (0): Linear(in_features=2, out_features=8, bias=True)
    (1): Linear(in_features=8, out_features=16, bias=True)
    (2): Linear(in_features=16, out_features=32, bias=True)
    (3): Linear(in_features=32, out_features=64, bias=True)
    (4): Linear(in_features=64, out_features=128, bias=True)
    (5): Linear(in_features=128, out_features=256, bias=True)
    (6): Linear(in_features=256, out_features=512, bias=True)
    (7): Linear(in_features=512, out_features=1024, bias=True)
    (8): Linear(in_features=1024, out_features=512, bias=True)
    (9): Linear(in_features=512, out_features=256, bias=True)
    (10): Linear(in_features=256, out_features=128, bias=True)
    (11): Linear(in_features=128, out_features=64, bias=True)
    (12): Linear(in_features=64, out_features=32, bias=True)
    (13): Linear(in_features=32, out_features=16, bias=True)
    (14): Linear(in_features=16, out_features=8, bias=True)
    (15): Linear(in_features=8, out_features=1, bias=True)
  )
  (batch_norms): ModuleList(
    (0): BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (4): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (7): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (9): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (10): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (11): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (12): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (13): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (14): BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (15): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (dropout): Dropout(p=0.0, inplace=False)
)
INFO:root:Number of parameters: 1407211
INFO:root:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0.0
)
INFO:root:
----------parameters----------
seed: 0
model_path: ./models
output_path: ./outputs
log_path: ./log
layers: [2, 8, 16, 32, 64, 128, 256, 512, 1024, 512, 256, 128, 64, 32, 16, 8, 1]
learning_rate: 0.001
epochs: 3000
log_epoch_freq: 100
save_epoch_freq: 500
INFO:root:
----------model----------
INFO:root:PINN(
  (activation): Tanh()
  (loss_function): MSELoss()
  (linears): ModuleList(
    (0): Linear(in_features=2, out_features=8, bias=True)
    (1): Linear(in_features=8, out_features=16, bias=True)
    (2): Linear(in_features=16, out_features=32, bias=True)
    (3): Linear(in_features=32, out_features=64, bias=True)
    (4): Linear(in_features=64, out_features=128, bias=True)
    (5): Linear(in_features=128, out_features=256, bias=True)
    (6): Linear(in_features=256, out_features=512, bias=True)
    (7): Linear(in_features=512, out_features=1024, bias=True)
    (8): Linear(in_features=1024, out_features=512, bias=True)
    (9): Linear(in_features=512, out_features=256, bias=True)
    (10): Linear(in_features=256, out_features=128, bias=True)
    (11): Linear(in_features=128, out_features=64, bias=True)
    (12): Linear(in_features=64, out_features=32, bias=True)
    (13): Linear(in_features=32, out_features=16, bias=True)
    (14): Linear(in_features=16, out_features=8, bias=True)
    (15): Linear(in_features=8, out_features=1, bias=True)
  )
  (batch_norms): ModuleList(
    (0): BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (4): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (7): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (9): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (10): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (11): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (12): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (13): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (14): BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (15): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (dropout): Dropout(p=0.0, inplace=False)
)
INFO:root:Number of parameters: 1407211
INFO:root:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0.0
)
INFO:root:
----------parameters----------
seed: 0
model_path: ./models
output_path: ./outputs
log_path: ./log
layers: [2, 8, 16, 32, 64, 128, 256, 512, 1024, 512, 256, 128, 64, 32, 16, 8, 1]
learning_rate: 0.001
epochs: 3000
log_epoch_freq: 100
save_epoch_freq: 500
INFO:root:
----------model----------
INFO:root:PINN(
  (activation): Tanh()
  (loss_function): MSELoss()
  (linears): ModuleList(
    (0): Linear(in_features=2, out_features=8, bias=True)
    (1): Linear(in_features=8, out_features=16, bias=True)
    (2): Linear(in_features=16, out_features=32, bias=True)
    (3): Linear(in_features=32, out_features=64, bias=True)
    (4): Linear(in_features=64, out_features=128, bias=True)
    (5): Linear(in_features=128, out_features=256, bias=True)
    (6): Linear(in_features=256, out_features=512, bias=True)
    (7): Linear(in_features=512, out_features=1024, bias=True)
    (8): Linear(in_features=1024, out_features=512, bias=True)
    (9): Linear(in_features=512, out_features=256, bias=True)
    (10): Linear(in_features=256, out_features=128, bias=True)
    (11): Linear(in_features=128, out_features=64, bias=True)
    (12): Linear(in_features=64, out_features=32, bias=True)
    (13): Linear(in_features=32, out_features=16, bias=True)
    (14): Linear(in_features=16, out_features=8, bias=True)
    (15): Linear(in_features=8, out_features=1, bias=True)
  )
  (batch_norms): ModuleList(
    (0): BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (4): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (7): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (9): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (10): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (11): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (12): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (13): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (14): BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (15): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (dropout): Dropout(p=0.0, inplace=False)
)
INFO:root:Number of parameters: 1407211
INFO:root:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0.0
)
INFO:root:
----------parameters----------
seed: 0
model_path: ./models
output_path: ./outputs
log_path: ./log
layers: [2, 8, 16, 32, 64, 128, 256, 512, 1024, 512, 256, 128, 64, 32, 16, 8, 1]
learning_rate: 0.001
epochs: 4000
log_epoch_freq: 100
save_epoch_freq: 500
INFO:root:
----------model----------
INFO:root:PINN(
  (activation): Tanh()
  (loss_function): MSELoss()
  (linears): ModuleList(
    (0): Linear(in_features=2, out_features=8, bias=True)
    (1): Linear(in_features=8, out_features=16, bias=True)
    (2): Linear(in_features=16, out_features=32, bias=True)
    (3): Linear(in_features=32, out_features=64, bias=True)
    (4): Linear(in_features=64, out_features=128, bias=True)
    (5): Linear(in_features=128, out_features=256, bias=True)
    (6): Linear(in_features=256, out_features=512, bias=True)
    (7): Linear(in_features=512, out_features=1024, bias=True)
    (8): Linear(in_features=1024, out_features=512, bias=True)
    (9): Linear(in_features=512, out_features=256, bias=True)
    (10): Linear(in_features=256, out_features=128, bias=True)
    (11): Linear(in_features=128, out_features=64, bias=True)
    (12): Linear(in_features=64, out_features=32, bias=True)
    (13): Linear(in_features=32, out_features=16, bias=True)
    (14): Linear(in_features=16, out_features=8, bias=True)
    (15): Linear(in_features=8, out_features=1, bias=True)
  )
  (batch_norms): ModuleList(
    (0): BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (4): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (7): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (9): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (10): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (11): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (12): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (13): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (14): BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (15): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (dropout): Dropout(p=0.0, inplace=False)
)
INFO:root:Number of parameters: 1407211
INFO:root:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0.0
)
INFO:root:
----------parameters----------
seed: 0
model_path: ./models
output_path: ./outputs
log_path: ./log
layers: [2, 8, 16, 32, 64, 128, 256, 512, 1024, 512, 256, 128, 64, 32, 16, 8, 1]
learning_rate: 0.001
epochs: 5000
log_epoch_freq: 100
save_epoch_freq: 500
INFO:root:
----------model----------
INFO:root:PINN(
  (activation): Tanh()
  (loss_function): MSELoss()
  (linears): ModuleList(
    (0): Linear(in_features=2, out_features=8, bias=True)
    (1): Linear(in_features=8, out_features=16, bias=True)
    (2): Linear(in_features=16, out_features=32, bias=True)
    (3): Linear(in_features=32, out_features=64, bias=True)
    (4): Linear(in_features=64, out_features=128, bias=True)
    (5): Linear(in_features=128, out_features=256, bias=True)
    (6): Linear(in_features=256, out_features=512, bias=True)
    (7): Linear(in_features=512, out_features=1024, bias=True)
    (8): Linear(in_features=1024, out_features=512, bias=True)
    (9): Linear(in_features=512, out_features=256, bias=True)
    (10): Linear(in_features=256, out_features=128, bias=True)
    (11): Linear(in_features=128, out_features=64, bias=True)
    (12): Linear(in_features=64, out_features=32, bias=True)
    (13): Linear(in_features=32, out_features=16, bias=True)
    (14): Linear(in_features=16, out_features=8, bias=True)
    (15): Linear(in_features=8, out_features=1, bias=True)
  )
  (batch_norms): ModuleList(
    (0): BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (4): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (7): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (9): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (10): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (11): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (12): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (13): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (14): BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (15): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (dropout): Dropout(p=0.0, inplace=False)
)
INFO:root:Number of parameters: 1407211
INFO:root:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0.0
)
INFO:root:
----------parameters----------
seed: 0
model_path: ./models
output_path: ./outputs
log_path: ./log
layers: [2, 8, 16, 32, 64, 128, 256, 512, 1024, 512, 256, 128, 64, 32, 16, 8, 1]
learning_rate: 0.001
epochs: 5000
log_epoch_freq: 100
save_epoch_freq: 500
INFO:root:
----------model----------
INFO:root:PINN(
  (activation): Tanh()
  (loss_function): MSELoss()
  (linears): ModuleList(
    (0): Linear(in_features=2, out_features=8, bias=True)
    (1): Linear(in_features=8, out_features=16, bias=True)
    (2): Linear(in_features=16, out_features=32, bias=True)
    (3): Linear(in_features=32, out_features=64, bias=True)
    (4): Linear(in_features=64, out_features=128, bias=True)
    (5): Linear(in_features=128, out_features=256, bias=True)
    (6): Linear(in_features=256, out_features=512, bias=True)
    (7): Linear(in_features=512, out_features=1024, bias=True)
    (8): Linear(in_features=1024, out_features=512, bias=True)
    (9): Linear(in_features=512, out_features=256, bias=True)
    (10): Linear(in_features=256, out_features=128, bias=True)
    (11): Linear(in_features=128, out_features=64, bias=True)
    (12): Linear(in_features=64, out_features=32, bias=True)
    (13): Linear(in_features=32, out_features=16, bias=True)
    (14): Linear(in_features=16, out_features=8, bias=True)
    (15): Linear(in_features=8, out_features=1, bias=True)
  )
  (batch_norms): ModuleList(
    (0): BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (4): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (7): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (9): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (10): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (11): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (12): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (13): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (14): BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (15): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (dropout): Dropout(p=0.0, inplace=False)
)
INFO:root:Number of parameters: 1407211
INFO:root:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0.0
)
INFO:root:
----------parameters----------
seed: 0
model_path: ./models
output_path: ./outputs
log_path: ./log
layers: [2, 8, 16, 32, 64, 128, 256, 512, 512, 512, 512, 512, 256, 128, 64, 32, 16, 8, 1]
learning_rate: 0.001
epochs: 7000
log_epoch_freq: 100
save_epoch_freq: 500
INFO:root:
----------model----------
INFO:root:PINN(
  (activation): Tanh()
  (loss_function): MSELoss()
  (linears): ModuleList(
    (0): Linear(in_features=2, out_features=8, bias=True)
    (1): Linear(in_features=8, out_features=16, bias=True)
    (2): Linear(in_features=16, out_features=32, bias=True)
    (3): Linear(in_features=32, out_features=64, bias=True)
    (4): Linear(in_features=64, out_features=128, bias=True)
    (5): Linear(in_features=128, out_features=256, bias=True)
    (6): Linear(in_features=256, out_features=512, bias=True)
    (7-10): 4 x Linear(in_features=512, out_features=512, bias=True)
    (11): Linear(in_features=512, out_features=256, bias=True)
    (12): Linear(in_features=256, out_features=128, bias=True)
    (13): Linear(in_features=128, out_features=64, bias=True)
    (14): Linear(in_features=64, out_features=32, bias=True)
    (15): Linear(in_features=32, out_features=16, bias=True)
    (16): Linear(in_features=16, out_features=8, bias=True)
    (17): Linear(in_features=8, out_features=1, bias=True)
  )
  (batch_norms): ModuleList(
    (0): BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (4): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6-10): 5 x BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (11): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (12): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (13): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (14): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (15): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (16): BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (17): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (dropout): Dropout(p=0.0, inplace=False)
)
INFO:root:Number of parameters: 1408747
INFO:root:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0.0
)
INFO:root:
----------parameters----------
seed: 0
model_path: ./models
output_path: ./outputs
log_path: ./log
layers: [2, 8, 16, 32, 64, 128, 256, 512, 512, 512, 512, 512, 256, 128, 64, 32, 16, 8, 1]
learning_rate: 0.001
epochs: 7000
log_epoch_freq: 100
save_epoch_freq: 500
INFO:root:
----------model----------
INFO:root:PINN(
  (activation): Tanh()
  (loss_function): MSELoss()
  (linears): ModuleList(
    (0): Linear(in_features=2, out_features=8, bias=True)
    (1): Linear(in_features=8, out_features=16, bias=True)
    (2): Linear(in_features=16, out_features=32, bias=True)
    (3): Linear(in_features=32, out_features=64, bias=True)
    (4): Linear(in_features=64, out_features=128, bias=True)
    (5): Linear(in_features=128, out_features=256, bias=True)
    (6): Linear(in_features=256, out_features=512, bias=True)
    (7-10): 4 x Linear(in_features=512, out_features=512, bias=True)
    (11): Linear(in_features=512, out_features=256, bias=True)
    (12): Linear(in_features=256, out_features=128, bias=True)
    (13): Linear(in_features=128, out_features=64, bias=True)
    (14): Linear(in_features=64, out_features=32, bias=True)
    (15): Linear(in_features=32, out_features=16, bias=True)
    (16): Linear(in_features=16, out_features=8, bias=True)
    (17): Linear(in_features=8, out_features=1, bias=True)
  )
  (batch_norms): ModuleList(
    (0): BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (4): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6-10): 5 x BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (11): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (12): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (13): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (14): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (15): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (16): BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (17): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (dropout): Dropout(p=0.0, inplace=False)
)
INFO:root:Number of parameters: 1408747
INFO:root:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0.0
)
INFO:root:
----------parameters----------
seed: 0
model_path: ./models
output_path: ./outputs
log_path: ./log
layers: [2, 8, 16, 32, 64, 128, 256, 128, 64, 32, 16, 8, 1]
learning_rate: 0.001
epochs: 7000
log_epoch_freq: 100
save_epoch_freq: 500
INFO:root:
----------model----------
INFO:root:PINN(
  (activation): Tanh()
  (loss_function): MSELoss()
  (linears): ModuleList(
    (0): Linear(in_features=2, out_features=8, bias=True)
    (1): Linear(in_features=8, out_features=16, bias=True)
    (2): Linear(in_features=16, out_features=32, bias=True)
    (3): Linear(in_features=32, out_features=64, bias=True)
    (4): Linear(in_features=64, out_features=128, bias=True)
    (5): Linear(in_features=128, out_features=256, bias=True)
    (6): Linear(in_features=256, out_features=128, bias=True)
    (7): Linear(in_features=128, out_features=64, bias=True)
    (8): Linear(in_features=64, out_features=32, bias=True)
    (9): Linear(in_features=32, out_features=16, bias=True)
    (10): Linear(in_features=16, out_features=8, bias=True)
    (11): Linear(in_features=8, out_features=1, bias=True)
  )
  (batch_norms): ModuleList(
    (0): BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (4): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (7): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (9): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (10): BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (11): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (dropout): Dropout(p=0.0, inplace=False)
)
INFO:root:Number of parameters: 89579
INFO:root:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0.0
)
INFO:root:
----------parameters----------
seed: 0
model_path: ./models
output_path: ./outputs
log_path: ./log
layers: [2, 8, 16, 32, 64, 128, 256, 128, 64, 32, 16, 8, 1]
learning_rate: 0.001
epochs: 6000
log_epoch_freq: 100
save_epoch_freq: 500
INFO:root:
----------model----------
INFO:root:PINN(
  (activation): Tanh()
  (loss_function): MSELoss()
  (linears): ModuleList(
    (0): Linear(in_features=2, out_features=8, bias=True)
    (1): Linear(in_features=8, out_features=16, bias=True)
    (2): Linear(in_features=16, out_features=32, bias=True)
    (3): Linear(in_features=32, out_features=64, bias=True)
    (4): Linear(in_features=64, out_features=128, bias=True)
    (5): Linear(in_features=128, out_features=256, bias=True)
    (6): Linear(in_features=256, out_features=128, bias=True)
    (7): Linear(in_features=128, out_features=64, bias=True)
    (8): Linear(in_features=64, out_features=32, bias=True)
    (9): Linear(in_features=32, out_features=16, bias=True)
    (10): Linear(in_features=16, out_features=8, bias=True)
    (11): Linear(in_features=8, out_features=1, bias=True)
  )
  (batch_norms): ModuleList(
    (0): BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (4): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (7): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (9): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (10): BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (11): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (dropout): Dropout(p=0.0, inplace=False)
)
INFO:root:Number of parameters: 89579
INFO:root:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0.0
)
INFO:root:
----------parameters----------
seed: 0
model_path: ./models
output_path: ./outputs
log_path: ./log
layers: [2, 8, 16, 32, 64, 128, 256, 128, 64, 32, 16, 8, 1]
learning_rate: 0.01
epochs: 6000
log_epoch_freq: 100
save_epoch_freq: 500
INFO:root:
----------model----------
INFO:root:PINN(
  (activation): Tanh()
  (loss_function): MSELoss()
  (linears): ModuleList(
    (0): Linear(in_features=2, out_features=8, bias=True)
    (1): Linear(in_features=8, out_features=16, bias=True)
    (2): Linear(in_features=16, out_features=32, bias=True)
    (3): Linear(in_features=32, out_features=64, bias=True)
    (4): Linear(in_features=64, out_features=128, bias=True)
    (5): Linear(in_features=128, out_features=256, bias=True)
    (6): Linear(in_features=256, out_features=128, bias=True)
    (7): Linear(in_features=128, out_features=64, bias=True)
    (8): Linear(in_features=64, out_features=32, bias=True)
    (9): Linear(in_features=32, out_features=16, bias=True)
    (10): Linear(in_features=16, out_features=8, bias=True)
    (11): Linear(in_features=8, out_features=1, bias=True)
  )
  (batch_norms): ModuleList(
    (0): BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (4): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (7): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (9): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (10): BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (11): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (dropout): Dropout(p=0.0, inplace=False)
)
INFO:root:Number of parameters: 89579
INFO:root:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.01
    maximize: False
    weight_decay: 0.0
)
INFO:root:
----------parameters----------
seed: 0
model_path: ./models
output_path: ./outputs
log_path: ./log
debug: False
layers: [2, 8, 16, 32, 64, 128, 256, 128, 64, 32, 16, 8, 1]
learning_rate: 0.01
epochs: 6000
log_epoch_freq: 100
save_epoch_freq: 500
INFO:root:
----------model----------
INFO:root:PINN(
  (activation): Tanh()
  (loss_function): MSELoss()
  (linears): ModuleList(
    (0): Linear(in_features=2, out_features=8, bias=True)
    (1): Linear(in_features=8, out_features=16, bias=True)
    (2): Linear(in_features=16, out_features=32, bias=True)
    (3): Linear(in_features=32, out_features=64, bias=True)
    (4): Linear(in_features=64, out_features=128, bias=True)
    (5): Linear(in_features=128, out_features=256, bias=True)
    (6): Linear(in_features=256, out_features=128, bias=True)
    (7): Linear(in_features=128, out_features=64, bias=True)
    (8): Linear(in_features=64, out_features=32, bias=True)
    (9): Linear(in_features=32, out_features=16, bias=True)
    (10): Linear(in_features=16, out_features=8, bias=True)
    (11): Linear(in_features=8, out_features=1, bias=True)
  )
  (batch_norms): ModuleList(
    (0): BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (4): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (7): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (9): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (10): BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (11): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (dropout): Dropout(p=0.0, inplace=False)
)
INFO:root:Number of parameters: 89579
INFO:root:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.01
    maximize: False
    weight_decay: 0.0
)
INFO:root:
----------parameters----------
seed: 0
model_path: ./models
output_path: ./outputs
log_path: ./log
debug: False
layers: [2, 8, 16, 32, 64, 128, 256, 128, 64, 32, 16, 8, 1]
learning_rate: 0.01
epochs: 6000
log_epoch_freq: 100
save_epoch_freq: 500
INFO:root:
----------model----------
INFO:root:PINN(
  (activation): Tanh()
  (loss_function): MSELoss()
  (linears): ModuleList(
    (0): Linear(in_features=2, out_features=8, bias=True)
    (1): Linear(in_features=8, out_features=16, bias=True)
    (2): Linear(in_features=16, out_features=32, bias=True)
    (3): Linear(in_features=32, out_features=64, bias=True)
    (4): Linear(in_features=64, out_features=128, bias=True)
    (5): Linear(in_features=128, out_features=256, bias=True)
    (6): Linear(in_features=256, out_features=128, bias=True)
    (7): Linear(in_features=128, out_features=64, bias=True)
    (8): Linear(in_features=64, out_features=32, bias=True)
    (9): Linear(in_features=32, out_features=16, bias=True)
    (10): Linear(in_features=16, out_features=8, bias=True)
    (11): Linear(in_features=8, out_features=1, bias=True)
  )
  (batch_norms): ModuleList(
    (0): BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (4): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (7): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (9): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (10): BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (11): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (dropout): Dropout(p=0.0, inplace=False)
)
INFO:root:Number of parameters: 89579
INFO:root:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.01
    maximize: False
    weight_decay: 0.0
)
INFO:root:
----------parameters----------
seed: 0
model_path: ./models
output_path: ./outputs
log_path: ./log
debug: False
layers: [2, 8, 16, 32, 64, 128, 256, 128, 64, 32, 16, 8, 1]
learning_rate: 0.01
epochs: 6000
log_epoch_freq: 100
save_epoch_freq: 500
INFO:root:
----------model----------
INFO:root:PINN(
  (activation): Tanh()
  (loss_function): MSELoss()
  (linears): ModuleList(
    (0): Linear(in_features=2, out_features=8, bias=True)
    (1): Linear(in_features=8, out_features=16, bias=True)
    (2): Linear(in_features=16, out_features=32, bias=True)
    (3): Linear(in_features=32, out_features=64, bias=True)
    (4): Linear(in_features=64, out_features=128, bias=True)
    (5): Linear(in_features=128, out_features=256, bias=True)
    (6): Linear(in_features=256, out_features=128, bias=True)
    (7): Linear(in_features=128, out_features=64, bias=True)
    (8): Linear(in_features=64, out_features=32, bias=True)
    (9): Linear(in_features=32, out_features=16, bias=True)
    (10): Linear(in_features=16, out_features=8, bias=True)
    (11): Linear(in_features=8, out_features=1, bias=True)
  )
  (batch_norms): ModuleList(
    (0): BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (4): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (7): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (9): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (10): BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (11): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (dropout): Dropout(p=0.0, inplace=False)
)
INFO:root:Number of parameters: 89579
INFO:root:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.01
    maximize: False
    weight_decay: 0.0
)
INFO:root:
----------parameters----------
seed: 0
model_path: ./models
output_path: ./outputs
log_path: ./log
debug: False
layers: [2, 8, 16, 32, 64, 128, 256, 128, 64, 32, 16, 8, 1]
learning_rate: 0.01
epochs: 6000
log_epoch_freq: 100
save_epoch_freq: 500
INFO:root:
----------model----------
INFO:root:PINN(
  (activation): Tanh()
  (loss_function): MSELoss()
  (linears): ModuleList(
    (0): Linear(in_features=2, out_features=8, bias=True)
    (1): Linear(in_features=8, out_features=16, bias=True)
    (2): Linear(in_features=16, out_features=32, bias=True)
    (3): Linear(in_features=32, out_features=64, bias=True)
    (4): Linear(in_features=64, out_features=128, bias=True)
    (5): Linear(in_features=128, out_features=256, bias=True)
    (6): Linear(in_features=256, out_features=128, bias=True)
    (7): Linear(in_features=128, out_features=64, bias=True)
    (8): Linear(in_features=64, out_features=32, bias=True)
    (9): Linear(in_features=32, out_features=16, bias=True)
    (10): Linear(in_features=16, out_features=8, bias=True)
    (11): Linear(in_features=8, out_features=1, bias=True)
  )
  (batch_norms): ModuleList(
    (0): BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (4): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (7): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (9): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (10): BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (11): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (dropout): Dropout(p=0.0, inplace=False)
)
INFO:root:Number of parameters: 89579
INFO:root:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.01
    maximize: False
    weight_decay: 0.0
)
INFO:root:
----------parameters----------
seed: 0
model_path: ./models
output_path: ./outputs
log_path: ./log
debug: False
layers: [2, 8, 16, 32, 64, 128, 256, 128, 64, 32, 16, 8, 1]
learning_rate: 0.01
epochs: 6000
log_epoch_freq: 100
save_epoch_freq: 500
INFO:root:
----------parameters----------
seed: 0
model_path: ./models
output_path: ./outputs
log_path: ./log
debug: False
layers: [2, 8, 16, 32, 64, 128, 256, 128, 64, 32, 16, 8, 1]
learning_rate: 0.01
epochs: 6000
log_epoch_freq: 100
save_epoch_freq: 500
INFO:root:
----------parameters----------
seed: 0
model_path: ./models
output_path: ./outputs
log_path: ./log
debug: False
layers: [2, 8, 16, 32, 64, 128, 256, 128, 64, 32, 16, 8, 1]
learning_rate: 0.01
epochs: 6000
log_epoch_freq: 100
save_epoch_freq: 500
INFO:root:
----------parameters----------
seed: 0
model_path: ./models
output_path: ./outputs
log_path: ./log
debug: False
layers: [2, 8, 16, 32, 64, 128, 256, 128, 64, 32, 16, 8, 1]
learning_rate: 0.01
epochs: 6000
log_epoch_freq: 100
save_epoch_freq: 500
INFO:root:
----------parameters----------
seed: 0
model_path: ./models
output_path: ./outputs
log_path: ./log
debug: False
layers: [2, 8, 16, 32, 64, 128, 256, 128, 64, 32, 16, 8, 1]
learning_rate: 0.01
epochs: 6000
log_epoch_freq: 100
save_epoch_freq: 500
INFO:root:
----------parameters----------
seed: 0
model_path: ./models
output_path: ./outputs
log_path: ./log
debug: False
layers: [2, 8, 16, 32, 64, 128, 256, 128, 64, 32, 16, 8, 1]
learning_rate: 0.01
epochs: 6000
log_epoch_freq: 100
save_epoch_freq: 500
INFO:root:
----------parameters----------
seed: 0
model_path: ./models
output_path: ./outputs
log_path: ./log
debug: False
layers: [2, 8, 16, 32, 64, 128, 256, 128, 64, 32, 16, 8, 1]
learning_rate: 0.01
epochs: 6000
log_epoch_freq: 100
save_epoch_freq: 500
INFO:root:
----------parameters----------
seed: 0
model_path: ./models
output_path: ./outputs
log_path: ./log
debug: False
layers: [2, 8, 16, 32, 64, 128, 256, 128, 64, 32, 16, 8, 1]
learning_rate: 0.01
epochs: 6000
log_epoch_freq: 100
save_epoch_freq: 500
INFO:root:
----------parameters----------
seed: 0
model_path: ./models
output_path: ./outputs
log_path: ./log
debug: False
layers: [2, 8, 16, 32, 64, 128, 256, 128, 64, 32, 16, 8, 1]
learning_rate: 0.01
epochs: 6000
log_epoch_freq: 100
save_epoch_freq: 500
INFO:root:
----------parameters----------
seed: 0
model_path: ./models
output_path: ./outputs
log_path: ./log
debug: False
layers: [2, 8, 16, 32, 64, 128, 256, 128, 64, 32, 16, 8, 1]
learning_rate: 0.01
epochs: 6000
log_epoch_freq: 100
save_epoch_freq: 500
INFO:root:
----------model----------
INFO:root:PINN(
  (activation): Tanh()
  (loss_function): MSELoss()
  (linears): ModuleList(
    (0): Linear(in_features=2, out_features=8, bias=True)
    (1): Linear(in_features=8, out_features=16, bias=True)
    (2): Linear(in_features=16, out_features=32, bias=True)
    (3): Linear(in_features=32, out_features=64, bias=True)
    (4): Linear(in_features=64, out_features=128, bias=True)
    (5): Linear(in_features=128, out_features=256, bias=True)
    (6): Linear(in_features=256, out_features=128, bias=True)
    (7): Linear(in_features=128, out_features=64, bias=True)
    (8): Linear(in_features=64, out_features=32, bias=True)
    (9): Linear(in_features=32, out_features=16, bias=True)
    (10): Linear(in_features=16, out_features=8, bias=True)
    (11): Linear(in_features=8, out_features=1, bias=True)
  )
  (batch_norms): ModuleList(
    (0): BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (4): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (7): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (9): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (10): BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (11): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (dropout): Dropout(p=0.0, inplace=False)
)
INFO:root:Number of parameters: 89579
INFO:root:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.01
    maximize: False
    weight_decay: 0.0
)
INFO:root:
----------parameters----------
seed: 0
model_path: ./models
output_path: ./outputs
log_path: ./log
debug: False
layers: [2, 8, 16, 32, 64, 128, 256, 128, 64, 32, 16, 8, 1]
learning_rate: 0.01
epochs: 6000
log_epoch_freq: 100
save_epoch_freq: 500
INFO:root:
----------model----------
INFO:root:PINN(
  (activation): Tanh()
  (loss_function): MSELoss()
  (linears): ModuleList(
    (0): Linear(in_features=2, out_features=8, bias=True)
    (1): Linear(in_features=8, out_features=16, bias=True)
    (2): Linear(in_features=16, out_features=32, bias=True)
    (3): Linear(in_features=32, out_features=64, bias=True)
    (4): Linear(in_features=64, out_features=128, bias=True)
    (5): Linear(in_features=128, out_features=256, bias=True)
    (6): Linear(in_features=256, out_features=128, bias=True)
    (7): Linear(in_features=128, out_features=64, bias=True)
    (8): Linear(in_features=64, out_features=32, bias=True)
    (9): Linear(in_features=32, out_features=16, bias=True)
    (10): Linear(in_features=16, out_features=8, bias=True)
    (11): Linear(in_features=8, out_features=1, bias=True)
  )
  (batch_norms): ModuleList(
    (0): BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (4): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (7): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (9): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (10): BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (11): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (dropout): Dropout(p=0.0, inplace=False)
)
INFO:root:Number of parameters: 89579
INFO:root:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.01
    maximize: False
    weight_decay: 0.0
)
INFO:root:
----------parameters----------
seed: 0
model_path: ./models
output_path: ./outputs
log_path: ./log
debug: False
layers: [2, 8, 16, 32, 64, 128, 256, 128, 64, 32, 16, 8, 1]
learning_rate: 0.01
epochs: 6000
log_epoch_freq: 100
save_epoch_freq: 500
INFO:root:
----------model----------
INFO:root:PINN(
  (activation): Tanh()
  (loss_function): MSELoss()
  (linears): ModuleList(
    (0): Linear(in_features=2, out_features=8, bias=True)
    (1): Linear(in_features=8, out_features=16, bias=True)
    (2): Linear(in_features=16, out_features=32, bias=True)
    (3): Linear(in_features=32, out_features=64, bias=True)
    (4): Linear(in_features=64, out_features=128, bias=True)
    (5): Linear(in_features=128, out_features=256, bias=True)
    (6): Linear(in_features=256, out_features=128, bias=True)
    (7): Linear(in_features=128, out_features=64, bias=True)
    (8): Linear(in_features=64, out_features=32, bias=True)
    (9): Linear(in_features=32, out_features=16, bias=True)
    (10): Linear(in_features=16, out_features=8, bias=True)
    (11): Linear(in_features=8, out_features=1, bias=True)
  )
  (batch_norms): ModuleList(
    (0): BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (4): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (7): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (9): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (10): BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (11): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (dropout): Dropout(p=0.0, inplace=False)
)
INFO:root:Number of parameters: 89579
INFO:root:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.01
    maximize: False
    weight_decay: 0.0
)
INFO:root:
----------parameters----------
seed: 0
model_path: ./models
output_path: ./outputs
log_path: ./log
debug: False
layers: [2, 8, 16, 32, 64, 128, 256, 128, 64, 32, 16, 8, 1]
learning_rate: 0.01
epochs: 6000
log_epoch_freq: 100
save_epoch_freq: 500
INFO:root:
----------model----------
INFO:root:PINN(
  (activation): Tanh()
  (loss_function): MSELoss()
  (linears): ModuleList(
    (0): Linear(in_features=2, out_features=8, bias=True)
    (1): Linear(in_features=8, out_features=16, bias=True)
    (2): Linear(in_features=16, out_features=32, bias=True)
    (3): Linear(in_features=32, out_features=64, bias=True)
    (4): Linear(in_features=64, out_features=128, bias=True)
    (5): Linear(in_features=128, out_features=256, bias=True)
    (6): Linear(in_features=256, out_features=128, bias=True)
    (7): Linear(in_features=128, out_features=64, bias=True)
    (8): Linear(in_features=64, out_features=32, bias=True)
    (9): Linear(in_features=32, out_features=16, bias=True)
    (10): Linear(in_features=16, out_features=8, bias=True)
    (11): Linear(in_features=8, out_features=1, bias=True)
  )
  (batch_norms): ModuleList(
    (0): BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (4): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (7): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (9): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (10): BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (11): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (dropout): Dropout(p=0.0, inplace=False)
)
INFO:root:Number of parameters: 89579
INFO:root:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.01
    maximize: False
    weight_decay: 0.0
)
INFO:root:
----------parameters----------
seed: 0
model_path: ./models
output_path: ./outputs
log_path: ./log
debug: False
layers: [2, 8, 16, 32, 64, 128, 256, 128, 64, 32, 16, 8, 1]
learning_rate: 0.01
epochs: 6000
log_epoch_freq: 100
save_epoch_freq: 500
INFO:root:
----------model----------
INFO:root:PINN(
  (activation): Tanh()
  (loss_function): MSELoss()
  (linears): ModuleList(
    (0): Linear(in_features=2, out_features=8, bias=True)
    (1): Linear(in_features=8, out_features=16, bias=True)
    (2): Linear(in_features=16, out_features=32, bias=True)
    (3): Linear(in_features=32, out_features=64, bias=True)
    (4): Linear(in_features=64, out_features=128, bias=True)
    (5): Linear(in_features=128, out_features=256, bias=True)
    (6): Linear(in_features=256, out_features=128, bias=True)
    (7): Linear(in_features=128, out_features=64, bias=True)
    (8): Linear(in_features=64, out_features=32, bias=True)
    (9): Linear(in_features=32, out_features=16, bias=True)
    (10): Linear(in_features=16, out_features=8, bias=True)
    (11): Linear(in_features=8, out_features=1, bias=True)
  )
  (batch_norms): ModuleList(
    (0): BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (4): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (7): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (9): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (10): BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (11): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (dropout): Dropout(p=0.0, inplace=False)
)
INFO:root:Number of parameters: 89579
INFO:root:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.01
    maximize: False
    weight_decay: 0.0
)
INFO:root:
----------parameters----------
seed: 0
model_path: ./models
output_path: ./outputs
log_path: ./log
debug: False
layers: [2, 8, 16, 32, 64, 128, 256, 128, 64, 32, 16, 8, 1]
learning_rate: 0.01
epochs: 6000
log_epoch_freq: 100
save_epoch_freq: 500
INFO:root:
----------model----------
INFO:root:PINN(
  (activation): Tanh()
  (loss_function): MSELoss()
  (linears): ModuleList(
    (0): Linear(in_features=2, out_features=8, bias=True)
    (1): Linear(in_features=8, out_features=16, bias=True)
    (2): Linear(in_features=16, out_features=32, bias=True)
    (3): Linear(in_features=32, out_features=64, bias=True)
    (4): Linear(in_features=64, out_features=128, bias=True)
    (5): Linear(in_features=128, out_features=256, bias=True)
    (6): Linear(in_features=256, out_features=128, bias=True)
    (7): Linear(in_features=128, out_features=64, bias=True)
    (8): Linear(in_features=64, out_features=32, bias=True)
    (9): Linear(in_features=32, out_features=16, bias=True)
    (10): Linear(in_features=16, out_features=8, bias=True)
    (11): Linear(in_features=8, out_features=1, bias=True)
  )
  (batch_norms): ModuleList(
    (0): BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (4): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (7): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (9): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (10): BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (11): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (dropout): Dropout(p=0.0, inplace=False)
)
INFO:root:Number of parameters: 89579
INFO:root:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.01
    maximize: False
    weight_decay: 0.0
)
INFO:root:
----------parameters----------
seed: 0
model_path: ./models
output_path: ./outputs
log_path: ./log
debug: False
layers: [2, 8, 16, 32, 64, 128, 256, 128, 64, 32, 16, 8, 1]
learning_rate: 0.01
epochs: 6000
log_epoch_freq: 100
save_epoch_freq: 500
INFO:root:
----------model----------
INFO:root:PINN(
  (activation): Tanh()
  (loss_function): MSELoss()
  (linears): ModuleList(
    (0): Linear(in_features=2, out_features=8, bias=True)
    (1): Linear(in_features=8, out_features=16, bias=True)
    (2): Linear(in_features=16, out_features=32, bias=True)
    (3): Linear(in_features=32, out_features=64, bias=True)
    (4): Linear(in_features=64, out_features=128, bias=True)
    (5): Linear(in_features=128, out_features=256, bias=True)
    (6): Linear(in_features=256, out_features=128, bias=True)
    (7): Linear(in_features=128, out_features=64, bias=True)
    (8): Linear(in_features=64, out_features=32, bias=True)
    (9): Linear(in_features=32, out_features=16, bias=True)
    (10): Linear(in_features=16, out_features=8, bias=True)
    (11): Linear(in_features=8, out_features=1, bias=True)
  )
  (batch_norms): ModuleList(
    (0): BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (4): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (7): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (9): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (10): BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (11): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (dropout): Dropout(p=0.0, inplace=False)
)
INFO:root:Number of parameters: 89579
INFO:root:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.01
    maximize: False
    weight_decay: 0.0
)
INFO:root:
----------parameters----------
seed: 0
model_path: ./models
output_path: ./outputs
log_path: ./log
debug: False
layers: [2, 8, 16, 32, 64, 128, 256, 128, 64, 32, 16, 8, 1]
learning_rate: 0.01
epochs: 6000
log_epoch_freq: 100
save_epoch_freq: 500
INFO:root:
----------model----------
INFO:root:PINN(
  (activation): Tanh()
  (loss_function): MSELoss()
  (linears): ModuleList(
    (0): Linear(in_features=2, out_features=8, bias=True)
    (1): Linear(in_features=8, out_features=16, bias=True)
    (2): Linear(in_features=16, out_features=32, bias=True)
    (3): Linear(in_features=32, out_features=64, bias=True)
    (4): Linear(in_features=64, out_features=128, bias=True)
    (5): Linear(in_features=128, out_features=256, bias=True)
    (6): Linear(in_features=256, out_features=128, bias=True)
    (7): Linear(in_features=128, out_features=64, bias=True)
    (8): Linear(in_features=64, out_features=32, bias=True)
    (9): Linear(in_features=32, out_features=16, bias=True)
    (10): Linear(in_features=16, out_features=8, bias=True)
    (11): Linear(in_features=8, out_features=1, bias=True)
  )
  (batch_norms): ModuleList(
    (0): BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (4): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (7): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (9): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (10): BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (11): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (dropout): Dropout(p=0.0, inplace=False)
)
INFO:root:Number of parameters: 89579
INFO:root:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.01
    maximize: False
    weight_decay: 0.0
)
INFO:root:
----------parameters----------
seed: 0
model_path: ./models
output_path: ./outputs
log_path: ./log
debug: False
layers: [2, 8, 16, 32, 64, 128, 256, 128, 64, 32, 16, 8, 1]
learning_rate: 0.01
epochs: 6000
log_epoch_freq: 100
save_epoch_freq: 500
INFO:root:
----------model----------
INFO:root:PINN(
  (activation): Tanh()
  (loss_function): MSELoss()
  (linears): ModuleList(
    (0): Linear(in_features=2, out_features=8, bias=True)
    (1): Linear(in_features=8, out_features=16, bias=True)
    (2): Linear(in_features=16, out_features=32, bias=True)
    (3): Linear(in_features=32, out_features=64, bias=True)
    (4): Linear(in_features=64, out_features=128, bias=True)
    (5): Linear(in_features=128, out_features=256, bias=True)
    (6): Linear(in_features=256, out_features=128, bias=True)
    (7): Linear(in_features=128, out_features=64, bias=True)
    (8): Linear(in_features=64, out_features=32, bias=True)
    (9): Linear(in_features=32, out_features=16, bias=True)
    (10): Linear(in_features=16, out_features=8, bias=True)
    (11): Linear(in_features=8, out_features=1, bias=True)
  )
  (batch_norms): ModuleList(
    (0): BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (4): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (7): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (9): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (10): BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (11): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (dropout): Dropout(p=0.0, inplace=False)
)
INFO:root:Number of parameters: 89579
INFO:root:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.01
    maximize: False
    weight_decay: 0.0
)
INFO:root:
----------parameters----------
seed: 0
model_path: ./models
output_path: ./outputs
log_path: ./log
debug: False
layers: [2, 8, 16, 32, 64, 128, 256, 128, 64, 32, 16, 8, 1]
learning_rate: 0.01
epochs: 6000
log_epoch_freq: 100
save_epoch_freq: 500
INFO:root:
----------model----------
INFO:root:PINN(
  (activation): Tanh()
  (loss_function): MSELoss()
  (linears): ModuleList(
    (0): Linear(in_features=2, out_features=8, bias=True)
    (1): Linear(in_features=8, out_features=16, bias=True)
    (2): Linear(in_features=16, out_features=32, bias=True)
    (3): Linear(in_features=32, out_features=64, bias=True)
    (4): Linear(in_features=64, out_features=128, bias=True)
    (5): Linear(in_features=128, out_features=256, bias=True)
    (6): Linear(in_features=256, out_features=128, bias=True)
    (7): Linear(in_features=128, out_features=64, bias=True)
    (8): Linear(in_features=64, out_features=32, bias=True)
    (9): Linear(in_features=32, out_features=16, bias=True)
    (10): Linear(in_features=16, out_features=8, bias=True)
    (11): Linear(in_features=8, out_features=1, bias=True)
  )
  (batch_norms): ModuleList(
    (0): BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (4): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (7): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (9): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (10): BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (11): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (dropout): Dropout(p=0.0, inplace=False)
)
INFO:root:Number of parameters: 89579
INFO:root:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.01
    maximize: False
    weight_decay: 0.0
)
INFO:root:
----------parameters----------
seed: 0
model_path: ./models
output_path: ./outputs
log_path: ./log
debug: False
layers: [2, 8, 16, 32, 64, 128, 256, 128, 64, 32, 16, 8, 1]
learning_rate: 0.01
epochs: 6000
log_epoch_freq: 100
save_epoch_freq: 500
INFO:root:
----------model----------
INFO:root:PINN(
  (activation): Tanh()
  (loss_function): MSELoss()
  (linears): ModuleList(
    (0): Linear(in_features=2, out_features=8, bias=True)
    (1): Linear(in_features=8, out_features=16, bias=True)
    (2): Linear(in_features=16, out_features=32, bias=True)
    (3): Linear(in_features=32, out_features=64, bias=True)
    (4): Linear(in_features=64, out_features=128, bias=True)
    (5): Linear(in_features=128, out_features=256, bias=True)
    (6): Linear(in_features=256, out_features=128, bias=True)
    (7): Linear(in_features=128, out_features=64, bias=True)
    (8): Linear(in_features=64, out_features=32, bias=True)
    (9): Linear(in_features=32, out_features=16, bias=True)
    (10): Linear(in_features=16, out_features=8, bias=True)
    (11): Linear(in_features=8, out_features=1, bias=True)
  )
  (batch_norms): ModuleList(
    (0): BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (4): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (7): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (9): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (10): BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (11): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (dropout): Dropout(p=0.0, inplace=False)
)
INFO:root:Number of parameters: 89579
INFO:root:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.01
    maximize: False
    weight_decay: 0.0
)
INFO:root:
----------parameters----------
seed: 0
model_path: ./models
output_path: ./outputs
log_path: ./log
debug: False
layers: [2, 8, 16, 32, 64, 128, 256, 128, 64, 32, 16, 8, 1]
learning_rate: 0.01
epochs: 6000
log_epoch_freq: 100
save_epoch_freq: 500
INFO:root:
----------model----------
INFO:root:PINN(
  (activation): Tanh()
  (loss_function): MSELoss()
  (linears): ModuleList(
    (0): Linear(in_features=2, out_features=8, bias=True)
    (1): Linear(in_features=8, out_features=16, bias=True)
    (2): Linear(in_features=16, out_features=32, bias=True)
    (3): Linear(in_features=32, out_features=64, bias=True)
    (4): Linear(in_features=64, out_features=128, bias=True)
    (5): Linear(in_features=128, out_features=256, bias=True)
    (6): Linear(in_features=256, out_features=128, bias=True)
    (7): Linear(in_features=128, out_features=64, bias=True)
    (8): Linear(in_features=64, out_features=32, bias=True)
    (9): Linear(in_features=32, out_features=16, bias=True)
    (10): Linear(in_features=16, out_features=8, bias=True)
    (11): Linear(in_features=8, out_features=1, bias=True)
  )
  (batch_norms): ModuleList(
    (0): BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (4): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (7): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (9): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (10): BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (11): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (dropout): Dropout(p=0.0, inplace=False)
)
INFO:root:Number of parameters: 89579
INFO:root:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.01
    maximize: False
    weight_decay: 0.0
)
INFO:root:
----------parameters----------
seed: 0
model_path: ./models
output_path: ./outputs
log_path: ./log
debug: False
layers: [2, 8, 16, 32, 64, 128, 256, 128, 64, 32, 16, 8, 1]
learning_rate: 0.01
epochs: 6000
log_epoch_freq: 100
save_epoch_freq: 500
INFO:root:
----------model----------
INFO:root:PINN(
  (activation): Tanh()
  (loss_function): MSELoss()
  (linears): ModuleList(
    (0): Linear(in_features=2, out_features=8, bias=True)
    (1): Linear(in_features=8, out_features=16, bias=True)
    (2): Linear(in_features=16, out_features=32, bias=True)
    (3): Linear(in_features=32, out_features=64, bias=True)
    (4): Linear(in_features=64, out_features=128, bias=True)
    (5): Linear(in_features=128, out_features=256, bias=True)
    (6): Linear(in_features=256, out_features=128, bias=True)
    (7): Linear(in_features=128, out_features=64, bias=True)
    (8): Linear(in_features=64, out_features=32, bias=True)
    (9): Linear(in_features=32, out_features=16, bias=True)
    (10): Linear(in_features=16, out_features=8, bias=True)
    (11): Linear(in_features=8, out_features=1, bias=True)
  )
  (batch_norms): ModuleList(
    (0): BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (4): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (7): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (9): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (10): BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (11): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (dropout): Dropout(p=0.0, inplace=False)
)
INFO:root:Number of parameters: 89579
INFO:root:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.01
    maximize: False
    weight_decay: 0.0
)
INFO:root:
----------parameters----------
seed: 0
model_path: ./models
output_path: ./outputs
log_path: ./log
debug: False
layers: [2, 8, 16, 32, 64, 128, 256, 128, 64, 32, 16, 8, 1]
learning_rate: 0.01
epochs: 6000
log_epoch_freq: 100
save_epoch_freq: 500
INFO:root:
----------model----------
INFO:root:PINN(
  (activation): Tanh()
  (loss_function): MSELoss()
  (linears): ModuleList(
    (0): Linear(in_features=2, out_features=8, bias=True)
    (1): Linear(in_features=8, out_features=16, bias=True)
    (2): Linear(in_features=16, out_features=32, bias=True)
    (3): Linear(in_features=32, out_features=64, bias=True)
    (4): Linear(in_features=64, out_features=128, bias=True)
    (5): Linear(in_features=128, out_features=256, bias=True)
    (6): Linear(in_features=256, out_features=128, bias=True)
    (7): Linear(in_features=128, out_features=64, bias=True)
    (8): Linear(in_features=64, out_features=32, bias=True)
    (9): Linear(in_features=32, out_features=16, bias=True)
    (10): Linear(in_features=16, out_features=8, bias=True)
    (11): Linear(in_features=8, out_features=1, bias=True)
  )
  (batch_norms): ModuleList(
    (0): BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (4): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (7): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (9): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (10): BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (11): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (dropout): Dropout(p=0.0, inplace=False)
)
INFO:root:Number of parameters: 89579
INFO:root:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.01
    maximize: False
    weight_decay: 0.0
)
INFO:root:
----------parameters----------
seed: 0
model_path: ./models
output_path: ./outputs
log_path: ./log
debug: False
layers: [2, 8, 16, 32, 64, 128, 256, 128, 64, 32, 16, 8, 1]
learning_rate: 0.01
epochs: 10000
log_epoch_freq: 100
save_epoch_freq: 500
INFO:root:
----------model----------
INFO:root:PINN(
  (activation): Tanh()
  (loss_function): MSELoss()
  (linears): ModuleList(
    (0): Linear(in_features=2, out_features=8, bias=True)
    (1): Linear(in_features=8, out_features=16, bias=True)
    (2): Linear(in_features=16, out_features=32, bias=True)
    (3): Linear(in_features=32, out_features=64, bias=True)
    (4): Linear(in_features=64, out_features=128, bias=True)
    (5): Linear(in_features=128, out_features=256, bias=True)
    (6): Linear(in_features=256, out_features=128, bias=True)
    (7): Linear(in_features=128, out_features=64, bias=True)
    (8): Linear(in_features=64, out_features=32, bias=True)
    (9): Linear(in_features=32, out_features=16, bias=True)
    (10): Linear(in_features=16, out_features=8, bias=True)
    (11): Linear(in_features=8, out_features=1, bias=True)
  )
  (batch_norms): ModuleList(
    (0): BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (4): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (7): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (9): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (10): BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (11): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (dropout): Dropout(p=0.0, inplace=False)
)
INFO:root:Number of parameters: 89579
INFO:root:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.01
    maximize: False
    weight_decay: 0.0
)
INFO:root:
----------parameters----------
seed: 0
model_path: ./models
output_path: ./outputs
log_path: ./log
debug: False
layers: [2, 8, 16, 32, 64, 128, 256, 128, 64, 32, 16, 8, 1]
learning_rate: 0.01
epochs: 10000
log_epoch_freq: 100
save_epoch_freq: 500
INFO:root:
----------model----------
INFO:root:PINN(
  (activation): Tanh()
  (loss_function): MSELoss()
  (linears): ModuleList(
    (0): Linear(in_features=2, out_features=8, bias=True)
    (1): Linear(in_features=8, out_features=16, bias=True)
    (2): Linear(in_features=16, out_features=32, bias=True)
    (3): Linear(in_features=32, out_features=64, bias=True)
    (4): Linear(in_features=64, out_features=128, bias=True)
    (5): Linear(in_features=128, out_features=256, bias=True)
    (6): Linear(in_features=256, out_features=128, bias=True)
    (7): Linear(in_features=128, out_features=64, bias=True)
    (8): Linear(in_features=64, out_features=32, bias=True)
    (9): Linear(in_features=32, out_features=16, bias=True)
    (10): Linear(in_features=16, out_features=8, bias=True)
    (11): Linear(in_features=8, out_features=1, bias=True)
  )
  (batch_norms): ModuleList(
    (0): BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (4): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (7): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (9): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (10): BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (11): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (dropout): Dropout(p=0.0, inplace=False)
)
INFO:root:Number of parameters: 89579
INFO:root:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.01
    maximize: False
    weight_decay: 0.0
)
INFO:root:
----------parameters----------
seed: 0
model_path: ./models
output_path: ./outputs
log_path: ./log
debug: False
layers: [2, 8, 16, 32, 64, 128, 256, 128, 64, 32, 16, 8, 1]
learning_rate: 0.01
epochs: 10000
log_epoch_freq: 100
save_epoch_freq: 500
INFO:root:
----------model----------
INFO:root:PINN(
  (activation): Tanh()
  (loss_function): MSELoss()
  (linears): ModuleList(
    (0): Linear(in_features=2, out_features=8, bias=True)
    (1): Linear(in_features=8, out_features=16, bias=True)
    (2): Linear(in_features=16, out_features=32, bias=True)
    (3): Linear(in_features=32, out_features=64, bias=True)
    (4): Linear(in_features=64, out_features=128, bias=True)
    (5): Linear(in_features=128, out_features=256, bias=True)
    (6): Linear(in_features=256, out_features=128, bias=True)
    (7): Linear(in_features=128, out_features=64, bias=True)
    (8): Linear(in_features=64, out_features=32, bias=True)
    (9): Linear(in_features=32, out_features=16, bias=True)
    (10): Linear(in_features=16, out_features=8, bias=True)
    (11): Linear(in_features=8, out_features=1, bias=True)
  )
  (batch_norms): ModuleList(
    (0): BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (4): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (7): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (9): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (10): BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (11): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (dropout): Dropout(p=0.0, inplace=False)
)
INFO:root:Number of parameters: 89579
INFO:root:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.01
    maximize: False
    weight_decay: 0.0
)
INFO:root:
----------parameters----------
seed: 5648
model_path: ./models
output_path: ./outputs
log_path: ./log
debug: False
layers: [2, 8, 16, 32, 64, 128, 256, 128, 64, 32, 16, 8, 1]
learning_rate: 0.01
epochs: 10000
log_epoch_freq: 100
save_epoch_freq: 500
INFO:root:
----------model----------
INFO:root:PINN(
  (activation): Tanh()
  (loss_function): MSELoss()
  (linears): ModuleList(
    (0): Linear(in_features=2, out_features=8, bias=True)
    (1): Linear(in_features=8, out_features=16, bias=True)
    (2): Linear(in_features=16, out_features=32, bias=True)
    (3): Linear(in_features=32, out_features=64, bias=True)
    (4): Linear(in_features=64, out_features=128, bias=True)
    (5): Linear(in_features=128, out_features=256, bias=True)
    (6): Linear(in_features=256, out_features=128, bias=True)
    (7): Linear(in_features=128, out_features=64, bias=True)
    (8): Linear(in_features=64, out_features=32, bias=True)
    (9): Linear(in_features=32, out_features=16, bias=True)
    (10): Linear(in_features=16, out_features=8, bias=True)
    (11): Linear(in_features=8, out_features=1, bias=True)
  )
  (batch_norms): ModuleList(
    (0): BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (4): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (7): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (9): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (10): BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (11): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (dropout): Dropout(p=0.0, inplace=False)
)
INFO:root:Number of parameters: 89579
INFO:root:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.01
    maximize: False
    weight_decay: 0.0
)
INFO:root:
----------parameters----------
seed: 5648
model_path: ./models
output_path: ./outputs
log_path: ./log
debug: False
layers: [2, 8, 16, 32, 64, 128, 256, 128, 64, 32, 16, 8, 1]
learning_rate: 0.001
epochs: 1000
log_epoch_freq: 100
save_epoch_freq: 500
INFO:root:
----------model----------
INFO:root:PINN(
  (activation): Tanh()
  (loss_function): MSELoss()
  (linears): ModuleList(
    (0): Linear(in_features=2, out_features=8, bias=True)
    (1): Linear(in_features=8, out_features=16, bias=True)
    (2): Linear(in_features=16, out_features=32, bias=True)
    (3): Linear(in_features=32, out_features=64, bias=True)
    (4): Linear(in_features=64, out_features=128, bias=True)
    (5): Linear(in_features=128, out_features=256, bias=True)
    (6): Linear(in_features=256, out_features=128, bias=True)
    (7): Linear(in_features=128, out_features=64, bias=True)
    (8): Linear(in_features=64, out_features=32, bias=True)
    (9): Linear(in_features=32, out_features=16, bias=True)
    (10): Linear(in_features=16, out_features=8, bias=True)
    (11): Linear(in_features=8, out_features=1, bias=True)
  )
  (batch_norms): ModuleList(
    (0): BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (4): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (7): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (9): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (10): BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (11): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (dropout): Dropout(p=0.0, inplace=False)
)
INFO:root:Number of parameters: 89579
INFO:root:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0.0
)
INFO:root:
----------parameters----------
seed: 0
model_path: ./models
output_path: ./outputs
log_path: ./log
debug: False
layers: [2, 128, 128, 128, 1]
learning_rate: 0.001
epochs: 1000
log_epoch_freq: 100
save_epoch_freq: 500
INFO:root:
----------model----------
INFO:root:PINN(
  (activation): Tanh()
  (loss_function): MSELoss()
  (linears): ModuleList(
    (0): Linear(in_features=2, out_features=128, bias=True)
    (1-2): 2 x Linear(in_features=128, out_features=128, bias=True)
    (3): Linear(in_features=128, out_features=1, bias=True)
  )
  (batch_norms): ModuleList(
    (0-2): 3 x BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (dropout): Dropout(p=0.0, inplace=False)
)
INFO:root:Number of parameters: 34307
INFO:root:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0.0
)
INFO:root:
----------parameters----------
seed: 0
model_path: ./models
output_path: ./outputs
log_path: ./log
debug: False
layers: [2, 128, 128, 128, 1]
learning_rate: 0.001
epochs: 2000
log_epoch_freq: 100
save_epoch_freq: 500
INFO:root:
----------model----------
INFO:root:PINN(
  (activation): Tanh()
  (loss_function): MSELoss()
  (linears): ModuleList(
    (0): Linear(in_features=2, out_features=128, bias=True)
    (1-2): 2 x Linear(in_features=128, out_features=128, bias=True)
    (3): Linear(in_features=128, out_features=1, bias=True)
  )
  (batch_norms): ModuleList(
    (0-2): 3 x BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (dropout): Dropout(p=0.0, inplace=False)
)
INFO:root:Number of parameters: 34307
INFO:root:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0.0
)
INFO:root:
----------parameters----------
seed: 0
model_path: ./models
output_path: ./outputs
log_path: ./log
debug: False
layers: [2, 128, 128, 128, 1]
learning_rate: 0.001
epochs: 3000
log_epoch_freq: 100
save_epoch_freq: 500
INFO:root:
----------model----------
INFO:root:PINN(
  (activation): Tanh()
  (loss_function): MSELoss()
  (linears): ModuleList(
    (0): Linear(in_features=2, out_features=128, bias=True)
    (1-2): 2 x Linear(in_features=128, out_features=128, bias=True)
    (3): Linear(in_features=128, out_features=1, bias=True)
  )
  (batch_norms): ModuleList(
    (0-2): 3 x BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (dropout): Dropout(p=0.0, inplace=False)
)
INFO:root:Number of parameters: 34307
INFO:root:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0.0
)
INFO:root:
----------parameters----------
seed: 0
model_path: ./models
output_path: ./outputs
log_path: ./log
debug: False
layers: [2, 128, 128, 128, 1]
learning_rate: 0.001
epochs: 3000
log_epoch_freq: 100
save_epoch_freq: 500
INFO:root:
----------model----------
INFO:root:PINN(
  (activation): Tanh()
  (loss_function): MSELoss()
  (linears): ModuleList(
    (0): Linear(in_features=2, out_features=128, bias=True)
    (1-2): 2 x Linear(in_features=128, out_features=128, bias=True)
    (3): Linear(in_features=128, out_features=1, bias=True)
  )
  (batch_norms): ModuleList(
    (0-2): 3 x BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (dropout): Dropout(p=0.0, inplace=False)
)
INFO:root:Number of parameters: 34307
INFO:root:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0.0
)
INFO:root:
----------parameters----------
seed: 0
model_path: ./models
output_path: ./outputs
log_path: ./log
debug: False
layers: [2, 128, 128, 128, 1]
learning_rate: 0.001
epochs: 3000
log_epoch_freq: 100
save_epoch_freq: 500
INFO:root:
----------model----------
INFO:root:PINN(
  (activation): Tanh()
  (loss_function): MSELoss()
  (linears): ModuleList(
    (0): Linear(in_features=2, out_features=128, bias=True)
    (1-2): 2 x Linear(in_features=128, out_features=128, bias=True)
    (3): Linear(in_features=128, out_features=1, bias=True)
  )
  (batch_norms): ModuleList(
    (0-2): 3 x BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (dropout): Dropout(p=0.0, inplace=False)
)
INFO:root:Number of parameters: 34307
INFO:root:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0.0
)
INFO:root:
----------parameters----------
seed: 0
model_path: ./models
output_path: ./outputs
log_path: ./log
debug: False
layers: [2, 128, 128, 128, 1]
learning_rate: 0.001
epochs: 3000
log_epoch_freq: 100
save_epoch_freq: 500
INFO:root:
----------model----------
INFO:root:PINN(
  (activation): Tanh()
  (loss_function): MSELoss()
  (linears): ModuleList(
    (0): Linear(in_features=2, out_features=128, bias=True)
    (1-2): 2 x Linear(in_features=128, out_features=128, bias=True)
    (3): Linear(in_features=128, out_features=1, bias=True)
  )
  (batch_norms): ModuleList(
    (0-2): 3 x BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (dropout): Dropout(p=0.0, inplace=False)
)
INFO:root:Number of parameters: 34307
INFO:root:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0.0
)
INFO:root:
----------parameters----------
seed: 0
model_path: ./models
output_path: ./outputs
log_path: ./log
debug: False
layers: [2, 128, 128, 128, 1]
learning_rate: 0.001
epochs: 5000
log_epoch_freq: 100
save_epoch_freq: 500
INFO:root:
----------model----------
INFO:root:PINN(
  (activation): Tanh()
  (loss_function): MSELoss()
  (linears): ModuleList(
    (0): Linear(in_features=2, out_features=128, bias=True)
    (1-2): 2 x Linear(in_features=128, out_features=128, bias=True)
    (3): Linear(in_features=128, out_features=1, bias=True)
  )
  (batch_norms): ModuleList(
    (0-2): 3 x BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (dropout): Dropout(p=0.0, inplace=False)
)
INFO:root:Number of parameters: 34307
INFO:root:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0.0
)
INFO:root:
----------parameters----------
seed: 0
model_path: ./models
output_path: ./outputs
log_path: ./log
debug: False
layers: [2, 128, 128, 1]
learning_rate: 0.001
epochs: 5000
log_epoch_freq: 100
save_epoch_freq: 500
INFO:root:
----------model----------
INFO:root:PINN(
  (activation): Tanh()
  (loss_function): MSELoss()
  (linears): ModuleList(
    (0): Linear(in_features=2, out_features=128, bias=True)
    (1): Linear(in_features=128, out_features=128, bias=True)
    (2): Linear(in_features=128, out_features=1, bias=True)
  )
  (batch_norms): ModuleList(
    (0-1): 2 x BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (dropout): Dropout(p=0.0, inplace=False)
)
INFO:root:Number of parameters: 17539
INFO:root:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0.0
)
INFO:root:
----------parameters----------
seed: 0
model_path: ./models
output_path: ./outputs
log_path: ./log
debug: False
layers: [2, 128, 1]
learning_rate: 0.001
epochs: 5000
log_epoch_freq: 100
save_epoch_freq: 500
INFO:root:
----------model----------
INFO:root:PINN(
  (activation): Tanh()
  (loss_function): MSELoss()
  (linears): ModuleList(
    (0): Linear(in_features=2, out_features=128, bias=True)
    (1): Linear(in_features=128, out_features=1, bias=True)
  )
  (batch_norms): ModuleList(
    (0): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (dropout): Dropout(p=0.0, inplace=False)
)
INFO:root:Number of parameters: 771
INFO:root:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0.0
)
INFO:root:
----------parameters----------
seed: 0
model_path: ./models
output_path: ./outputs
log_path: ./log
debug: False
layers: [2, 128, 1]
learning_rate: 0.001
epochs: 5000
log_epoch_freq: 100
save_epoch_freq: 500
INFO:root:
----------model----------
INFO:root:PINN(
  (activation): Tanh()
  (loss_function): MSELoss()
  (linears): ModuleList(
    (0): Linear(in_features=2, out_features=128, bias=True)
    (1): Linear(in_features=128, out_features=1, bias=True)
  )
  (batch_norms): ModuleList(
    (0): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (dropout): Dropout(p=0.0, inplace=False)
)
INFO:root:Number of parameters: 771
INFO:root:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0.0
)
INFO:root:
----------parameters----------
seed: 0
model_path: ./models
output_path: ./outputs
log_path: ./log
debug: False
layers: [2, 256, 1]
learning_rate: 0.001
epochs: 10000
log_epoch_freq: 100
save_epoch_freq: 500
INFO:root:
----------model----------
INFO:root:PINN(
  (activation): Tanh()
  (loss_function): MSELoss()
  (linears): ModuleList(
    (0): Linear(in_features=2, out_features=256, bias=True)
    (1): Linear(in_features=256, out_features=1, bias=True)
  )
  (batch_norms): ModuleList(
    (0): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (dropout): Dropout(p=0.0, inplace=False)
)
INFO:root:Number of parameters: 1539
INFO:root:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0.0
)
INFO:root:
----------parameters----------
seed: 0
model_path: ./models
output_path: ./outputs
log_path: ./log
debug: False
layers: [2, 256, 1]
learning_rate: 0.001
epochs: 10000
log_epoch_freq: 100
save_epoch_freq: 500
INFO:root:
----------model----------
INFO:root:PINN(
  (activation): Tanh()
  (loss_function): MSELoss()
  (linears): ModuleList(
    (0): Linear(in_features=2, out_features=256, bias=True)
    (1): Linear(in_features=256, out_features=1, bias=True)
  )
  (batch_norms): ModuleList(
    (0): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (dropout): Dropout(p=0.0, inplace=False)
)
INFO:root:Number of parameters: 1539
INFO:root:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0.0
)
INFO:root:
----------parameters----------
seed: 0
model_path: ./models
output_path: ./outputs
log_path: ./log
debug: False
layers: [2, 256, 1]
learning_rate: 0.001
epochs: 10000
log_epoch_freq: 100
save_epoch_freq: 500
INFO:root:
----------model----------
INFO:root:PINN(
  (activation): Tanh()
  (loss_function): MSELoss()
  (linears): ModuleList(
    (0): Linear(in_features=2, out_features=256, bias=True)
    (1): Linear(in_features=256, out_features=1, bias=True)
  )
  (batch_norms): ModuleList(
    (0): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (dropout): Dropout(p=0.0, inplace=False)
)
INFO:root:Number of parameters: 1539
INFO:root:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0.0
)
INFO:root:
----------parameters----------
seed: 0
model_path: ./models
output_path: ./outputs
log_path: ./log
debug: False
layers: [2, 256, 256, 1]
learning_rate: 0.001
epochs: 10000
log_epoch_freq: 100
save_epoch_freq: 500
INFO:root:
----------model----------
INFO:root:PINN(
  (activation): Tanh()
  (loss_function): MSELoss()
  (linears): ModuleList(
    (0): Linear(in_features=2, out_features=256, bias=True)
    (1): Linear(in_features=256, out_features=256, bias=True)
    (2): Linear(in_features=256, out_features=1, bias=True)
  )
  (batch_norms): ModuleList(
    (0-1): 2 x BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (dropout): Dropout(p=0.0, inplace=False)
)
INFO:root:Number of parameters: 67843
INFO:root:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0.0
)
INFO:root:
----------parameters----------
seed: 0
model_path: ./models
output_path: ./outputs
log_path: ./log
debug: False
layers: [2, 256, 1]
learning_rate: 0.001
epochs: 2000
log_epoch_freq: 100
save_epoch_freq: 500
INFO:root:
----------model----------
INFO:root:PINN(
  (activation): Tanh()
  (loss_function): MSELoss()
  (linears): ModuleList(
    (0): Linear(in_features=2, out_features=256, bias=True)
    (1): Linear(in_features=256, out_features=1, bias=True)
  )
  (batch_norms): ModuleList(
    (0): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (dropout): Dropout(p=0.0, inplace=False)
)
INFO:root:Number of parameters: 1539
INFO:root:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0.0
)
INFO:root:
----------parameters----------
seed: 0
model_path: ./models
output_path: ./outputs
log_path: ./log
debug: False
layers: [2, 20, 1]
learning_rate: 0.001
epochs: 2000
log_epoch_freq: 100
save_epoch_freq: 500
INFO:root:
----------model----------
INFO:root:PINN(
  (activation): Tanh()
  (loss_function): MSELoss()
  (linears): ModuleList(
    (0): Linear(in_features=2, out_features=20, bias=True)
    (1): Linear(in_features=20, out_features=1, bias=True)
  )
  (batch_norms): ModuleList(
    (0): BatchNorm1d(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (dropout): Dropout(p=0.0, inplace=False)
)
INFO:root:Number of parameters: 123
INFO:root:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0.0
)
INFO:root:
----------parameters----------
seed: 0
model_path: ./models
output_path: ./outputs
log_path: ./log
debug: False
layers: [2, 20, 1]
learning_rate: 0.001
epochs: 5000
log_epoch_freq: 100
save_epoch_freq: 500
INFO:root:
----------model----------
INFO:root:PINN(
  (activation): Tanh()
  (loss_function): MSELoss()
  (linears): ModuleList(
    (0): Linear(in_features=2, out_features=20, bias=True)
    (1): Linear(in_features=20, out_features=1, bias=True)
  )
  (batch_norms): ModuleList(
    (0): BatchNorm1d(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (dropout): Dropout(p=0.0, inplace=False)
)
INFO:root:Number of parameters: 123
INFO:root:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0.0
)
INFO:root:
----------parameters----------
seed: 0
model_path: ./models
output_path: ./outputs
log_path: ./log
debug: False
layers: [2, 20, 1]
learning_rate: 0.005
epochs: 5000
log_epoch_freq: 100
save_epoch_freq: 500
INFO:root:
----------model----------
INFO:root:PINN(
  (activation): Tanh()
  (loss_function): MSELoss()
  (linears): ModuleList(
    (0): Linear(in_features=2, out_features=20, bias=True)
    (1): Linear(in_features=20, out_features=1, bias=True)
  )
  (batch_norms): ModuleList(
    (0): BatchNorm1d(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (dropout): Dropout(p=0.0, inplace=False)
)
INFO:root:Number of parameters: 123
INFO:root:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.005
    maximize: False
    weight_decay: 0.0
)
INFO:root:
----------parameters----------
seed: 0
model_path: ./models
output_path: ./outputs
log_path: ./log
debug: False
layers: [2, 20, 1]
learning_rate: 0.01
epochs: 5000
log_epoch_freq: 100
save_epoch_freq: 500
INFO:root:
----------model----------
INFO:root:PINN(
  (activation): Tanh()
  (loss_function): MSELoss()
  (linears): ModuleList(
    (0): Linear(in_features=2, out_features=20, bias=True)
    (1): Linear(in_features=20, out_features=1, bias=True)
  )
  (batch_norms): ModuleList(
    (0): BatchNorm1d(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (dropout): Dropout(p=0.0, inplace=False)
)
INFO:root:Number of parameters: 123
INFO:root:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.01
    maximize: False
    weight_decay: 0.0
)
INFO:root:
----------parameters----------
seed: 0
model_path: ./models
output_path: ./outputs
log_path: ./log
debug: False
layers: [2, 20, 1]
learning_rate: 0.01
epochs: 5000
log_epoch_freq: 100
save_epoch_freq: 500
INFO:root:
----------model----------
INFO:root:PINN(
  (activation): Tanh()
  (loss_function): MSELoss()
  (linears): ModuleList(
    (0): Linear(in_features=2, out_features=20, bias=True)
    (1): Linear(in_features=20, out_features=1, bias=True)
  )
  (batch_norms): ModuleList(
    (0): BatchNorm1d(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (dropout): Dropout(p=0.0, inplace=False)
)
INFO:root:Number of parameters: 123
INFO:root:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.01
    maximize: False
    weight_decay: 0.0
)
INFO:root:
----------parameters----------
seed: 0
model_path: ./models
output_path: ./outputs
log_path: ./log
debug: False
layers: [2, 20, 1]
learning_rate: 0.01
epochs: 5000
log_epoch_freq: 100
save_epoch_freq: 500
INFO:root:
----------model----------
INFO:root:PINN(
  (activation): Tanh()
  (loss_function): MSELoss()
  (linears): ModuleList(
    (0): Linear(in_features=2, out_features=20, bias=True)
    (1): Linear(in_features=20, out_features=1, bias=True)
  )
  (batch_norms): ModuleList(
    (0): BatchNorm1d(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (dropout): Dropout(p=0.0, inplace=False)
)
INFO:root:Number of parameters: 123
INFO:root:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.01
    maximize: False
    weight_decay: 0.0
)
INFO:root:
----------parameters----------
seed: 0
model_path: ./models
output_path: ./outputs
log_path: ./log
debug: False
layers: [2, 64, 64, 1]
learning_rate: 0.01
epochs: 5000
log_epoch_freq: 100
save_epoch_freq: 500
INFO:root:
----------model----------
INFO:root:PINN(
  (activation): Tanh()
  (loss_function): MSELoss()
  (linears): ModuleList(
    (0): Linear(in_features=2, out_features=64, bias=True)
    (1): Linear(in_features=64, out_features=64, bias=True)
    (2): Linear(in_features=64, out_features=1, bias=True)
  )
  (batch_norms): ModuleList(
    (0-1): 2 x BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (dropout): Dropout(p=0.0, inplace=False)
)
INFO:root:Number of parameters: 4675
INFO:root:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.01
    maximize: False
    weight_decay: 0.0
)
INFO:root:
----------parameters----------
seed: 0
model_path: ./models
output_path: ./outputs
log_path: ./log
debug: False
layers: [2, 64, 64, 1]
learning_rate: 0.1
epochs: 5000
log_epoch_freq: 100
save_epoch_freq: 500
INFO:root:
----------model----------
INFO:root:PINN(
  (activation): Tanh()
  (loss_function): MSELoss()
  (linears): ModuleList(
    (0): Linear(in_features=2, out_features=64, bias=True)
    (1): Linear(in_features=64, out_features=64, bias=True)
    (2): Linear(in_features=64, out_features=1, bias=True)
  )
  (batch_norms): ModuleList(
    (0-1): 2 x BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (dropout): Dropout(p=0.0, inplace=False)
)
INFO:root:Number of parameters: 4675
INFO:root:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.1
    maximize: False
    weight_decay: 0.0
)
INFO:root:
----------parameters----------
seed: 0
model_path: ./models
output_path: ./outputs
log_path: ./log
debug: False
layers: [2, 64, 64, 1]
learning_rate: 0.05
epochs: 5000
log_epoch_freq: 100
save_epoch_freq: 500
INFO:root:
----------model----------
INFO:root:PINN(
  (activation): Tanh()
  (loss_function): MSELoss()
  (linears): ModuleList(
    (0): Linear(in_features=2, out_features=64, bias=True)
    (1): Linear(in_features=64, out_features=64, bias=True)
    (2): Linear(in_features=64, out_features=1, bias=True)
  )
  (batch_norms): ModuleList(
    (0-1): 2 x BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (dropout): Dropout(p=0.0, inplace=False)
)
INFO:root:Number of parameters: 4675
INFO:root:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.05
    maximize: False
    weight_decay: 0.0
)
INFO:root:
----------parameters----------
seed: 0
model_path: ./models
output_path: ./outputs
log_path: ./log
debug: False
layers: [2, 64, 64, 1]
learning_rate: 0.001
epochs: 1000
log_epoch_freq: 100
save_epoch_freq: 500
INFO:root:
----------model----------
INFO:root:PINN(
  (activation): Tanh()
  (loss_function): MSELoss()
  (linears): ModuleList(
    (0): Linear(in_features=2, out_features=64, bias=True)
    (1): Linear(in_features=64, out_features=64, bias=True)
    (2): Linear(in_features=64, out_features=1, bias=True)
  )
  (batch_norms): ModuleList(
    (0-1): 2 x BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (dropout): Dropout(p=0.0, inplace=False)
)
INFO:root:Number of parameters: 4675
INFO:root:SGD (
Parameter Group 0
    dampening: 0
    differentiable: False
    foreach: None
    lr: 0.001
    maximize: False
    momentum: 0
    nesterov: False
    weight_decay: 0
)
INFO:root:
----------parameters----------
seed: 0
model_path: ./models
output_path: ./outputs
log_path: ./log
debug: False
layers: [2, 64, 64, 1]
learning_rate: 0.005
epochs: 5000
log_epoch_freq: 100
save_epoch_freq: 500
INFO:root:
----------model----------
INFO:root:PINN(
  (activation): Tanh()
  (loss_function): MSELoss()
  (linears): ModuleList(
    (0): Linear(in_features=2, out_features=64, bias=True)
    (1): Linear(in_features=64, out_features=64, bias=True)
    (2): Linear(in_features=64, out_features=1, bias=True)
  )
  (batch_norms): ModuleList(
    (0-1): 2 x BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (dropout): Dropout(p=0.0, inplace=False)
)
INFO:root:Number of parameters: 4675
INFO:root:SGD (
Parameter Group 0
    dampening: 0
    differentiable: False
    foreach: None
    lr: 0.005
    maximize: False
    momentum: 0
    nesterov: False
    weight_decay: 0
)
INFO:root:
----------parameters----------
seed: 0
model_path: ./models
output_path: ./outputs
log_path: ./log
debug: False
layers: [2, 64, 64, 1]
learning_rate: 0.01
epochs: 5000
log_epoch_freq: 100
save_epoch_freq: 500
INFO:root:
----------model----------
INFO:root:PINN(
  (activation): Tanh()
  (loss_function): MSELoss()
  (linears): ModuleList(
    (0): Linear(in_features=2, out_features=64, bias=True)
    (1): Linear(in_features=64, out_features=64, bias=True)
    (2): Linear(in_features=64, out_features=1, bias=True)
  )
  (batch_norms): ModuleList(
    (0-1): 2 x BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (dropout): Dropout(p=0.0, inplace=False)
)
INFO:root:Number of parameters: 4675
INFO:root:SGD (
Parameter Group 0
    dampening: 0
    differentiable: False
    foreach: None
    lr: 0.01
    maximize: False
    momentum: 0
    nesterov: False
    weight_decay: 0
)
INFO:root:
----------parameters----------
seed: 0
model_path: ./models
output_path: ./outputs
log_path: ./log
debug: False
layers: [2, 64, 64, 1]
learning_rate: 0.01
epochs: 5000
log_epoch_freq: 100
save_epoch_freq: 500
INFO:root:
----------model----------
INFO:root:PINN(
  (activation): Tanh()
  (loss_function): MSELoss()
  (linears): ModuleList(
    (0): Linear(in_features=2, out_features=64, bias=True)
    (1): Linear(in_features=64, out_features=64, bias=True)
    (2): Linear(in_features=64, out_features=1, bias=True)
  )
  (batch_norms): ModuleList(
    (0-1): 2 x BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (dropout): Dropout(p=0.0, inplace=False)
)
INFO:root:Number of parameters: 4675
INFO:root:SGD (
Parameter Group 0
    dampening: 0
    differentiable: False
    foreach: None
    lr: 0.01
    maximize: False
    momentum: 0
    nesterov: False
    weight_decay: 0
)
INFO:root:
----------parameters----------
seed: 0
model_path: ./models
output_path: ./outputs
log_path: ./log
debug: False
layers: [2, 64, 64, 1]
learning_rate: 0.01
epochs: 10000
log_epoch_freq: 100
save_epoch_freq: 500
INFO:root:
----------model----------
INFO:root:PINN(
  (activation): Tanh()
  (loss_function): MSELoss()
  (linears): ModuleList(
    (0): Linear(in_features=2, out_features=64, bias=True)
    (1): Linear(in_features=64, out_features=64, bias=True)
    (2): Linear(in_features=64, out_features=1, bias=True)
  )
  (batch_norms): ModuleList(
    (0-1): 2 x BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (dropout): Dropout(p=0.0, inplace=False)
)
INFO:root:Number of parameters: 4675
INFO:root:SGD (
Parameter Group 0
    dampening: 0
    differentiable: False
    foreach: None
    lr: 0.01
    maximize: False
    momentum: 0
    nesterov: False
    weight_decay: 0
)
INFO:root:
----------parameters----------
seed: 0
model_path: ./models
output_path: ./outputs
log_path: ./log
debug: False
layers: [2, 64, 64, 1]
learning_rate: 0.01
epochs: 10000
log_epoch_freq: 100
save_epoch_freq: 500
INFO:root:
----------model----------
INFO:root:PINN(
  (activation): Tanh()
  (loss_function): MSELoss()
  (linears): ModuleList(
    (0): Linear(in_features=2, out_features=64, bias=True)
    (1): Linear(in_features=64, out_features=64, bias=True)
    (2): Linear(in_features=64, out_features=1, bias=True)
  )
  (batch_norms): ModuleList(
    (0-1): 2 x BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (dropout): Dropout(p=0.0, inplace=False)
)
INFO:root:Number of parameters: 4675
INFO:root:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.01
    maximize: False
    weight_decay: 0.0
)
INFO:root:
----------parameters----------
seed: 0
model_path: ./models
output_path: ./outputs
log_path: ./log
debug: False
layers: [2, 64, 64, 1]
learning_rate: 0.01
epochs: 10000
log_epoch_freq: 100
save_epoch_freq: 500
INFO:root:
----------model----------
INFO:root:PINN(
  (activation): Tanh()
  (loss_function): MSELoss()
  (linears): ModuleList(
    (0): Linear(in_features=2, out_features=64, bias=True)
    (1): Linear(in_features=64, out_features=64, bias=True)
    (2): Linear(in_features=64, out_features=1, bias=True)
  )
  (batch_norms): ModuleList(
    (0-1): 2 x BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (dropout): Dropout(p=0.0, inplace=False)
)
INFO:root:Number of parameters: 4675
INFO:root:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.01
    maximize: False
    weight_decay: 0.0
)
INFO:root:
----------parameters----------
seed: 0
model_path: ./models
output_path: ./outputs
log_path: ./log
debug: False
layers: [2, 64, 1]
learning_rate: 0.01
epochs: 10000
log_epoch_freq: 100
save_epoch_freq: 500
INFO:root:
----------model----------
INFO:root:PINN(
  (activation): Tanh()
  (loss_function): MSELoss()
  (linears): ModuleList(
    (0): Linear(in_features=2, out_features=64, bias=True)
    (1): Linear(in_features=64, out_features=1, bias=True)
  )
  (batch_norms): ModuleList(
    (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (dropout): Dropout(p=0.0, inplace=False)
)
INFO:root:Number of parameters: 387
INFO:root:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.01
    maximize: False
    weight_decay: 0.0
)
INFO:root:
----------parameters----------
seed: 0
model_path: ./models
output_path: ./outputs
log_path: ./log
debug: False
layers: [2, 64, 1]
learning_rate: 0.01
epochs: 10000
log_epoch_freq: 100
save_epoch_freq: 500
INFO:root:
----------model----------
INFO:root:PINN(
  (activation): Tanh()
  (loss_function): MSELoss()
  (linears): ModuleList(
    (0): Linear(in_features=2, out_features=64, bias=True)
    (1): Linear(in_features=64, out_features=1, bias=True)
  )
  (batch_norms): ModuleList(
    (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (dropout): Dropout(p=0.0, inplace=False)
)
INFO:root:Number of parameters: 387
INFO:root:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.01
    maximize: False
    weight_decay: 0.0
)
INFO:root:
----------parameters----------
seed: 0
model_path: ./models
output_path: ./outputs
log_path: ./log
debug: False
layers: [2, 64, 1]
learning_rate: 0.01
epochs: 10000
log_epoch_freq: 100
save_epoch_freq: 500
INFO:root:
----------model----------
INFO:root:PINN(
  (activation): Tanh()
  (loss_function): MSELoss()
  (linears): ModuleList(
    (0): Linear(in_features=2, out_features=64, bias=True)
    (1): Linear(in_features=64, out_features=1, bias=True)
  )
  (batch_norms): ModuleList(
    (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (dropout): Dropout(p=0.0, inplace=False)
)
INFO:root:Number of parameters: 387
INFO:root:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.01
    maximize: False
    weight_decay: 0.0
)
INFO:root:
----------parameters----------
seed: 0
model_path: ./models
output_path: ./outputs
log_path: ./log
debug: False
layers: [2, 64, 1]
learning_rate: 0.01
epochs: 10000
log_epoch_freq: 100
save_epoch_freq: 500
INFO:root:
----------model----------
INFO:root:PINN(
  (activation): Tanh()
  (loss_function): MSELoss()
  (linears): ModuleList(
    (0): Linear(in_features=2, out_features=64, bias=True)
    (1): Linear(in_features=64, out_features=1, bias=True)
  )
  (batch_norms): ModuleList(
    (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (dropout): Dropout(p=0.0, inplace=False)
)
INFO:root:Number of parameters: 387
INFO:root:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.01
    maximize: False
    weight_decay: 0.0
)
INFO:root:
----------parameters----------
seed: 0
model_path: ./models
output_path: ./outputs
log_path: ./log
debug: False
layers: [2, 64, 64, 1]
learning_rate: 0.01
epochs: 10000
log_epoch_freq: 100
save_epoch_freq: 500
INFO:root:
----------model----------
INFO:root:PINN(
  (activation): Tanh()
  (loss_function): MSELoss()
  (linears): ModuleList(
    (0): Linear(in_features=2, out_features=64, bias=True)
    (1): Linear(in_features=64, out_features=64, bias=True)
    (2): Linear(in_features=64, out_features=1, bias=True)
  )
  (batch_norms): ModuleList(
    (0-1): 2 x BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (dropout): Dropout(p=0.0, inplace=False)
)
INFO:root:Number of parameters: 4675
INFO:root:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.01
    maximize: False
    weight_decay: 0.0
)
INFO:root:
----------parameters----------
seed: 0
model_path: ./models
output_path: ./outputs
log_path: ./log
debug: False
layers: [2, 64, 64, 1]
learning_rate: 0.01
epochs: 10000
log_epoch_freq: 100
save_epoch_freq: 500
INFO:root:
----------model----------
INFO:root:PINN(
  (activation): Tanh()
  (loss_function): MSELoss()
  (linears): ModuleList(
    (0): Linear(in_features=2, out_features=64, bias=True)
    (1): Linear(in_features=64, out_features=64, bias=True)
    (2): Linear(in_features=64, out_features=1, bias=True)
  )
  (batch_norms): ModuleList(
    (0-1): 2 x BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (dropout): Dropout(p=0.0, inplace=False)
)
INFO:root:Number of parameters: 4675
INFO:root:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.01
    maximize: False
    weight_decay: 0.0
)
INFO:root:
----------parameters----------
seed: 0
model_path: ./models
output_path: ./outputs
log_path: ./log
debug: False
layers: [2, 64, 64, 1]
learning_rate: 0.01
epochs: 10000
log_epoch_freq: 100
save_epoch_freq: 500
INFO:root:
----------model----------
INFO:root:PINN(
  (activation): Tanh()
  (loss_function): MSELoss()
  (linears): ModuleList(
    (0): Linear(in_features=2, out_features=64, bias=True)
    (1): Linear(in_features=64, out_features=64, bias=True)
    (2): Linear(in_features=64, out_features=1, bias=True)
  )
  (batch_norms): ModuleList(
    (0-1): 2 x BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (dropout): Dropout(p=0.0, inplace=False)
)
INFO:root:Number of parameters: 4675
INFO:root:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.01
    maximize: False
    weight_decay: 0.0
)
INFO:root:
----------parameters----------
seed: 0
model_path: ./models
output_path: ./outputs
log_path: ./log
debug: False
layers: [2, 64, 64, 1]
learning_rate: 0.01
epochs: 10000
log_epoch_freq: 100
save_epoch_freq: 500
INFO:root:
----------model----------
INFO:root:PINN(
  (activation): Tanh()
  (loss_function): MSELoss()
  (linears): ModuleList(
    (0): Linear(in_features=2, out_features=64, bias=True)
    (1): Linear(in_features=64, out_features=64, bias=True)
    (2): Linear(in_features=64, out_features=1, bias=True)
  )
  (batch_norms): ModuleList(
    (0-1): 2 x BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (dropout): Dropout(p=0.0, inplace=False)
)
INFO:root:Number of parameters: 4675
INFO:root:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.01
    maximize: False
    weight_decay: 0.0
)
INFO:root:
----------parameters----------
seed: 0
model_path: ./models
output_path: ./outputs
log_path: ./log
debug: False
layers: [2, 64, 64, 1]
learning_rate: 0.01
epochs: 10000
log_epoch_freq: 100
save_epoch_freq: 500
INFO:root:
----------model----------
INFO:root:PINN(
  (activation): Tanh()
  (loss_function): MSELoss()
  (linears): ModuleList(
    (0): Linear(in_features=2, out_features=64, bias=True)
    (1): Linear(in_features=64, out_features=64, bias=True)
    (2): Linear(in_features=64, out_features=1, bias=True)
  )
  (batch_norms): ModuleList(
    (0-1): 2 x BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (dropout): Dropout(p=0.0, inplace=False)
)
INFO:root:Number of parameters: 4675
INFO:root:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.01
    maximize: False
    weight_decay: 0.0
)
INFO:root:
----------parameters----------
seed: 0
model_path: ./models
output_path: ./outputs
log_path: ./log
debug: False
layers: [2, 64, 64, 1]
learning_rate: 0.01
epochs: 10000
log_epoch_freq: 100
save_epoch_freq: 500
INFO:root:
----------model----------
INFO:root:PINN(
  (activation): Tanh()
  (loss_function): MSELoss()
  (linears): ModuleList(
    (0): Linear(in_features=2, out_features=64, bias=True)
    (1): Linear(in_features=64, out_features=64, bias=True)
    (2): Linear(in_features=64, out_features=1, bias=True)
  )
  (batch_norms): ModuleList(
    (0-1): 2 x BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (dropout): Dropout(p=0.0, inplace=False)
)
INFO:root:Number of parameters: 4675
INFO:root:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.01
    maximize: False
    weight_decay: 0.0
)
INFO:root:
----------parameters----------
seed: 0
model_path: ./models
output_path: ./outputs
log_path: ./log
debug: False
layers: [2, 64, 64, 1]
learning_rate: 0.01
epochs: 10000
log_epoch_freq: 100
save_epoch_freq: 500
INFO:root:
----------parameters----------
seed: 0
model_path: ./models
output_path: ./outputs
log_path: ./log
debug: False
layers: [2, 64, 64, 1]
learning_rate: 0.01
epochs: 10000
log_epoch_freq: 100
save_epoch_freq: 500
INFO:root:
----------model----------
INFO:root:PINN(
  (activation): Tanh()
  (loss_function): MSELoss()
  (linears): ModuleList(
    (0): Linear(in_features=2, out_features=64, bias=True)
    (1): Linear(in_features=64, out_features=64, bias=True)
    (2): Linear(in_features=64, out_features=1, bias=True)
  )
  (batch_norms): ModuleList(
    (0-1): 2 x BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (dropout): Dropout(p=0.0, inplace=False)
)
INFO:root:Number of parameters: 4675
INFO:root:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.01
    maximize: False
    weight_decay: 0.0
)
INFO:root:
----------parameters----------
seed: 0
model_path: ./models
output_path: ./outputs
log_path: ./log
debug: False
layers: [2, 64, 64, 1]
learning_rate: 0.01
epochs: 10000
log_epoch_freq: 100
save_epoch_freq: 500
INFO:root:
----------model----------
INFO:root:PINN(
  (activation): Tanh()
  (loss_function): MSELoss()
  (linears): ModuleList(
    (0): Linear(in_features=2, out_features=64, bias=True)
    (1): Linear(in_features=64, out_features=64, bias=True)
    (2): Linear(in_features=64, out_features=1, bias=True)
  )
  (batch_norms): ModuleList(
    (0-1): 2 x BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (dropout): Dropout(p=0.0, inplace=False)
)
INFO:root:Number of parameters: 4675
INFO:root:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.01
    maximize: False
    weight_decay: 0.0
)
INFO:root:
----------parameters----------
seed: 0
model_path: ./models
output_path: ./outputs
log_path: ./log
debug: False
layers: [2, 64, 64, 1]
learning_rate: 0.01
epochs: 10000
log_epoch_freq: 100
save_epoch_freq: 500
INFO:root:
----------model----------
INFO:root:PINN(
  (activation): Tanh()
  (loss_function): MSELoss()
  (linears): ModuleList(
    (0): Linear(in_features=2, out_features=64, bias=True)
    (1): Linear(in_features=64, out_features=64, bias=True)
    (2): Linear(in_features=64, out_features=1, bias=True)
  )
  (batch_norms): ModuleList(
    (0-1): 2 x BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (dropout): Dropout(p=0.0, inplace=False)
)
INFO:root:Number of parameters: 4675
INFO:root:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.01
    maximize: False
    weight_decay: 0.0
)
INFO:root:
----------parameters----------
seed: 0
model_path: ./models
output_path: ./outputs
log_path: ./log
debug: False
layers: [2, 64, 64, 1]
learning_rate: 0.01
epochs: 10000
log_epoch_freq: 100
save_epoch_freq: 500
INFO:root:
----------model----------
INFO:root:PINN(
  (activation): Tanh()
  (loss_function): MSELoss()
  (linears): ModuleList(
    (0): Linear(in_features=2, out_features=64, bias=True)
    (1): Linear(in_features=64, out_features=64, bias=True)
    (2): Linear(in_features=64, out_features=1, bias=True)
  )
  (batch_norms): ModuleList(
    (0-1): 2 x BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (dropout): Dropout(p=0.0, inplace=False)
)
INFO:root:Number of parameters: 4675
INFO:root:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.01
    maximize: False
    weight_decay: 0.0
)
INFO:root:
----------parameters----------
seed: 0
model_path: ./models
output_path: ./outputs
log_path: ./log
debug: False
layers: [2, 64, 64, 1]
learning_rate: 0.01
epochs: 10000
log_epoch_freq: 100
save_epoch_freq: 500
INFO:root:
----------model----------
INFO:root:PINN(
  (activation): Tanh()
  (loss_function): MSELoss()
  (linears): ModuleList(
    (0): Linear(in_features=2, out_features=64, bias=True)
    (1): Linear(in_features=64, out_features=64, bias=True)
    (2): Linear(in_features=64, out_features=1, bias=True)
  )
  (batch_norms): ModuleList(
    (0-1): 2 x BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (dropout): Dropout(p=0.0, inplace=False)
)
INFO:root:Number of parameters: 4675
INFO:root:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.01
    maximize: False
    weight_decay: 0.0
)
INFO:root:
----------parameters----------
seed: 0
model_path: ./models
output_path: ./outputs
log_path: ./log
debug: False
layers: [2, 6, 1]
learning_rate: 0.01
epochs: 10000
log_epoch_freq: 100
save_epoch_freq: 500
INFO:root:
----------model----------
INFO:root:PINN(
  (activation): Tanh()
  (loss_function): MSELoss()
  (linears): ModuleList(
    (0): Linear(in_features=2, out_features=6, bias=True)
    (1): Linear(in_features=6, out_features=1, bias=True)
  )
  (batch_norms): ModuleList(
    (0): BatchNorm1d(6, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (dropout): Dropout(p=0.0, inplace=False)
)
INFO:root:Number of parameters: 39
INFO:root:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.01
    maximize: False
    weight_decay: 0.0
)
INFO:root:
----------parameters----------
seed: 0
model_path: ./models
output_path: ./outputs
log_path: ./log
debug: False
layers: [2, 6, 1]
learning_rate: 0.01
epochs: 10000
log_epoch_freq: 100
save_epoch_freq: 500
INFO:root:
----------model----------
INFO:root:PINN(
  (activation): Tanh()
  (loss_function): MSELoss()
  (linears): ModuleList(
    (0): Linear(in_features=2, out_features=6, bias=True)
    (1): Linear(in_features=6, out_features=1, bias=True)
  )
  (batch_norms): ModuleList(
    (0): BatchNorm1d(6, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (dropout): Dropout(p=0.0, inplace=False)
)
INFO:root:Number of parameters: 39
INFO:root:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.01
    maximize: False
    weight_decay: 0.0
)
INFO:root:
----------parameters----------
seed: 0
model_path: ./models
output_path: ./outputs
log_path: ./log
debug: False
layers: [2, 8, 1]
learning_rate: 0.01
epochs: 20000
log_epoch_freq: 100
save_epoch_freq: 500
INFO:root:
----------model----------
INFO:root:PINN(
  (activation): Tanh()
  (loss_function): MSELoss()
  (linears): ModuleList(
    (0): Linear(in_features=2, out_features=8, bias=True)
    (1): Linear(in_features=8, out_features=1, bias=True)
  )
  (batch_norms): ModuleList(
    (0): BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (dropout): Dropout(p=0.0, inplace=False)
)
INFO:root:Number of parameters: 51
INFO:root:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.01
    maximize: False
    weight_decay: 0.0
)
INFO:root:
----------parameters----------
seed: 0
model_path: ./models
output_path: ./outputs
log_path: ./log
debug: False
layers: [2, 8, 1]
learning_rate: 0.01
epochs: 20000
log_epoch_freq: 100
save_epoch_freq: 500
INFO:root:
----------model----------
INFO:root:PINN(
  (activation): Tanh()
  (loss_function): MSELoss()
  (linears): ModuleList(
    (0): Linear(in_features=2, out_features=8, bias=True)
    (1): Linear(in_features=8, out_features=1, bias=True)
  )
  (batch_norms): ModuleList(
    (0): BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (dropout): Dropout(p=0.0, inplace=False)
)
INFO:root:Number of parameters: 51
INFO:root:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.01
    maximize: False
    weight_decay: 0.0
)
INFO:root:
----------parameters----------
seed: 0
model_path: ./models
output_path: ./outputs
log_path: ./log
debug: False
layers: [2, 8, 1]
learning_rate: 0.01
epochs: 20000
log_epoch_freq: 100
save_epoch_freq: 500
INFO:root:
----------model----------
INFO:root:PINN(
  (activation): Tanh()
  (loss_function): MSELoss()
  (linears): ModuleList(
    (0): Linear(in_features=2, out_features=8, bias=True)
    (1): Linear(in_features=8, out_features=1, bias=True)
  )
  (batch_norms): ModuleList(
    (0): BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (dropout): Dropout(p=0.0, inplace=False)
)
INFO:root:Number of parameters: 51
INFO:root:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.01
    maximize: False
    weight_decay: 0.0
)
INFO:root:
----------parameters----------
seed: 0
model_path: ./models
output_path: ./outputs
log_path: ./log
debug: False
layers: [2, 8, 1]
learning_rate: 0.01
epochs: 50000
log_epoch_freq: 100
save_epoch_freq: 1000
INFO:root:
----------model----------
INFO:root:PINN(
  (activation): Tanh()
  (loss_function): MSELoss()
  (linears): ModuleList(
    (0): Linear(in_features=2, out_features=8, bias=True)
    (1): Linear(in_features=8, out_features=1, bias=True)
  )
  (batch_norms): ModuleList(
    (0): BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (dropout): Dropout(p=0.0, inplace=False)
)
INFO:root:Number of parameters: 51
INFO:root:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.01
    maximize: False
    weight_decay: 0.0
)
INFO:root:
----------parameters----------
seed: 0
model_path: ./models
output_path: ./outputs
log_path: ./log
debug: False
layers: [2, 8, 1]
learning_rate: 0.01
epochs: 10000
log_epoch_freq: 100
save_epoch_freq: 1000
INFO:root:
----------parameters----------
seed: 0
model_path: ./models
output_path: ./outputs
log_path: ./log
debug: False
layers: [2, 8, 1]
learning_rate: 0.01
epochs: 10000
log_epoch_freq: 100
save_epoch_freq: 1000
INFO:root:
----------parameters----------
seed: 0
model_path: ./models
output_path: ./outputs
log_path: ./log
debug: False
layers: [2, 8, 1]
learning_rate: 0.01
epochs: 10000
log_epoch_freq: 100
save_epoch_freq: 1000
INFO:root:
----------parameters----------
seed: 0
model_path: ./models
output_path: ./outputs
log_path: ./log
debug: False
layers: [2, 8, 1]
learning_rate: 0.01
epochs: 10000
log_epoch_freq: 100
save_epoch_freq: 1000
INFO:root:
----------parameters----------
seed: 0
model_path: ./models
output_path: ./outputs
log_path: ./log
debug: False
layers: [2, 8, 1]
learning_rate: 0.01
epochs: 1000
log_epoch_freq: 100
save_epoch_freq: 100
INFO:root:
----------parameters----------
seed: 0
model_path: ./models
output_path: ./outputs
log_path: ./log
debug: False
layers: [2, 8, 1]
learning_rate: 0.01
epochs: 1000
log_epoch_freq: 100
save_epoch_freq: 100
INFO:root:
----------parameters----------
seed: 0
model_path: ./models
output_path: ./outputs
log_path: ./log
debug: False
layers: [2, 8, 1]
learning_rate: 0.01
epochs: 1000
log_epoch_freq: 100
save_epoch_freq: 100
INFO:root:
----------model----------
INFO:root:PINN(
  (activation): Tanh()
  (loss_function): MSELoss()
  (linears): ModuleList(
    (0): Linear(in_features=2, out_features=8, bias=True)
    (1): Linear(in_features=8, out_features=1, bias=True)
  )
  (batch_norms): ModuleList(
    (0): BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (dropout): Dropout(p=0.0, inplace=False)
)
INFO:root:Number of parameters: 51
INFO:root:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.01
    maximize: False
    weight_decay: 0.0
)
INFO:root:
----------parameters----------
seed: 0
model_path: ./models
output_path: ./outputs
log_path: ./log
debug: False
layers: [2, 8, 1]
learning_rate: 0.01
epochs: 2000
log_epoch_freq: 100
save_epoch_freq: 100
INFO:root:
----------model----------
INFO:root:PINN(
  (activation): Tanh()
  (loss_function): MSELoss()
  (linears): ModuleList(
    (0): Linear(in_features=2, out_features=8, bias=True)
    (1): Linear(in_features=8, out_features=1, bias=True)
  )
  (batch_norms): ModuleList(
    (0): BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (dropout): Dropout(p=0.0, inplace=False)
)
INFO:root:Number of parameters: 51
INFO:root:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.01
    maximize: False
    weight_decay: 0.0
)
INFO:root:
----------parameters----------
seed: 0
model_path: ./models
output_path: ./outputs
log_path: ./log
debug: False
layers: [2, 16, 1]
learning_rate: 0.01
epochs: 2000
log_epoch_freq: 100
save_epoch_freq: 100
INFO:root:
----------model----------
INFO:root:PINN(
  (activation): Tanh()
  (loss_function): MSELoss()
  (linears): ModuleList(
    (0): Linear(in_features=2, out_features=16, bias=True)
    (1): Linear(in_features=16, out_features=1, bias=True)
  )
  (batch_norms): ModuleList(
    (0): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (dropout): Dropout(p=0.0, inplace=False)
)
INFO:root:Number of parameters: 99
INFO:root:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.01
    maximize: False
    weight_decay: 0.0
)
INFO:root:
----------parameters----------
seed: 0
model_path: ./models
output_path: ./outputs
log_path: ./log
debug: False
layers: [2, 32, 1]
learning_rate: 0.01
epochs: 2000
log_epoch_freq: 100
save_epoch_freq: 100
INFO:root:
----------model----------
INFO:root:PINN(
  (activation): Tanh()
  (loss_function): MSELoss()
  (linears): ModuleList(
    (0): Linear(in_features=2, out_features=32, bias=True)
    (1): Linear(in_features=32, out_features=1, bias=True)
  )
  (batch_norms): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (dropout): Dropout(p=0.0, inplace=False)
)
INFO:root:Number of parameters: 195
INFO:root:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.01
    maximize: False
    weight_decay: 0.0
)
INFO:root:
----------parameters----------
seed: 0
model_path: ./models
output_path: ./outputs
log_path: ./log
debug: False
layers: [2, 32, 1]
learning_rate: 0.001
epochs: 5000
log_epoch_freq: 100
save_epoch_freq: 100
INFO:root:
----------model----------
INFO:root:PINN(
  (activation): Tanh()
  (loss_function): MSELoss()
  (linears): ModuleList(
    (0): Linear(in_features=2, out_features=32, bias=True)
    (1): Linear(in_features=32, out_features=1, bias=True)
  )
  (batch_norms): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (dropout): Dropout(p=0.0, inplace=False)
)
INFO:root:Number of parameters: 195
INFO:root:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0.0
)
INFO:root:
----------parameters----------
seed: 2359
model_path: ./models
output_path: ./outputs
log_path: ./log
debug: False
layers: [2, 32, 1]
learning_rate: 0.001
epochs: 5000
log_epoch_freq: 100
save_epoch_freq: 100
INFO:root:
----------model----------
INFO:root:PINN(
  (activation): Tanh()
  (loss_function): MSELoss()
  (linears): ModuleList(
    (0): Linear(in_features=2, out_features=32, bias=True)
    (1): Linear(in_features=32, out_features=1, bias=True)
  )
  (batch_norms): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (dropout): Dropout(p=0.0, inplace=False)
)
INFO:root:Number of parameters: 195
INFO:root:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0.0
)
INFO:root:
----------parameters----------
seed: 2359
model_path: ./models
output_path: ./outputs
log_path: ./log
debug: False
layers: [2, 32, 1]
learning_rate: 0.001
epochs: 10000
log_epoch_freq: 100
save_epoch_freq: 1000
INFO:root:
----------model----------
INFO:root:PINN(
  (activation): Tanh()
  (loss_function): MSELoss()
  (linears): ModuleList(
    (0): Linear(in_features=2, out_features=32, bias=True)
    (1): Linear(in_features=32, out_features=1, bias=True)
  )
  (batch_norms): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (dropout): Dropout(p=0.0, inplace=False)
)
INFO:root:Number of parameters: 195
INFO:root:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0.0
)
INFO:root:
----------parameters----------
seed: 2359
model_path: ./models
output_path: ./outputs
log_path: ./log
debug: False
layers: [2, 32, 1]
learning_rate: 0.001
epochs: 50000
log_epoch_freq: 100
save_epoch_freq: 5000
INFO:root:
----------model----------
INFO:root:PINN(
  (activation): Tanh()
  (loss_function): MSELoss()
  (linears): ModuleList(
    (0): Linear(in_features=2, out_features=32, bias=True)
    (1): Linear(in_features=32, out_features=1, bias=True)
  )
  (batch_norms): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (dropout): Dropout(p=0.0, inplace=False)
)
INFO:root:Number of parameters: 195
INFO:root:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0.0
)
INFO:root:
----------parameters----------
seed: 2359
model_path: ./models
output_path: ./outputs
log_path: ./log
debug: False
layers: [2, 32, 1]
learning_rate: 0.001
epochs: 50000
log_epoch_freq: 100
save_epoch_freq: 5000
INFO:root:
----------model----------
INFO:root:PINN(
  (activation): Tanh()
  (loss_function): MSELoss()
  (linears): ModuleList(
    (0): Linear(in_features=2, out_features=32, bias=True)
    (1): Linear(in_features=32, out_features=1, bias=True)
  )
  (batch_norms): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (dropout): Dropout(p=0.0, inplace=False)
)
INFO:root:Number of parameters: 195
INFO:root:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0.0
)
INFO:root:
----------parameters----------
seed: 2359
model_path: ./models
output_path: ./outputs
log_path: ./log
debug: False
layers: [2, 32, 1]
learning_rate: 0.001
epochs: 50000
log_epoch_freq: 100
save_epoch_freq: 5000
INFO:root:
----------model----------
INFO:root:PINN(
  (activation): Tanh()
  (loss_function): MSELoss()
  (linears): ModuleList(
    (0): Linear(in_features=2, out_features=32, bias=True)
    (1): Linear(in_features=32, out_features=1, bias=True)
  )
  (batch_norms): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (dropout): Dropout(p=0.0, inplace=False)
)
INFO:root:Number of parameters: 195
INFO:root:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0.0
)
INFO:root:
----------parameters----------
seed: 2359
model_path: ./models
output_path: ./outputs
log_path: ./log
debug: False
layers: [2, 32, 1]
learning_rate: 0.001
epochs: 50000
log_epoch_freq: 100
save_epoch_freq: 5000
INFO:root:
----------model----------
INFO:root:PINN(
  (activation): Tanh()
  (loss_function): MSELoss()
  (linears): ModuleList(
    (0): Linear(in_features=2, out_features=32, bias=True)
    (1): Linear(in_features=32, out_features=1, bias=True)
  )
  (batch_norms): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (dropout): Dropout(p=0.0, inplace=False)
)
INFO:root:Number of parameters: 195
INFO:root:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0.0
)
INFO:root:
----------parameters----------
seed: 2359
model_path: ./models
output_path: ./outputs
log_path: ./log
debug: False
layers: [2, 32, 1]
learning_rate: 0.001
epochs: 50000
log_epoch_freq: 100
save_epoch_freq: 5000
INFO:root:
----------model----------
INFO:root:PINN(
  (activation): Sigmoid()
  (loss_function): MSELoss()
  (linears): ModuleList(
    (0): Linear(in_features=2, out_features=32, bias=True)
    (1): Linear(in_features=32, out_features=1, bias=True)
  )
  (batch_norms): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (dropout): Dropout(p=0.0, inplace=False)
)
INFO:root:Number of parameters: 195
INFO:root:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0.0
)
INFO:root:
----------parameters----------
seed: 2359
model_path: ./models
output_path: ./outputs
log_path: ./log
debug: False
layers: [2, 16, 16, 1]
learning_rate: 0.001
epochs: 50000
log_epoch_freq: 100
save_epoch_freq: 5000
INFO:root:
----------model----------
INFO:root:PINN(
  (activation): Tanh()
  (loss_function): MSELoss()
  (linears): ModuleList(
    (0): Linear(in_features=2, out_features=16, bias=True)
    (1): Linear(in_features=16, out_features=16, bias=True)
    (2): Linear(in_features=16, out_features=1, bias=True)
  )
  (batch_norms): ModuleList(
    (0-1): 2 x BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (dropout): Dropout(p=0.0, inplace=False)
)
INFO:root:Number of parameters: 403
INFO:root:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0.0
)
INFO:root:
----------parameters----------
seed: 2359
model_path: ./models
output_path: ./outputs
log_path: ./log
debug: False
layers: [2, 16, 16, 1]
learning_rate: 0.001
epochs: 50000
log_epoch_freq: 100
save_epoch_freq: 5000
INFO:root:
----------model----------
INFO:root:PINN(
  (activation): Tanh()
  (loss_function): MSELoss()
  (linears): ModuleList(
    (0): Linear(in_features=2, out_features=16, bias=True)
    (1): Linear(in_features=16, out_features=16, bias=True)
    (2): Linear(in_features=16, out_features=1, bias=True)
  )
  (batch_norms): ModuleList(
    (0-1): 2 x BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (dropout): Dropout(p=0.0, inplace=False)
)
INFO:root:Number of parameters: 403
INFO:root:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0.0
)
INFO:root:
----------parameters----------
seed: 2359
model_path: ./models
output_path: ./outputs
log_path: ./log
debug: False
layers: [2, 16, 16, 1]
learning_rate: 0.001
epochs: 50000
log_epoch_freq: 100
save_epoch_freq: 5000
INFO:root:
----------model----------
INFO:root:PINN(
  (activation): Tanh()
  (loss_function): MSELoss()
  (linears): ModuleList(
    (0): Linear(in_features=2, out_features=16, bias=True)
    (1): Linear(in_features=16, out_features=16, bias=True)
    (2): Linear(in_features=16, out_features=1, bias=True)
  )
  (batch_norms): ModuleList(
    (0-1): 2 x BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (dropout): Dropout(p=0.0, inplace=False)
)
INFO:root:Number of parameters: 403
INFO:root:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0.0
)
INFO:root:
----------parameters----------
seed: 2359
model_path: ./models
output_path: ./outputs
log_path: ./log
debug: False
layers: [2, 16, 16, 1]
learning_rate: 0.001
epochs: 50000
log_epoch_freq: 100
save_epoch_freq: 5000
INFO:root:
----------model----------
INFO:root:PINN(
  (activation): Tanh()
  (loss_function): MSELoss()
  (linears): ModuleList(
    (0): Linear(in_features=2, out_features=16, bias=True)
    (1): Linear(in_features=16, out_features=16, bias=True)
    (2): Linear(in_features=16, out_features=1, bias=True)
  )
  (batch_norms): ModuleList(
    (0-1): 2 x BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (dropout): Dropout(p=0.0, inplace=False)
)
INFO:root:Number of parameters: 403
INFO:root:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0.0
)
INFO:root:
----------parameters----------
seed: 2359
model_path: ./models
output_path: ./outputs
log_path: ./log
debug: False
layers: [2, 8, 8, 8, 1]
learning_rate: 0.001
epochs: 50000
log_epoch_freq: 100
save_epoch_freq: 5000
INFO:root:
----------model----------
INFO:root:PINN(
  (activation): Tanh()
  (loss_function): MSELoss()
  (linears): ModuleList(
    (0): Linear(in_features=2, out_features=8, bias=True)
    (1-2): 2 x Linear(in_features=8, out_features=8, bias=True)
    (3): Linear(in_features=8, out_features=1, bias=True)
  )
  (batch_norms): ModuleList(
    (0-2): 3 x BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (dropout): Dropout(p=0.0, inplace=False)
)
INFO:root:Number of parameters: 227
INFO:root:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0.0
)
INFO:root:
----------parameters----------
seed: 2359
model_path: ./models
output_path: ./outputs
log_path: ./log
debug: False
layers: [2, 8, 8, 8, 1]
learning_rate: 0.001
epochs: 70000
log_epoch_freq: 100
save_epoch_freq: 5000
INFO:root:
----------model----------
INFO:root:PINN(
  (activation): Tanh()
  (loss_function): MSELoss()
  (linears): ModuleList(
    (0): Linear(in_features=2, out_features=8, bias=True)
    (1-2): 2 x Linear(in_features=8, out_features=8, bias=True)
    (3): Linear(in_features=8, out_features=1, bias=True)
  )
  (batch_norms): ModuleList(
    (0-2): 3 x BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (dropout): Dropout(p=0.0, inplace=False)
)
INFO:root:Number of parameters: 227
INFO:root:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0.0
)
INFO:root:
----------parameters----------
seed: 2359
model_path: ./models
output_path: ./outputs
log_path: ./log
debug: False
layers: [2, 8, 8, 8, 1]
learning_rate: 0.001
epochs: 70000
log_epoch_freq: 100
save_epoch_freq: 5000
INFO:root:
----------model----------
INFO:root:PINN(
  (activation): Tanh()
  (loss_function): MSELoss()
  (linears): ModuleList(
    (0): Linear(in_features=2, out_features=8, bias=True)
    (1-2): 2 x Linear(in_features=8, out_features=8, bias=True)
    (3): Linear(in_features=8, out_features=1, bias=True)
  )
  (batch_norms): ModuleList(
    (0-2): 3 x BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (dropout): Dropout(p=0.0, inplace=False)
)
INFO:root:Number of parameters: 227
INFO:root:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0.0
)
INFO:root:
----------parameters----------
seed: 2359
model_path: ./models
output_path: ./outputs
log_path: ./log
debug: False
layers: [2, 8, 8, 8, 1]
learning_rate: 0.001
epochs: 100000
log_epoch_freq: 100
save_epoch_freq: 5000
INFO:root:
----------model----------
INFO:root:PINN(
  (activation): Tanh()
  (loss_function): MSELoss()
  (linears): ModuleList(
    (0): Linear(in_features=2, out_features=8, bias=True)
    (1-2): 2 x Linear(in_features=8, out_features=8, bias=True)
    (3): Linear(in_features=8, out_features=1, bias=True)
  )
  (batch_norms): ModuleList(
    (0-2): 3 x BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (dropout): Dropout(p=0.0, inplace=False)
)
INFO:root:Number of parameters: 227
INFO:root:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0.0
)
INFO:root:
----------parameters----------
seed: 2359
model_path: ./models
output_path: ./outputs
log_path: ./log
debug: False
layers: [2, 8, 8, 8, 1]
learning_rate: 0.001
epochs: 100000
log_epoch_freq: 100
save_epoch_freq: 5000
INFO:root:
----------model----------
INFO:root:PINN(
  (activation): Tanh()
  (loss_function): MSELoss()
  (linears): ModuleList(
    (0): Linear(in_features=2, out_features=8, bias=True)
    (1-2): 2 x Linear(in_features=8, out_features=8, bias=True)
    (3): Linear(in_features=8, out_features=1, bias=True)
  )
  (batch_norms): ModuleList(
    (0-2): 3 x BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (dropout): Dropout(p=0.0, inplace=False)
)
INFO:root:Number of parameters: 227
INFO:root:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0.0
)
INFO:root:
----------parameters----------
seed: 8888
model_path: ./models
output_path: ./outputs
log_path: ./log
debug: False
layers: [2, 8, 8, 8, 1]
learning_rate: 0.001
epochs: 100000
log_epoch_freq: 100
save_epoch_freq: 5000
INFO:root:
----------model----------
INFO:root:PINN(
  (activation): Tanh()
  (loss_function): MSELoss()
  (linears): ModuleList(
    (0): Linear(in_features=2, out_features=8, bias=True)
    (1-2): 2 x Linear(in_features=8, out_features=8, bias=True)
    (3): Linear(in_features=8, out_features=1, bias=True)
  )
  (batch_norms): ModuleList(
    (0-2): 3 x BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (dropout): Dropout(p=0.0, inplace=False)
)
INFO:root:Number of parameters: 227
INFO:root:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0.0
)
INFO:root:
----------parameters----------
seed: 8888
model_path: ./models
output_path: ./outputs
log_path: ./log
debug: False
layers: [2, 8, 8, 8, 1]
learning_rate: 0.001
epochs: 100000
log_epoch_freq: 100
save_epoch_freq: 5000
INFO:root:
----------model----------
INFO:root:PINN(
  (activation): Tanh()
  (loss_function): MSELoss()
  (linears): ModuleList(
    (0): Linear(in_features=2, out_features=8, bias=True)
    (1-2): 2 x Linear(in_features=8, out_features=8, bias=True)
    (3): Linear(in_features=8, out_features=1, bias=True)
  )
  (batch_norms): ModuleList(
    (0-2): 3 x BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (dropout): Dropout(p=0.0, inplace=False)
)
INFO:root:Number of parameters: 227
INFO:root:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0.0
)
INFO:root:
----------parameters----------
seed: 8888
model_path: ./models
output_path: ./outputs
log_path: ./log
debug: False
layers: [2, 16, 16, 16, 1]
learning_rate: 0.001
epochs: 100000
log_epoch_freq: 100
save_epoch_freq: 5000
INFO:root:
----------model----------
INFO:root:PINN(
  (activation): Tanh()
  (loss_function): MSELoss()
  (linears): ModuleList(
    (0): Linear(in_features=2, out_features=16, bias=True)
    (1-2): 2 x Linear(in_features=16, out_features=16, bias=True)
    (3): Linear(in_features=16, out_features=1, bias=True)
  )
  (batch_norms): ModuleList(
    (0-2): 3 x BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (dropout): Dropout(p=0.0, inplace=False)
)
INFO:root:Number of parameters: 707
INFO:root:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0.0
)
INFO:root:
----------parameters----------
seed: 8888
model_path: ./models
output_path: ./outputs
log_path: ./log
debug: False
layers: [2, 16, 16, 16, 1]
learning_rate: 0.001
epochs: 100000
log_epoch_freq: 100
save_epoch_freq: 5000
INFO:root:
----------model----------
INFO:root:PINN(
  (activation): Tanh()
  (loss_function): MSELoss()
  (linears): ModuleList(
    (0): Linear(in_features=2, out_features=16, bias=True)
    (1-2): 2 x Linear(in_features=16, out_features=16, bias=True)
    (3): Linear(in_features=16, out_features=1, bias=True)
  )
  (batch_norms): ModuleList(
    (0-2): 3 x BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (dropout): Dropout(p=0.0, inplace=False)
)
INFO:root:Number of parameters: 707
INFO:root:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0.0
)
INFO:root:
----------parameters----------
seed: 8888
model_path: ./models
output_path: ./outputs
log_path: ./log
debug: False
layers: [2, 16, 16, 16, 1]
learning_rate: 0.001
epochs: 100000
log_epoch_freq: 100
save_epoch_freq: 5000
INFO:root:
----------model----------
INFO:root:PINN(
  (activation): Tanh()
  (loss_function): MSELoss()
  (linears): ModuleList(
    (0): Linear(in_features=2, out_features=16, bias=True)
    (1-2): 2 x Linear(in_features=16, out_features=16, bias=True)
    (3): Linear(in_features=16, out_features=1, bias=True)
  )
  (batch_norms): ModuleList(
    (0-2): 3 x BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (dropout): Dropout(p=0.0, inplace=False)
)
INFO:root:Number of parameters: 707
INFO:root:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0.0
)
INFO:root:
----------parameters----------
seed: 8888
model_path: ./models
output_path: ./outputs
log_path: ./log
debug: False
layers: [2, 16, 16, 16, 1]
learning_rate: 0.001
epochs: 100000
log_epoch_freq: 100
save_epoch_freq: 5000
INFO:root:
----------model----------
INFO:root:PINN(
  (activation): Tanh()
  (loss_function): MSELoss()
  (linears): ModuleList(
    (0): Linear(in_features=2, out_features=16, bias=True)
    (1-2): 2 x Linear(in_features=16, out_features=16, bias=True)
    (3): Linear(in_features=16, out_features=1, bias=True)
  )
  (batch_norms): ModuleList(
    (0-2): 3 x BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (dropout): Dropout(p=0.0, inplace=False)
)
INFO:root:Number of parameters: 707
INFO:root:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0.0
)
INFO:root:
----------parameters----------
seed: 8888
model_path: ./models
output_path: ./outputs
log_path: ./log
debug: False
layers: [2, 16, 16, 16, 1]
learning_rate: 0.001
epochs: 100000
log_epoch_freq: 100
save_epoch_freq: 5000
INFO:root:
----------model----------
INFO:root:PINN(
  (activation): Tanh()
  (loss_function): MSELoss()
  (linears): ModuleList(
    (0): Linear(in_features=2, out_features=16, bias=True)
    (1-2): 2 x Linear(in_features=16, out_features=16, bias=True)
    (3): Linear(in_features=16, out_features=1, bias=True)
  )
  (batch_norms): ModuleList(
    (0-2): 3 x BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (dropout): Dropout(p=0.0, inplace=False)
)
INFO:root:Number of parameters: 707
INFO:root:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0.0
)
INFO:root:
----------parameters----------
seed: 8888
model_path: ./models
output_path: ./outputs
log_path: ./log
debug: False
layers: [2, 16, 16, 16, 1]
learning_rate: 0.01
epochs: 100000
log_epoch_freq: 100
save_epoch_freq: 5000
INFO:root:
----------model----------
INFO:root:PINN(
  (activation): Tanh()
  (loss_function): MSELoss()
  (linears): ModuleList(
    (0): Linear(in_features=2, out_features=16, bias=True)
    (1-2): 2 x Linear(in_features=16, out_features=16, bias=True)
    (3): Linear(in_features=16, out_features=1, bias=True)
  )
  (batch_norms): ModuleList(
    (0-2): 3 x BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (dropout): Dropout(p=0.0, inplace=False)
)
INFO:root:Number of parameters: 707
INFO:root:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.01
    maximize: False
    weight_decay: 0.0
)
INFO:root:
----------parameters----------
seed: 0
model_path: ./models
output_path: ./outputs
log_path: ./log
debug: False
layers: [2, 16, 16, 16, 1]
learning_rate: 0.1
epochs: 100000
log_epoch_freq: 100
save_epoch_freq: 5000
INFO:root:
----------model----------
INFO:root:PINN(
  (activation): Tanh()
  (loss_function): MSELoss()
  (linears): ModuleList(
    (0): Linear(in_features=2, out_features=16, bias=True)
    (1-2): 2 x Linear(in_features=16, out_features=16, bias=True)
    (3): Linear(in_features=16, out_features=1, bias=True)
  )
  (batch_norms): ModuleList(
    (0-2): 3 x BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (dropout): Dropout(p=0.0, inplace=False)
)
INFO:root:Number of parameters: 707
INFO:root:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.1
    maximize: False
    weight_decay: 0.0
)
INFO:root:
----------parameters----------
seed: 0
model_path: ./models
output_path: ./outputs
log_path: ./log
debug: False
layers: [2, 20, 20, 20, 20, 20, 1]
learning_rate: 0.0002
epochs: 100000
log_epoch_freq: 100
save_epoch_freq: 5000
INFO:root:
----------model----------
INFO:root:PINN(
  (activation): Tanh()
  (loss_function): MSELoss()
  (linears): ModuleList(
    (0): Linear(in_features=2, out_features=20, bias=True)
    (1-4): 4 x Linear(in_features=20, out_features=20, bias=True)
    (5): Linear(in_features=20, out_features=1, bias=True)
  )
  (batch_norms): ModuleList(
    (0-4): 5 x BatchNorm1d(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (dropout): Dropout(p=0.0, inplace=False)
)
INFO:root:Number of parameters: 1963
INFO:root:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0002
    maximize: False
    weight_decay: 0.0
)
INFO:root:
----------parameters----------
seed: 0
model_path: ./models
output_path: ./outputs
log_path: ./log
debug: False
layers: [2, 20, 20, 20, 20, 20, 1]
learning_rate: 0.0002
epochs: 100000
log_epoch_freq: 100
save_epoch_freq: 5000
INFO:root:
----------model----------
INFO:root:PINN(
  (activation): Tanh()
  (loss_function): MSELoss()
  (linears): ModuleList(
    (0): Linear(in_features=2, out_features=20, bias=True)
    (1-4): 4 x Linear(in_features=20, out_features=20, bias=True)
    (5): Linear(in_features=20, out_features=1, bias=True)
  )
  (batch_norms): ModuleList(
    (0-4): 5 x BatchNorm1d(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (dropout): Dropout(p=0.0, inplace=False)
)
INFO:root:Number of parameters: 1963
INFO:root:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0002
    maximize: False
    weight_decay: 0.0
)
INFO:root:
----------parameters----------
seed: 0
model_path: ./models
output_path: ./outputs
log_path: ./log
debug: False
layers: [2, 20, 20, 20, 20, 20, 1]
learning_rate: 0.0002
epochs: 100000
log_epoch_freq: 100
save_epoch_freq: 5000
INFO:root:
----------model----------
INFO:root:PINN(
  (activation): Tanh()
  (loss_function): MSELoss()
  (linears): ModuleList(
    (0): Linear(in_features=2, out_features=20, bias=True)
    (1-4): 4 x Linear(in_features=20, out_features=20, bias=True)
    (5): Linear(in_features=20, out_features=1, bias=True)
  )
  (batch_norms): ModuleList(
    (0-4): 5 x BatchNorm1d(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (dropout): Dropout(p=0.0, inplace=False)
)
INFO:root:Number of parameters: 1963
INFO:root:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0002
    maximize: False
    weight_decay: 0.0
)
INFO:root:
----------parameters----------
seed: 0
model_path: ./models
output_path: ./outputs
log_path: ./log
debug: False
layers: [2, 20, 20, 20, 20, 20, 1]
learning_rate: 0.0002
epochs: 100000
log_epoch_freq: 100
save_epoch_freq: 5000
INFO:root:
----------model----------
INFO:root:PINN(
  (activation): Tanh()
  (loss_function): MSELoss()
  (linears): ModuleList(
    (0): Linear(in_features=2, out_features=20, bias=True)
    (1-4): 4 x Linear(in_features=20, out_features=20, bias=True)
    (5): Linear(in_features=20, out_features=1, bias=True)
  )
  (batch_norms): ModuleList(
    (0-4): 5 x BatchNorm1d(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (dropout): Dropout(p=0.0, inplace=False)
)
INFO:root:Number of parameters: 1963
INFO:root:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0002
    maximize: False
    weight_decay: 0.0
)
INFO:root:
----------parameters----------
seed: 0
model_path: ./models
output_path: ./outputs
log_path: ./log
debug: False
layers: [2, 20, 20, 20, 20, 20, 1]
learning_rate: 0.0002
epochs: 100000
log_epoch_freq: 100
save_epoch_freq: 5000
INFO:root:
----------model----------
INFO:root:PINN(
  (activation): Tanh()
  (loss_function): MSELoss()
  (linears): ModuleList(
    (0): Linear(in_features=2, out_features=20, bias=True)
    (1-4): 4 x Linear(in_features=20, out_features=20, bias=True)
    (5): Linear(in_features=20, out_features=1, bias=True)
  )
  (batch_norms): ModuleList(
    (0-4): 5 x BatchNorm1d(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (dropout): Dropout(p=0.0, inplace=False)
)
INFO:root:Number of parameters: 1963
INFO:root:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0002
    maximize: False
    weight_decay: 0.0
)
INFO:root:
----------parameters----------
seed: 0
model_path: ./models
output_path: ./outputs
log_path: ./log
debug: False
layers: [2, 20, 20, 20, 20, 20, 1]
learning_rate: 0.0002
epochs: 100000
log_epoch_freq: 100
save_epoch_freq: 5000
INFO:root:
----------model----------
INFO:root:PINN(
  (activation): Tanh()
  (loss_function): MSELoss()
  (linears): ModuleList(
    (0): Linear(in_features=2, out_features=20, bias=True)
    (1-4): 4 x Linear(in_features=20, out_features=20, bias=True)
    (5): Linear(in_features=20, out_features=1, bias=True)
  )
  (batch_norms): ModuleList(
    (0-4): 5 x BatchNorm1d(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (dropout): Dropout(p=0.0, inplace=False)
)
INFO:root:Number of parameters: 1963
INFO:root:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0002
    maximize: False
    weight_decay: 0.0
)
INFO:root:
----------parameters----------
seed: 0
model_path: ./models
output_path: ./outputs
log_path: ./log
debug: False
layers: [2, 20, 20, 20, 20, 20, 1]
learning_rate: 0.0002
epochs: 100000
log_epoch_freq: 100
save_epoch_freq: 5000
INFO:root:
----------model----------
INFO:root:PINN(
  (activation): Tanh()
  (loss_function): MSELoss()
  (linears): ModuleList(
    (0): Linear(in_features=2, out_features=20, bias=True)
    (1-4): 4 x Linear(in_features=20, out_features=20, bias=True)
    (5): Linear(in_features=20, out_features=1, bias=True)
  )
  (batch_norms): ModuleList(
    (0-4): 5 x BatchNorm1d(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (dropout): Dropout(p=0.0, inplace=False)
)
INFO:root:Number of parameters: 1963
INFO:root:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0002
    maximize: False
    weight_decay: 0.0
)
INFO:root:
----------parameters----------
seed: 0
model_path: ./models
output_path: ./outputs
log_path: ./log
debug: False
layers: [2, 20, 20, 1]
learning_rate: 0.0002
epochs: 100000
log_epoch_freq: 100
save_epoch_freq: 5000
INFO:root:
----------model----------
INFO:root:PINN(
  (activation): Tanh()
  (loss_function): MSELoss()
  (linears): ModuleList(
    (0): Linear(in_features=2, out_features=20, bias=True)
    (1): Linear(in_features=20, out_features=20, bias=True)
    (2): Linear(in_features=20, out_features=1, bias=True)
  )
  (batch_norms): ModuleList(
    (0-1): 2 x BatchNorm1d(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (dropout): Dropout(p=0.0, inplace=False)
)
INFO:root:Number of parameters: 583
INFO:root:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0002
    maximize: False
    weight_decay: 0.0
)
INFO:root:
----------parameters----------
seed: 4869
model_path: ./models
output_path: ./outputs
log_path: ./log
debug: False
layers: [2, 20, 20, 1]
learning_rate: 0.0002
epochs: 100000
log_epoch_freq: 100
save_epoch_freq: 5000
INFO:root:
----------model----------
INFO:root:PINN(
  (activation): Tanh()
  (loss_function): MSELoss()
  (linears): ModuleList(
    (0): Linear(in_features=2, out_features=20, bias=True)
    (1): Linear(in_features=20, out_features=20, bias=True)
    (2): Linear(in_features=20, out_features=1, bias=True)
  )
  (batch_norms): ModuleList(
    (0-1): 2 x BatchNorm1d(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (dropout): Dropout(p=0.0, inplace=False)
)
INFO:root:Number of parameters: 583
INFO:root:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0002
    maximize: False
    weight_decay: 0.0
)
INFO:root:
----------parameters----------
seed: 4869
model_path: ./models
output_path: ./outputs
log_path: ./log
debug: False
layers: [2, 20, 20, 1]
learning_rate: 0.0002
epochs: 100000
log_epoch_freq: 100
save_epoch_freq: 5000
INFO:root:
----------model----------
INFO:root:PINN(
  (activation): Tanh()
  (loss_function): MSELoss()
  (linears): ModuleList(
    (0): Linear(in_features=2, out_features=20, bias=True)
    (1): Linear(in_features=20, out_features=20, bias=True)
    (2): Linear(in_features=20, out_features=1, bias=True)
  )
  (batch_norms): ModuleList(
    (0-1): 2 x BatchNorm1d(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (dropout): Dropout(p=0.0, inplace=False)
)
INFO:root:Number of parameters: 583
INFO:root:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0002
    maximize: False
    weight_decay: 0.0
)
INFO:root:
----------parameters----------
seed: 4869
model_path: ./models
output_path: ./outputs
log_path: ./log
debug: False
layers: [2, 20, 1]
learning_rate: 0.0002
epochs: 100000
log_epoch_freq: 100
save_epoch_freq: 5000
INFO:root:
----------model----------
INFO:root:PINN(
  (activation): Tanh()
  (loss_function): MSELoss()
  (linears): ModuleList(
    (0): Linear(in_features=2, out_features=20, bias=True)
    (1): Linear(in_features=20, out_features=1, bias=True)
  )
  (batch_norms): ModuleList(
    (0): BatchNorm1d(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (dropout): Dropout(p=0.0, inplace=False)
)
INFO:root:Number of parameters: 123
INFO:root:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0002
    maximize: False
    weight_decay: 0.0
)
INFO:root:
----------parameters----------
seed: 4869
model_path: ./models
output_path: ./outputs
log_path: ./log
debug: False
layers: [2, 20, 1]
learning_rate: 0.0002
epochs: 100000
log_epoch_freq: 100
save_epoch_freq: 5000
INFO:root:
----------model----------
INFO:root:PINN(
  (activation): Tanh()
  (loss_function): MSELoss()
  (linears): ModuleList(
    (0): Linear(in_features=2, out_features=20, bias=True)
    (1): Linear(in_features=20, out_features=1, bias=True)
  )
  (batch_norms): ModuleList(
    (0): BatchNorm1d(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (dropout): Dropout(p=0.0, inplace=False)
)
INFO:root:Number of parameters: 123
INFO:root:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0002
    maximize: False
    weight_decay: 0.0
)
INFO:root:
----------parameters----------
seed: 4869
model_path: ./models
output_path: ./outputs
log_path: ./log
debug: False
layers: [2, 20, 1]
learning_rate: 0.0002
epochs: 100000
log_epoch_freq: 100
save_epoch_freq: 5000
INFO:root:
----------model----------
INFO:root:PINN(
  (activation): Tanh()
  (loss_function): MSELoss()
  (linears): ModuleList(
    (0): Linear(in_features=2, out_features=20, bias=True)
    (1): Linear(in_features=20, out_features=1, bias=True)
  )
  (batch_norms): ModuleList(
    (0): BatchNorm1d(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (dropout): Dropout(p=0.0, inplace=False)
)
INFO:root:Number of parameters: 123
INFO:root:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0002
    maximize: False
    weight_decay: 0.0
)
INFO:root:
----------parameters----------
seed: 4869
model_path: ./models
output_path: ./outputs
log_path: ./log
debug: False
layers: [2, 20, 1]
learning_rate: 0.0002
epochs: 100000
log_epoch_freq: 100
save_epoch_freq: 5000
INFO:root:
----------model----------
INFO:root:PINN(
  (activation): Tanh()
  (loss_function): MSELoss()
  (linears): ModuleList(
    (0): Linear(in_features=2, out_features=20, bias=True)
    (1): Linear(in_features=20, out_features=1, bias=True)
  )
  (batch_norms): ModuleList(
    (0): BatchNorm1d(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (dropout): Dropout(p=0.0, inplace=False)
)
INFO:root:Number of parameters: 123
INFO:root:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0002
    maximize: False
    weight_decay: 0.0
)
INFO:root:
----------parameters----------
seed: 4869
model_path: ./models
output_path: ./outputs
log_path: ./log
debug: False
layers: [2, 20, 1]
learning_rate: 0.002
epochs: 100000
log_epoch_freq: 100
save_epoch_freq: 5000
INFO:root:
----------model----------
INFO:root:PINN(
  (activation): Tanh()
  (loss_function): MSELoss()
  (linears): ModuleList(
    (0): Linear(in_features=2, out_features=20, bias=True)
    (1): Linear(in_features=20, out_features=1, bias=True)
  )
  (batch_norms): ModuleList(
    (0): BatchNorm1d(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (dropout): Dropout(p=0.0, inplace=False)
)
INFO:root:Number of parameters: 123
INFO:root:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.002
    maximize: False
    weight_decay: 0.0
)
INFO:root:
----------parameters----------
seed: 4869
model_path: ./models
output_path: ./outputs
log_path: ./log
debug: False
layers: [2, 8, 8, 1]
learning_rate: 0.01
epochs: 100000
log_epoch_freq: 100
save_epoch_freq: 5000
INFO:root:
----------model----------
INFO:root:PINN(
  (activation): Tanh()
  (loss_function): MSELoss()
  (linears): ModuleList(
    (0): Linear(in_features=2, out_features=8, bias=True)
    (1): Linear(in_features=8, out_features=8, bias=True)
    (2): Linear(in_features=8, out_features=1, bias=True)
  )
  (batch_norms): ModuleList(
    (0-1): 2 x BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (dropout): Dropout(p=0.0, inplace=False)
)
INFO:root:Number of parameters: 139
INFO:root:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.01
    maximize: False
    weight_decay: 0.0
)
INFO:root:
----------parameters----------
seed: 4869
model_path: ./models
output_path: ./outputs
log_path: ./log
debug: False
layers: [2, 8, 1]
learning_rate: 0.001
epochs: 100000
log_epoch_freq: 100
save_epoch_freq: 5000
INFO:root:
----------model----------
INFO:root:PINN(
  (activation): Tanh()
  (loss_function): MSELoss()
  (linears): ModuleList(
    (0): Linear(in_features=2, out_features=8, bias=True)
    (1): Linear(in_features=8, out_features=1, bias=True)
  )
  (batch_norms): ModuleList(
    (0): BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (dropout): Dropout(p=0.0, inplace=False)
)
INFO:root:Number of parameters: 51
INFO:root:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0.0
)
INFO:root:
----------parameters----------
seed: 4869
model_path: ./models
output_path: ./outputs
log_path: ./log
debug: False
layers: [2, 20, 1]
learning_rate: 0.001
epochs: 100000
log_epoch_freq: 100
save_epoch_freq: 5000
INFO:root:
----------model----------
INFO:root:PINN(
  (activation): Tanh()
  (loss_function): MSELoss()
  (linears): ModuleList(
    (0): Linear(in_features=2, out_features=20, bias=True)
    (1): Linear(in_features=20, out_features=1, bias=True)
  )
  (batch_norms): ModuleList(
    (0): BatchNorm1d(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (dropout): Dropout(p=0.0, inplace=False)
)
INFO:root:Number of parameters: 123
INFO:root:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0.0
)
INFO:root:
----------parameters----------
seed: 4869
model_path: ./models
output_path: ./outputs
log_path: ./log
debug: False
layers: [2, 20, 1]
learning_rate: 0.001
epochs: 100000
log_epoch_freq: 100
save_epoch_freq: 5000
INFO:root:
----------model----------
INFO:root:PINN(
  (activation): Tanh()
  (loss_function): MSELoss()
  (linears): ModuleList(
    (0): Linear(in_features=2, out_features=20, bias=True)
    (1): Linear(in_features=20, out_features=1, bias=True)
  )
  (batch_norms): ModuleList(
    (0): BatchNorm1d(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (dropout): Dropout(p=0.0, inplace=False)
)
INFO:root:Number of parameters: 123
INFO:root:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0.0
)
INFO:root:
----------parameters----------
seed: 4869
model_path: ./models
output_path: ./outputs
log_path: ./log
debug: False
layers: [2, 10, 1]
learning_rate: 0.001
epochs: 100000
log_epoch_freq: 100
save_epoch_freq: 5000
INFO:root:
----------model----------
INFO:root:PINN(
  (activation): Tanh()
  (loss_function): MSELoss()
  (linears): ModuleList(
    (0): Linear(in_features=2, out_features=10, bias=True)
    (1): Linear(in_features=10, out_features=1, bias=True)
  )
  (batch_norms): ModuleList(
    (0): BatchNorm1d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (dropout): Dropout(p=0.0, inplace=False)
)
INFO:root:Number of parameters: 63
INFO:root:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0.01
)
INFO:root:
----------parameters----------
seed: 4869
model_path: ./models
output_path: ./outputs
log_path: ./log
debug: False
layers: [2, 10, 1]
learning_rate: 0.001
epochs: 100000
log_epoch_freq: 100
save_epoch_freq: 5000
INFO:root:
----------model----------
INFO:root:PINN(
  (activation): Tanh()
  (loss_function): MSELoss()
  (linears): ModuleList(
    (0): Linear(in_features=2, out_features=10, bias=True)
    (1): Linear(in_features=10, out_features=1, bias=True)
  )
  (batch_norms): ModuleList(
    (0): BatchNorm1d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (dropout): Dropout(p=0.0, inplace=False)
)
INFO:root:Number of parameters: 63
INFO:root:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0.2
)
INFO:root:
----------parameters----------
seed: 4869
model_path: ./models
output_path: ./outputs
log_path: ./log
debug: False
layers: [2, 10, 1]
learning_rate: 0.001
epochs: 100000
log_epoch_freq: 100
save_epoch_freq: 5000
INFO:root:
----------model----------
INFO:root:PINN(
  (activation): Tanh()
  (loss_function): MSELoss()
  (linears): ModuleList(
    (0): Linear(in_features=2, out_features=10, bias=True)
    (1): Linear(in_features=10, out_features=1, bias=True)
  )
  (batch_norms): ModuleList(
    (0): BatchNorm1d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (dropout): Dropout(p=0.0, inplace=False)
)
INFO:root:Number of parameters: 63
INFO:root:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 1e-05
)
INFO:root:
----------parameters----------
seed: 4869
model_path: ./models
output_path: ./outputs
log_path: ./log
debug: False
layers: [2, 10, 1]
learning_rate: 0.001
epochs: 100000
log_epoch_freq: 100
save_epoch_freq: 5000
INFO:root:
----------model----------
INFO:root:PINN(
  (activation): Tanh()
  (loss_function): MSELoss()
  (linears): ModuleList(
    (0): Linear(in_features=2, out_features=10, bias=True)
    (1): Linear(in_features=10, out_features=1, bias=True)
  )
  (batch_norms): ModuleList(
    (0): BatchNorm1d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (dropout): Dropout(p=0.0, inplace=False)
)
INFO:root:Number of parameters: 63
INFO:root:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0.0
)
INFO:root:
----------parameters----------
seed: 4869
model_path: ./models
output_path: ./outputs
log_path: ./log
debug: False
layers: [2, 4, 1]
learning_rate: 0.001
epochs: 100000
log_epoch_freq: 100
save_epoch_freq: 5000
INFO:root:
----------model----------
INFO:root:PINN(
  (activation): Tanh()
  (loss_function): MSELoss()
  (linears): ModuleList(
    (0): Linear(in_features=2, out_features=4, bias=True)
    (1): Linear(in_features=4, out_features=1, bias=True)
  )
  (batch_norms): ModuleList(
    (0): BatchNorm1d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (dropout): Dropout(p=0.0, inplace=False)
)
INFO:root:Number of parameters: 27
INFO:root:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0.0
)
INFO:root:
----------parameters----------
seed: 4869
model_path: ./models
output_path: ./outputs
log_path: ./log
debug: False
layers: [2, 8, 1]
learning_rate: 0.001
epochs: 100000
log_epoch_freq: 100
save_epoch_freq: 5000
INFO:root:
----------model----------
INFO:root:PINN(
  (activation): Tanh()
  (loss_function): MSELoss()
  (linears): ModuleList(
    (0): Linear(in_features=2, out_features=8, bias=True)
    (1): Linear(in_features=8, out_features=1, bias=True)
  )
  (batch_norms): ModuleList(
    (0): BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (dropout): Dropout(p=0.0, inplace=False)
)
INFO:root:Number of parameters: 51
INFO:root:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0.0
)
INFO:root:
----------parameters----------
seed: 4869
model_path: ./models
output_path: ./outputs
log_path: ./log
debug: False
layers: [2, 20, 20, 20, 1]
learning_rate: 0.001
epochs: 100000
log_epoch_freq: 100
save_epoch_freq: 5000
INFO:root:
----------model----------
INFO:root:PINN(
  (activation): Tanh()
  (loss_function): MSELoss()
  (linears): ModuleList(
    (0): Linear(in_features=2, out_features=20, bias=True)
    (1-2): 2 x Linear(in_features=20, out_features=20, bias=True)
    (3): Linear(in_features=20, out_features=1, bias=True)
  )
  (batch_norms): ModuleList(
    (0-2): 3 x BatchNorm1d(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (dropout): Dropout(p=0.0, inplace=False)
)
INFO:root:Number of parameters: 1043
INFO:root:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0.0
)
